{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Data for Quality and get preliminary Results\n",
    "\n",
    "We test for validation of columns, quantity and quality of data points, ability to arrange data points such that analysis can be done via machine learning.\n",
    "\n",
    "## Important Notes\n",
    "This is not production quality code.  Code here is exploratory analytics code which needs to be wrapped up into proper functions as data differences and issues/exceptions are discovered.  This code can serve as reference for production code, but should not ever be treated as production code.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Key Libraries Required\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define data location & load data.\n",
    "base_dir = \"C:/Users/vmadmin/Documents/Work/spi/dataspi/\"\n",
    "good_file = \"GOOD_aug27_redo.csv\"\n",
    "bad_file = \"L7SPIresults_Defects_ONLY_query-impala-39690.csv\"\n",
    "\n",
    "good = pd.read_csv(base_dir + good_file)\n",
    "bad = pd.read_csv(base_dir + bad_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plcng_plant_cd</th>\n",
       "      <th>mach_id</th>\n",
       "      <th>pcb_side_inspd</th>\n",
       "      <th>wo_num</th>\n",
       "      <th>defct_dttm</th>\n",
       "      <th>intrvl_key</th>\n",
       "      <th>plcng_area_cd</th>\n",
       "      <th>plcng_prcs_cd</th>\n",
       "      <th>plcng_wrk_ctr_cd</th>\n",
       "      <th>fndng_plant_cd</th>\n",
       "      <th>...</th>\n",
       "      <th>pad_stncl_hgt</th>\n",
       "      <th>pad_spi_result</th>\n",
       "      <th>pad_spi_defct_type</th>\n",
       "      <th>solder_paste_vol_pct</th>\n",
       "      <th>solder_paste_hgt</th>\n",
       "      <th>solder_paste_area_pct</th>\n",
       "      <th>cmpnt_part_num</th>\n",
       "      <th>pkg_type</th>\n",
       "      <th>stncl_surf_area_ratio</th>\n",
       "      <th>extract_dttm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>127</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>113.5076</td>\n",
       "      <td>153.6871</td>\n",
       "      <td>93.79748</td>\n",
       "      <td>PN-27795-U5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>8/28/2018 2:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>127</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>105.2033</td>\n",
       "      <td>137.0668</td>\n",
       "      <td>97.47670</td>\n",
       "      <td>PN-27795-U5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>8/28/2018 2:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>127</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>106.6394</td>\n",
       "      <td>163.5016</td>\n",
       "      <td>82.83224</td>\n",
       "      <td>PN-27795-U5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>8/28/2018 2:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>127</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>113.9531</td>\n",
       "      <td>148.7802</td>\n",
       "      <td>97.27131</td>\n",
       "      <td>PN-27795-U5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>8/28/2018 2:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>127</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>110.2563</td>\n",
       "      <td>148.6627</td>\n",
       "      <td>94.19012</td>\n",
       "      <td>PN-27795-U5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>8/28/2018 2:54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   plcng_plant_cd  mach_id  pcb_side_inspd  wo_num  defct_dttm  intrvl_key  \\\n",
       "0             NaN      NaN             NaN     NaN         NaN         NaN   \n",
       "1             NaN      NaN             NaN     NaN         NaN         NaN   \n",
       "2             NaN      NaN             NaN     NaN         NaN         NaN   \n",
       "3             NaN      NaN             NaN     NaN         NaN         NaN   \n",
       "4             NaN      NaN             NaN     NaN         NaN         NaN   \n",
       "\n",
       "   plcng_area_cd  plcng_prcs_cd  plcng_wrk_ctr_cd  fndng_plant_cd  \\\n",
       "0            NaN            NaN               NaN             NaN   \n",
       "1            NaN            NaN               NaN             NaN   \n",
       "2            NaN            NaN               NaN             NaN   \n",
       "3            NaN            NaN               NaN             NaN   \n",
       "4            NaN            NaN               NaN             NaN   \n",
       "\n",
       "        ...        pad_stncl_hgt  pad_spi_result  pad_spi_defct_type  \\\n",
       "0       ...                  127            GOOD                GOOD   \n",
       "1       ...                  127            GOOD                GOOD   \n",
       "2       ...                  127            GOOD                GOOD   \n",
       "3       ...                  127            GOOD                GOOD   \n",
       "4       ...                  127            GOOD                GOOD   \n",
       "\n",
       "   solder_paste_vol_pct solder_paste_hgt  solder_paste_area_pct  \\\n",
       "0              113.5076         153.6871               93.79748   \n",
       "1              105.2033         137.0668               97.47670   \n",
       "2              106.6394         163.5016               82.83224   \n",
       "3              113.9531         148.7802               97.27131   \n",
       "4              110.2563         148.6627               94.19012   \n",
       "\n",
       "   cmpnt_part_num  pkg_type  stncl_surf_area_ratio    extract_dttm  \n",
       "0     PN-27795-U5         0                 0.9055  8/28/2018 2:54  \n",
       "1     PN-27795-U5         0                 0.9055  8/28/2018 2:54  \n",
       "2     PN-27795-U5         0                 0.9055  8/28/2018 2:54  \n",
       "3     PN-27795-U5         0                 0.9055  8/28/2018 2:54  \n",
       "4     PN-27795-U5         0                 0.9055  8/28/2018 2:54  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get a feel for what is in the data.\n",
    "good.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plcng_plant_cd</th>\n",
       "      <th>mach_id</th>\n",
       "      <th>pcb_side_inspd</th>\n",
       "      <th>wo_num</th>\n",
       "      <th>defct_dttm</th>\n",
       "      <th>intrvl_key</th>\n",
       "      <th>plcng_area_cd</th>\n",
       "      <th>plcng_prcs_cd</th>\n",
       "      <th>plcng_wrk_ctr_cd</th>\n",
       "      <th>fndng_plant_cd</th>\n",
       "      <th>...</th>\n",
       "      <th>solder_paste_offst_y_axis</th>\n",
       "      <th>pad_stncl_hgt</th>\n",
       "      <th>pad_spi_result</th>\n",
       "      <th>pad_spi_defct_type</th>\n",
       "      <th>solder_paste_vol_pct</th>\n",
       "      <th>solder_paste_hgt</th>\n",
       "      <th>solder_paste_area_pct</th>\n",
       "      <th>pkg_type</th>\n",
       "      <th>stncl_surf_area_ratio</th>\n",
       "      <th>extract_dttm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1020</td>\n",
       "      <td>FP9</td>\n",
       "      <td>TOP</td>\n",
       "      <td>4009351183</td>\n",
       "      <td>6/24/2018 15:56</td>\n",
       "      <td>1529855100</td>\n",
       "      <td>TWB_SM3</td>\n",
       "      <td>TWB_PCBA_SM3_TOP_FP</td>\n",
       "      <td>TWB_PCBA_TOP_FP9</td>\n",
       "      <td>1020</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.45</td>\n",
       "      <td>127</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>127.3716</td>\n",
       "      <td>165.5654</td>\n",
       "      <td>97.70272</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>7/4/2018 13:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1020</td>\n",
       "      <td>FP9</td>\n",
       "      <td>TOP</td>\n",
       "      <td>4009376503</td>\n",
       "      <td>7/3/2018 8:56</td>\n",
       "      <td>1530607500</td>\n",
       "      <td>TWB_SM3</td>\n",
       "      <td>TWB_PCBA_SM3_TOP_FP</td>\n",
       "      <td>TWB_PCBA_TOP_FP9</td>\n",
       "      <td>1020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.92</td>\n",
       "      <td>127</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>130.2810</td>\n",
       "      <td>159.0643</td>\n",
       "      <td>104.01890</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>7/4/2018 14:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1020</td>\n",
       "      <td>FP9</td>\n",
       "      <td>TOP</td>\n",
       "      <td>4009376503</td>\n",
       "      <td>7/3/2018 8:56</td>\n",
       "      <td>1530607500</td>\n",
       "      <td>TWB_SM3</td>\n",
       "      <td>TWB_PCBA_SM3_TOP_FP</td>\n",
       "      <td>TWB_PCBA_TOP_FP9</td>\n",
       "      <td>1020</td>\n",
       "      <td>...</td>\n",
       "      <td>4.82</td>\n",
       "      <td>127</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>132.1127</td>\n",
       "      <td>160.2906</td>\n",
       "      <td>104.67440</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>7/4/2018 14:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1020</td>\n",
       "      <td>FP9</td>\n",
       "      <td>TOP</td>\n",
       "      <td>4009376503</td>\n",
       "      <td>7/6/2018 14:51</td>\n",
       "      <td>1530888300</td>\n",
       "      <td>TWB_SM3</td>\n",
       "      <td>TWB_PCBA_SM3_TOP_FP</td>\n",
       "      <td>TWB_PCBA_TOP_FP9</td>\n",
       "      <td>1020</td>\n",
       "      <td>...</td>\n",
       "      <td>1.51</td>\n",
       "      <td>127</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>130.4016</td>\n",
       "      <td>170.2945</td>\n",
       "      <td>97.24921</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>7/4/2018 14:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1020</td>\n",
       "      <td>FP9</td>\n",
       "      <td>TOP</td>\n",
       "      <td>4009376503</td>\n",
       "      <td>7/6/2018 14:51</td>\n",
       "      <td>1530888300</td>\n",
       "      <td>TWB_SM3</td>\n",
       "      <td>TWB_PCBA_SM3_TOP_FP</td>\n",
       "      <td>TWB_PCBA_TOP_FP9</td>\n",
       "      <td>1020</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.27</td>\n",
       "      <td>127</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>123.9029</td>\n",
       "      <td>166.4613</td>\n",
       "      <td>94.53050</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>7/4/2018 14:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   plcng_plant_cd mach_id pcb_side_inspd      wo_num       defct_dttm  \\\n",
       "0            1020     FP9            TOP  4009351183  6/24/2018 15:56   \n",
       "1            1020     FP9            TOP  4009376503    7/3/2018 8:56   \n",
       "2            1020     FP9            TOP  4009376503    7/3/2018 8:56   \n",
       "3            1020     FP9            TOP  4009376503   7/6/2018 14:51   \n",
       "4            1020     FP9            TOP  4009376503   7/6/2018 14:51   \n",
       "\n",
       "   intrvl_key plcng_area_cd        plcng_prcs_cd  plcng_wrk_ctr_cd  \\\n",
       "0  1529855100       TWB_SM3  TWB_PCBA_SM3_TOP_FP  TWB_PCBA_TOP_FP9   \n",
       "1  1530607500       TWB_SM3  TWB_PCBA_SM3_TOP_FP  TWB_PCBA_TOP_FP9   \n",
       "2  1530607500       TWB_SM3  TWB_PCBA_SM3_TOP_FP  TWB_PCBA_TOP_FP9   \n",
       "3  1530888300       TWB_SM3  TWB_PCBA_SM3_TOP_FP  TWB_PCBA_TOP_FP9   \n",
       "4  1530888300       TWB_SM3  TWB_PCBA_SM3_TOP_FP  TWB_PCBA_TOP_FP9   \n",
       "\n",
       "   fndng_plant_cd       ...       solder_paste_offst_y_axis pad_stncl_hgt  \\\n",
       "0            1020       ...                          -11.45           127   \n",
       "1            1020       ...                            0.92           127   \n",
       "2            1020       ...                            4.82           127   \n",
       "3            1020       ...                            1.51           127   \n",
       "4            1020       ...                           -2.27           127   \n",
       "\n",
       "  pad_spi_result pad_spi_defct_type solder_paste_vol_pct solder_paste_hgt  \\\n",
       "0           GOOD               GOOD             127.3716         165.5654   \n",
       "1           GOOD               GOOD             130.2810         159.0643   \n",
       "2           GOOD               GOOD             132.1127         160.2906   \n",
       "3           GOOD               GOOD             130.4016         170.2945   \n",
       "4           GOOD               GOOD             123.9029         166.4613   \n",
       "\n",
       "  solder_paste_area_pct pkg_type stncl_surf_area_ratio    extract_dttm  \n",
       "0              97.70272        0                0.9055  7/4/2018 13:15  \n",
       "1             104.01890        0                0.9055  7/4/2018 14:17  \n",
       "2             104.67440        0                0.9055  7/4/2018 14:17  \n",
       "3              97.24921        0                0.9055  7/4/2018 14:19  \n",
       "4              94.53050        0                0.9055  7/4/2018 14:19  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get a feel for what is in the bad data\n",
    "bad.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89094, 39)\n",
      "(33700, 38)\n"
     ]
    }
   ],
   "source": [
    "#How many good/ bad do we have (pins)\n",
    "print(good.shape)\n",
    "print(bad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plcng_plant_cd' 'mach_id' 'pcb_side_inspd' 'wo_num' 'defct_dttm'\n",
      " 'intrvl_key' 'plcng_area_cd' 'plcng_prcs_cd' 'plcng_wrk_ctr_cd'\n",
      " 'fndng_plant_cd' 'fndng_area_cd' 'fndng_prcs_cd' 'bld_part_no'\n",
      " 'bld_serial_no' 'barcd' 'assy_part_no' 'assy_serial_no' 'defct_cd'\n",
      " 'failed_test_code' 'fail_type' 'cmpnt_part_no' 'spi_test_id' 'ref_id'\n",
      " 'silkscrn_nbr' 'cmpntpin_nbr' 'cmpntpin_size_x_axis'\n",
      " 'cmpntpin_size_y_axis' 'solder_paste_offst_x_axis'\n",
      " 'solder_paste_offst_y_axis' 'pad_stncl_hgt' 'pad_spi_result'\n",
      " 'pad_spi_defct_type' 'solder_paste_vol_pct' 'solder_paste_hgt'\n",
      " 'solder_paste_area_pct' 'cmpnt_part_num' 'pkg_type'\n",
      " 'stncl_surf_area_ratio' 'extract_dttm']\n",
      "['cmpnt_part_num']\n"
     ]
    }
   ],
   "source": [
    "# See what full list of columns are and if there is a difference in columns between the two\n",
    "print(good.columns.values)\n",
    "print(list(set(good) - set(bad)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cmpnt_part_num']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(good) - set(bad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(x):\n",
    "    r = x.split(\"-\") \n",
    "    if(len(r) > 2):\n",
    "        x = '-'.join(r[0:1])\n",
    "    return x\n",
    "bad[\"cmpnt_part_no\"] = bad[\"cmpnt_part_no\"].apply(lambda x: combine(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'00F5D9D5', '00F39057', '00F11D75', '00F5DB75', '00F015C0', '00F7BBA3', '00F4B3F9', '00F11D43', '00F75C74', '00F87339', '00F0B7F2', '00F0B9E8', '00F40BC9', '00F38E59', '00F11B0D', '00F01822', '00F29584', '00F11851', '00F40B13', '00F0BA04', '00F11ADD', '00F7C00F', '00F4B2FB', '00F11909', '00F11A77', '00F4B5DF', '00F6F7DB', '00F5FD84', '00F69D9F', '00F11F8B', '00F40F19', '00F01806', '00F29678', '00F01554', '00F75A1C', '00F7BA65', '00F11BE7', '00F15277', '00F45F61', '00F5FD50', '00F11C41', '00F40CAB', '00F407CF', '00F15667', '00F872D1', '00F11BC5', '00F40B7D', '00F15471', '00F75A7E', '00F7DE52', '00F40F3D', '00F151BF', '00F6F799', '00F6F87D', '00F1562B', '00F87323', '00F296AA', '00F409A1', '00F2970E', '00F75A04', '00F7C0F9', '00F5DA97', '00F11AC7', '00F87211', '00F21545', '00F407D7', '00F0B9F4', '00F29AA2', '00F08C10', '00F11AED', '00F7DED8', '00F11F71', '00F01584', '00F5D9D9', '00F0B986', '00F019A4', '00F29A28', '00F11905', '00F11B29', '00F7C4BD', '00F7C077', '00F7C38B', '00F75C6A', '00F38C71', '00F75A70', '00F11AD9', '00F86E67', '00F4B44F'}\n",
      "{1, 2}\n",
      "{'U11', 'U20', 'U6', 'U13', 'U26', 'U23', 'U5', 'U4', 'U12', 'U25'}\n",
      "{'PN-419257', 'PN-27795', 'PN-271803', '94474092', 'PN-31488', 'PN', 'PN-29537', 'PN-27724'}\n"
     ]
    }
   ],
   "source": [
    "print(set(bad[\"barcd\"]))\n",
    "print(set(bad[\"silkscrn_nbr\"]))\n",
    "print(set(bad[\"ref_id\"]))\n",
    "print(set(bad[\"cmpnt_part_no\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Bad Data and Get Data Counts For Each Component\n",
    "\n",
    "We need to get a feel for how much data we actually have and which components we have a decent shot of dealing with using standard machine learning approaches.\n",
    "\n",
    "It is possible to solve all components using non standard approaches; however deeper analysis will need to be done to validate the approaches which could be applied.  This should be done both at a theoretical and practical level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This looks at bad currently.  For good I need to change first groupby to use \"cmpnt_part_num not \"cmpnt_part_no\".\n",
    "bad_vals = []\n",
    "for k, v in bad.groupby(\"cmpnt_part_no\"):\n",
    "    for k, v1 in v.groupby(\"barcd\"):\n",
    "        for k, v2 in v1.groupby(\"silkscrn_nbr\"):\n",
    "            for k, v3 in v2.groupby(\"ref_id\"):\n",
    "                for k, v4 in v3.groupby(\"defct_dttm\"):\n",
    "                    vals = v4.sort_values(\"cmpntpin_nbr\")[[\"solder_paste_offst_x_axis\", \n",
    "                                                       \"solder_paste_offst_y_axis\", \n",
    "                                                       \"solder_paste_vol_pct\",\n",
    "                                                       \"solder_paste_hgt\",\n",
    "                                                       \"solder_paste_area_pct\",\n",
    "                                                        \"ref_id\",\n",
    "                                                        \"cmpntpin_nbr\",\n",
    "                                                        \"cmpnt_part_no\"]]\n",
    "                    addition = {\"defect\" : True, \"pin_data\" : vals, \n",
    "                                \"ref_id\" : list(set(v4[\"ref_id\"]))[0],\n",
    "                               \"cmpnt_part_no\" : list(set(v4[\"cmpnt_part_no\"]))[0]}\n",
    "                    bad_vals.append(addition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref id: PN-419257 count: 27\n",
      "ref id: PN-27795 count: 34\n",
      "ref id: PN-271803 count: 10\n",
      "ref id: 94474092 count: 31\n",
      "ref id: PN-31488 count: 23\n",
      "ref id: PN count: 3\n",
      "ref id: PN-29537 count: 6\n",
      "ref id: PN-27724 count: 27\n"
     ]
    }
   ],
   "source": [
    "ref_ids = list(set(bad[\"cmpnt_part_no\"]))\n",
    "for ref_id in ref_ids:\n",
    "    num_ids = len([x for x in bad_vals if x[\"cmpnt_part_no\"] == ref_id])\n",
    "    print(\"ref id: {} count: {}\".format(ref_id, num_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Good Data and Get Data Counts For Each Component\n",
    "\n",
    "We need to get a feel for how much data we actually have and which components we have a decent shot of dealing with using standard machine learning approaches.\n",
    "\n",
    "It is possible to solve all components using non standard approaches; however deeper analysis will need to be done to validate the approaches which could be applied.  This should be done both at a theoretical and practical level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This looks at bad currently.  For good I need to change first groupby to use \"cmpnt_part_num not \"cmpnt_part_no\".\n",
    "#good[\"cmpnt_part_num\"] = good[\"cmpnt_part_num\"].apply(lambda x: combine(x))\n",
    "good_vals = []\n",
    "for k, v in good.groupby(\"cmpnt_part_num\"):\n",
    "    for k, v1 in v.groupby(\"barcd\"):\n",
    "        for k, v2 in v1.groupby(\"silkscrn_nbr\"):\n",
    "            for k, v3 in v2.groupby(\"ref_id\"):\n",
    "                for k, v4 in v3.groupby(\"spi_test_id\"):\n",
    "                    vals = v4.sort_values(\"cmpntpin_nbr\")[[\"solder_paste_offst_x_axis\", \n",
    "                                                       \"solder_paste_offst_y_axis\", \n",
    "                                                       \"solder_paste_vol_pct\",\n",
    "                                                       \"solder_paste_hgt\",\n",
    "                                                       \"solder_paste_area_pct\",\n",
    "                                                        \"ref_id\",\n",
    "                                                        \"cmpntpin_nbr\",\n",
    "                                                        \"cmpnt_part_num\"]]\n",
    "                    addition = {\"defect\" : False, \"pin_data\" : vals, \n",
    "                                \"ref_id\" : list(set(v4[\"ref_id\"]))[0],\n",
    "                               \"cmpnt_part_num\" : list(set(v4[\"cmpnt_part_num\"]))[0]}\n",
    "                    good_vals.append(addition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref id: PN-27795-U5 count: 62\n",
      "ref id: PN-271803 count: 186\n",
      "ref id: 94485092 count: 186\n",
      "ref id: 94474092 count: 62\n",
      "ref id: PN-31488-U6 count: 62\n",
      "ref id: PN-27724 count: 62\n"
     ]
    }
   ],
   "source": [
    "ref_ids = list(set(good[\"cmpnt_part_num\"]))\n",
    "for ref_id in ref_ids:\n",
    "    num_ids = len([x for x in good_vals if x[\"cmpnt_part_num\"] == ref_id])\n",
    "    print(\"ref id: {} count: {}\".format(ref_id, num_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Section - Get Numpy Arrays for what I Need\n",
    "\n",
    "This section is about extracting the numpy arrays for what we need and dealing with encoding stuff to numerical features if necessary.\n",
    "\n",
    "We are focusing on component PN-27795 which exists ONLY for ref_id U5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "good_27795 = [x for x in good_vals if x[\"cmpnt_part_num\"] == 'PN-27724']\n",
    "bad_27795 = [x for x in bad_vals if x[\"cmpnt_part_no\"] == 'PN-27724']\n",
    "\n",
    "print(len(good_27795))\n",
    "print(len(bad_27795))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1926,)\n",
      "(1926,)\n"
     ]
    }
   ],
   "source": [
    "row_1 = good_27795[0][\"pin_data\"][[\"solder_paste_offst_x_axis\", \n",
    "                                                       \"solder_paste_offst_y_axis\", \n",
    "                                                       \"solder_paste_vol_pct\",\n",
    "                                                       \"solder_paste_hgt\",\n",
    "                                                       \"solder_paste_area_pct\"]].values.flatten()\n",
    "row_1 = np.append(row_1, [0])\n",
    "print(row_1.shape)\n",
    "row_2 = good_27795[1][\"pin_data\"][[\"solder_paste_offst_x_axis\", \n",
    "                                                       \"solder_paste_offst_y_axis\", \n",
    "                                                       \"solder_paste_vol_pct\",\n",
    "                                                       \"solder_paste_hgt\",\n",
    "                                                       \"solder_paste_area_pct\"]].values.flatten()\n",
    "row_2 = np.append(row_2, [0])\n",
    "print(row_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = np.vstack([row_1, row_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1926,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1926)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to Data Shapes for Training\n",
    "\n",
    "We will convert the good & bad to data shapes required for training and then do a train/test split to prep for a simplistic keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ml_data(row, is_good):\n",
    "    prep = row[\"pin_data\"][[\"solder_paste_offst_x_axis\", \n",
    "                            \"solder_paste_offst_y_axis\", \n",
    "                            \"solder_paste_vol_pct\",\n",
    "                            \"solder_paste_hgt\",\n",
    "                            \"solder_paste_area_pct\"]].values.flatten()\n",
    "    if(is_good):\n",
    "        prep = np.append(prep, [0.0])\n",
    "    else:\n",
    "        prep = np.append(prep, [1.0])\n",
    "    return prep\n",
    "\n",
    "good_complete_data = get_ml_data(good_27795.pop(0), is_good=True)\n",
    "for data in good_27795:\n",
    "    good_complete_data = np.vstack([good_complete_data, get_ml_data(data, is_good=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62, 1926)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_complete_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-82c0cbf9d429>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbad_complete_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_ml_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbad_27795\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_good\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbad_27795\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mbad_complete_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbad_complete_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_ml_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_good\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m     \"\"\"\n\u001b[1;32m--> 234\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "bad_complete_data = get_ml_data(bad_27795.pop(0), is_good=False)\n",
    "for data in bad_27795:\n",
    "    bad_complete_data = np.vstack([bad_complete_data, get_ml_data(data, is_good=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1926)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_complete_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1925 into shape (16,16,5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-a77baf79e648>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbad_complete_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 1925 into shape (16,16,5)"
     ]
    }
   ],
   "source": [
    "bad_complete_data[0][:-1].reshape(16,16,5)[:][:][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67, 1926)\n"
     ]
    }
   ],
   "source": [
    "full_data = np.append(bad_complete_data, good_complete_data, axis=0)\n",
    "print(full_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67, 1925)\n",
      "(67, 1)\n"
     ]
    }
   ],
   "source": [
    "#verify sizes for x vs y to extract input vs output.  Last column is the output or y value.\n",
    "print(full_data[:,:-1].shape)\n",
    "print(full_data[:,-1:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prep for ml learning\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44, 1925)\n",
      "(44, 1)\n",
      "(23, 1925)\n",
      "(23, 1)\n"
     ]
    }
   ],
   "source": [
    "x_t, x_v, y_t, y_v = train_test_split(full_data[:,:-1], full_data[:,-1:], test_size = 0.33)\n",
    "print(x_t.shape)\n",
    "print(y_t.shape)\n",
    "print(x_v.shape)\n",
    "print(y_v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_t_scaled = scaler.fit_transform(x_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5.20870724e-01  9.53438913e-01 -2.23702124e+00 ... -6.07883892e-01\n",
      "  -4.26935045e-01 -2.20157663e-01]\n",
      " [-3.97369429e-01  6.73897813e-01  1.29834311e+00 ...  1.25195003e+00\n",
      "   1.43376994e+00 -4.96374429e-01]\n",
      " [-4.74557739e-01  1.48813854e-03  1.41155921e+00 ...  8.67721792e-01\n",
      "   9.06817080e-02  1.04455553e+00]\n",
      " ...\n",
      " [-6.99506527e-01  3.66654441e-01 -6.49685815e-01 ... -7.77210688e-01\n",
      "  -1.62586924e-01 -8.84566080e-01]\n",
      " [-2.87100415e-01 -3.74335525e+00  9.69524750e-01 ...  1.05165745e+00\n",
      "   5.49466287e-01  5.59441491e-01]\n",
      " [-7.45819513e-01 -6.90267337e-02  1.77318523e+00 ... -1.09139132e+00\n",
      "  -1.26424327e+00  4.77024320e-01]]\n",
      "[[ -8.06      9.13    103.0992  ... 114.1114  157.5489   91.98508]\n",
      " [ -7.5       8.02    119.7805  ... 127.517   178.1889   90.8848 ]\n",
      " [ -7.85      5.35    120.3147  ... 124.7475  163.2906   97.02293]\n",
      " ...\n",
      " [ -8.87      6.8     110.5889  ... 112.8909  160.4812   89.33848]\n",
      " [ -7.       -9.52    118.229   ... 126.0733  168.3797   95.09053]\n",
      " [ -9.08      5.07    122.021   ... 110.6263  148.261    94.76223]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "x_v_scaled = scaler.transform(x_v)\n",
    "print(x_v_scaled)\n",
    "print(x_v)\n",
    "print(y_v.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical Machine Learning\n",
    "\n",
    "Lets set a benchmark with classical machine learning from scikit.  We should see some level of performance from this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC()\n",
    "svm.fit(x_t_scaled, y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_p = svm.predict(x_v_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      1.00      0.95        21\n",
      "        1.0       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.83      0.91      0.87        23\n",
      "\n",
      "[[21  0]\n",
      " [ 2  0]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_v.flatten(), v_p))\n",
    "print(confusion_matrix(y_v.flatten(), v_p))\n",
    "print(v_p.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try a Random Forest Classifier\n",
    "\n",
    "Just another model to give a whirl at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(x_t_scaled, y_t)\n",
    "v_p = rfc.predict(x_v_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      1.00      0.95        21\n",
      "        1.0       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.83      0.91      0.87        23\n",
      "\n",
      "[[21  0]\n",
      " [ 2  0]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_v.flatten(), v_p))\n",
    "print(confusion_matrix(y_v.flatten(), v_p))\n",
    "print(v_p.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Dense Neural Network\n",
    "\n",
    "Lets give a shot at a dense neural network and see if we can get any decent results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers import Input, Dense, Dropout, Conv2D, Flatten, MaxPooling2D\n",
    "from keras.regularizers import L1L2\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, 1925)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 44 samples, validate on 23 samples\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 8.8149 - binary_accuracy: 0.5455 - val_loss: 8.5459 - val_binary_accuracy: 0.6957\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 0s 591us/step - loss: 8.3766 - binary_accuracy: 0.7273 - val_loss: 8.3801 - val_binary_accuracy: 0.6957\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 0s 727us/step - loss: 8.0668 - binary_accuracy: 0.8864 - val_loss: 8.1324 - val_binary_accuracy: 0.6957\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 0s 500us/step - loss: 7.7805 - binary_accuracy: 0.9773 - val_loss: 7.8910 - val_binary_accuracy: 0.7826\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 0s 659us/step - loss: 7.5324 - binary_accuracy: 1.0000 - val_loss: 7.6327 - val_binary_accuracy: 0.8261\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 0s 545us/step - loss: 7.2874 - binary_accuracy: 1.0000 - val_loss: 7.3736 - val_binary_accuracy: 0.8261\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 0s 501us/step - loss: 7.0393 - binary_accuracy: 1.0000 - val_loss: 7.1159 - val_binary_accuracy: 0.8261\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 0s 500us/step - loss: 6.7854 - binary_accuracy: 1.0000 - val_loss: 6.8487 - val_binary_accuracy: 0.8261\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 0s 496us/step - loss: 6.5244 - binary_accuracy: 1.0000 - val_loss: 6.5826 - val_binary_accuracy: 0.8696\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 0s 523us/step - loss: 6.2613 - binary_accuracy: 1.0000 - val_loss: 6.3132 - val_binary_accuracy: 0.8696\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 0s 545us/step - loss: 5.9954 - binary_accuracy: 1.0000 - val_loss: 6.0417 - val_binary_accuracy: 0.8696\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 0s 409us/step - loss: 5.7298 - binary_accuracy: 1.0000 - val_loss: 5.7757 - val_binary_accuracy: 0.8696\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 0s 477us/step - loss: 5.4667 - binary_accuracy: 1.0000 - val_loss: 5.5138 - val_binary_accuracy: 0.8696\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 0s 455us/step - loss: 5.2059 - binary_accuracy: 1.0000 - val_loss: 5.2561 - val_binary_accuracy: 0.8696\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 0s 591us/step - loss: 4.9481 - binary_accuracy: 1.0000 - val_loss: 5.0082 - val_binary_accuracy: 0.8696\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 0s 671us/step - loss: 4.6951 - binary_accuracy: 1.0000 - val_loss: 4.7660 - val_binary_accuracy: 0.8696\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 0s 614us/step - loss: 4.4474 - binary_accuracy: 1.0000 - val_loss: 4.5227 - val_binary_accuracy: 0.8696\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 0s 682us/step - loss: 4.2067 - binary_accuracy: 1.0000 - val_loss: 4.2813 - val_binary_accuracy: 0.8696\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 0s 591us/step - loss: 3.9735 - binary_accuracy: 1.0000 - val_loss: 4.0425 - val_binary_accuracy: 0.8696\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 0s 477us/step - loss: 3.7495 - binary_accuracy: 1.0000 - val_loss: 3.8231 - val_binary_accuracy: 0.8696\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 0s 386us/step - loss: 3.5339 - binary_accuracy: 1.0000 - val_loss: 3.6132 - val_binary_accuracy: 0.9130\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 0s 500us/step - loss: 3.3269 - binary_accuracy: 1.0000 - val_loss: 3.4091 - val_binary_accuracy: 0.9130\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 0s 500us/step - loss: 3.1299 - binary_accuracy: 1.0000 - val_loss: 3.2365 - val_binary_accuracy: 0.9130\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 0s 432us/step - loss: 2.9436 - binary_accuracy: 1.0000 - val_loss: 3.0668 - val_binary_accuracy: 0.9130\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 0s 568us/step - loss: 2.7669 - binary_accuracy: 1.0000 - val_loss: 2.8970 - val_binary_accuracy: 0.8696\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 0s 614us/step - loss: 2.6010 - binary_accuracy: 1.0000 - val_loss: 2.7398 - val_binary_accuracy: 0.8696\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 0s 432us/step - loss: 2.4459 - binary_accuracy: 1.0000 - val_loss: 2.5836 - val_binary_accuracy: 0.9130\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 0s 568us/step - loss: 2.3029 - binary_accuracy: 1.0000 - val_loss: 2.4522 - val_binary_accuracy: 0.9130\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 0s 409us/step - loss: 2.1705 - binary_accuracy: 1.0000 - val_loss: 2.3378 - val_binary_accuracy: 0.8261\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 0s 432us/step - loss: 2.0454 - binary_accuracy: 1.0000 - val_loss: 2.2839 - val_binary_accuracy: 0.8696\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 0s 500us/step - loss: 1.9314 - binary_accuracy: 1.0000 - val_loss: 2.2136 - val_binary_accuracy: 0.7826\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 0s 477us/step - loss: 1.8263 - binary_accuracy: 1.0000 - val_loss: 2.1724 - val_binary_accuracy: 0.8261\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 0s 409us/step - loss: 1.7259 - binary_accuracy: 1.0000 - val_loss: 1.9297 - val_binary_accuracy: 0.8696\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 0s 386us/step - loss: 1.6314 - binary_accuracy: 1.0000 - val_loss: 1.8237 - val_binary_accuracy: 0.9130\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 0s 409us/step - loss: 1.5467 - binary_accuracy: 1.0000 - val_loss: 1.7941 - val_binary_accuracy: 0.8261\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 0s 574us/step - loss: 1.4655 - binary_accuracy: 1.0000 - val_loss: 1.6958 - val_binary_accuracy: 0.8261\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 0s 659us/step - loss: 1.3927 - binary_accuracy: 1.0000 - val_loss: 1.6031 - val_binary_accuracy: 0.8696\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 0s 574us/step - loss: 1.3253 - binary_accuracy: 1.0000 - val_loss: 1.5196 - val_binary_accuracy: 0.8261\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 0s 320us/step - loss: 1.2670 - binary_accuracy: 1.0000 - val_loss: 1.5361 - val_binary_accuracy: 0.9130\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 0s 477us/step - loss: 1.2265 - binary_accuracy: 1.0000 - val_loss: 2.0112 - val_binary_accuracy: 0.6957\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 0s 530us/step - loss: 1.6596 - binary_accuracy: 0.7727 - val_loss: 2.7284 - val_binary_accuracy: 0.6957\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 0s 469us/step - loss: 2.6297 - binary_accuracy: 0.7500 - val_loss: 2.9153 - val_binary_accuracy: 0.6522\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 0s 500us/step - loss: 2.5131 - binary_accuracy: 0.7727 - val_loss: 2.7479 - val_binary_accuracy: 0.6522\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 0s 568us/step - loss: 2.3034 - binary_accuracy: 0.7955 - val_loss: 2.3562 - val_binary_accuracy: 0.7391\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 0s 409us/step - loss: 2.1435 - binary_accuracy: 0.9091 - val_loss: 2.5103 - val_binary_accuracy: 0.6522\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 0s 432us/step - loss: 2.2238 - binary_accuracy: 0.8864 - val_loss: 2.4903 - val_binary_accuracy: 0.7391\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 0s 318us/step - loss: 2.1469 - binary_accuracy: 1.0000 - val_loss: 2.3825 - val_binary_accuracy: 0.7826\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 0s 454us/step - loss: 2.0419 - binary_accuracy: 1.0000 - val_loss: 2.2587 - val_binary_accuracy: 0.8261\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 0s 432us/step - loss: 1.9401 - binary_accuracy: 1.0000 - val_loss: 2.1343 - val_binary_accuracy: 0.8261\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 0s 477us/step - loss: 1.8247 - binary_accuracy: 1.0000 - val_loss: 2.0186 - val_binary_accuracy: 0.8261\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 0s 500us/step - loss: 1.7084 - binary_accuracy: 1.0000 - val_loss: 1.9091 - val_binary_accuracy: 0.8696\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 386us/step - loss: 1.5980 - binary_accuracy: 1.0000 - val_loss: 1.7884 - val_binary_accuracy: 0.8261\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 0s 432us/step - loss: 1.5137 - binary_accuracy: 1.0000 - val_loss: 1.6844 - val_binary_accuracy: 0.8696\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 0s 477us/step - loss: 1.4263 - binary_accuracy: 1.0000 - val_loss: 1.5880 - val_binary_accuracy: 0.8696\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 0s 500us/step - loss: 1.3469 - binary_accuracy: 1.0000 - val_loss: 1.4988 - val_binary_accuracy: 0.8696\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 0s 341us/step - loss: 1.2763 - binary_accuracy: 1.0000 - val_loss: 1.4449 - val_binary_accuracy: 0.8696\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 0s 471us/step - loss: 1.2110 - binary_accuracy: 1.0000 - val_loss: 1.3891 - val_binary_accuracy: 0.8696\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 0s 341us/step - loss: 1.1519 - binary_accuracy: 1.0000 - val_loss: 1.3390 - val_binary_accuracy: 0.8696\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 0s 432us/step - loss: 1.0995 - binary_accuracy: 1.0000 - val_loss: 1.3013 - val_binary_accuracy: 0.9130\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 0s 435us/step - loss: 1.0545 - binary_accuracy: 1.0000 - val_loss: 1.2319 - val_binary_accuracy: 0.9130\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 0s 455us/step - loss: 1.0128 - binary_accuracy: 1.0000 - val_loss: 1.1642 - val_binary_accuracy: 0.8696\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 0s 364us/step - loss: 0.9717 - binary_accuracy: 1.0000 - val_loss: 1.1026 - val_binary_accuracy: 0.9565\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 0s 341us/step - loss: 0.9381 - binary_accuracy: 1.0000 - val_loss: 1.0669 - val_binary_accuracy: 0.9565\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 0s 432us/step - loss: 0.9083 - binary_accuracy: 1.0000 - val_loss: 1.0160 - val_binary_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 0s 439us/step - loss: 0.8772 - binary_accuracy: 1.0000 - val_loss: 1.0875 - val_binary_accuracy: 0.9130\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 0s 341us/step - loss: 0.8792 - binary_accuracy: 1.0000 - val_loss: 1.0567 - val_binary_accuracy: 0.9130\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 0s 459us/step - loss: 0.8626 - binary_accuracy: 1.0000 - val_loss: 1.0073 - val_binary_accuracy: 0.8696\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 0s 432us/step - loss: 0.8364 - binary_accuracy: 1.0000 - val_loss: 0.9287 - val_binary_accuracy: 0.9565\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 0s 341us/step - loss: 0.8074 - binary_accuracy: 1.0000 - val_loss: 0.8605 - val_binary_accuracy: 0.9565\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 0s 341us/step - loss: 0.7793 - binary_accuracy: 1.0000 - val_loss: 0.8962 - val_binary_accuracy: 0.9565\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 0s 341us/step - loss: 0.7557 - binary_accuracy: 1.0000 - val_loss: 0.9321 - val_binary_accuracy: 0.9130\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 0s 363us/step - loss: 0.7312 - binary_accuracy: 1.0000 - val_loss: 0.9184 - val_binary_accuracy: 0.8696\n",
      "Epoch 73/100\n",
      "44/44 [==============================] - 0s 432us/step - loss: 0.7105 - binary_accuracy: 1.0000 - val_loss: 0.8631 - val_binary_accuracy: 0.9565\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 0s 409us/step - loss: 0.6926 - binary_accuracy: 1.0000 - val_loss: 0.8232 - val_binary_accuracy: 0.9565\n",
      "Epoch 75/100\n",
      "44/44 [==============================] - 0s 365us/step - loss: 0.6759 - binary_accuracy: 1.0000 - val_loss: 0.9308 - val_binary_accuracy: 0.8696\n",
      "Epoch 76/100\n",
      "44/44 [==============================] - 0s 409us/step - loss: 0.6704 - binary_accuracy: 1.0000 - val_loss: 0.8866 - val_binary_accuracy: 0.9130\n",
      "Epoch 77/100\n",
      "44/44 [==============================] - 0s 318us/step - loss: 0.6637 - binary_accuracy: 1.0000 - val_loss: 0.8254 - val_binary_accuracy: 0.9130\n",
      "Epoch 78/100\n",
      "44/44 [==============================] - 0s 318us/step - loss: 0.6522 - binary_accuracy: 1.0000 - val_loss: 1.0633 - val_binary_accuracy: 0.8696\n",
      "Epoch 79/100\n",
      "44/44 [==============================] - 0s 348us/step - loss: 0.6843 - binary_accuracy: 0.9773 - val_loss: 0.9862 - val_binary_accuracy: 0.8696\n",
      "Epoch 80/100\n",
      "44/44 [==============================] - 0s 318us/step - loss: 0.7243 - binary_accuracy: 1.0000 - val_loss: 1.2826 - val_binary_accuracy: 0.7826\n",
      "Epoch 81/100\n",
      "44/44 [==============================] - 0s 345us/step - loss: 0.8138 - binary_accuracy: 0.9318 - val_loss: 1.2776 - val_binary_accuracy: 0.8261\n",
      "Epoch 82/100\n",
      "44/44 [==============================] - 0s 318us/step - loss: 0.9094 - binary_accuracy: 0.8864 - val_loss: 1.1242 - val_binary_accuracy: 0.8696\n",
      "Epoch 83/100\n",
      "44/44 [==============================] - 0s 454us/step - loss: 0.7843 - binary_accuracy: 1.0000 - val_loss: 1.0196 - val_binary_accuracy: 0.9130\n",
      "Epoch 84/100\n",
      "44/44 [==============================] - 0s 341us/step - loss: 0.8152 - binary_accuracy: 1.0000 - val_loss: 0.9850 - val_binary_accuracy: 0.9565\n",
      "Epoch 85/100\n",
      "44/44 [==============================] - 0s 364us/step - loss: 0.7973 - binary_accuracy: 1.0000 - val_loss: 0.9296 - val_binary_accuracy: 0.9565\n",
      "Epoch 86/100\n",
      "44/44 [==============================] - 0s 409us/step - loss: 0.7565 - binary_accuracy: 1.0000 - val_loss: 0.8886 - val_binary_accuracy: 0.9565\n",
      "Epoch 87/100\n",
      "44/44 [==============================] - 0s 477us/step - loss: 0.7175 - binary_accuracy: 1.0000 - val_loss: 0.8582 - val_binary_accuracy: 0.9565\n",
      "Epoch 88/100\n",
      "44/44 [==============================] - 0s 432us/step - loss: 0.6790 - binary_accuracy: 1.0000 - val_loss: 0.8245 - val_binary_accuracy: 0.9130\n",
      "Epoch 89/100\n",
      "44/44 [==============================] - 0s 402us/step - loss: 0.6446 - binary_accuracy: 1.0000 - val_loss: 0.7957 - val_binary_accuracy: 0.9130\n",
      "Epoch 90/100\n",
      "44/44 [==============================] - 0s 477us/step - loss: 0.6145 - binary_accuracy: 1.0000 - val_loss: 0.7844 - val_binary_accuracy: 0.9130\n",
      "Epoch 91/100\n",
      "44/44 [==============================] - 0s 341us/step - loss: 0.5882 - binary_accuracy: 1.0000 - val_loss: 0.7769 - val_binary_accuracy: 0.9130\n",
      "Epoch 92/100\n",
      "44/44 [==============================] - 0s 455us/step - loss: 0.5654 - binary_accuracy: 1.0000 - val_loss: 0.7815 - val_binary_accuracy: 0.9130\n",
      "Epoch 93/100\n",
      "44/44 [==============================] - 0s 432us/step - loss: 0.5455 - binary_accuracy: 1.0000 - val_loss: 0.7640 - val_binary_accuracy: 0.9130\n",
      "Epoch 94/100\n",
      "44/44 [==============================] - 0s 341us/step - loss: 0.5271 - binary_accuracy: 1.0000 - val_loss: 0.7400 - val_binary_accuracy: 0.9130\n",
      "Epoch 95/100\n",
      "44/44 [==============================] - 0s 318us/step - loss: 0.5113 - binary_accuracy: 1.0000 - val_loss: 0.7334 - val_binary_accuracy: 0.9130\n",
      "Epoch 96/100\n",
      "44/44 [==============================] - 0s 364us/step - loss: 0.4967 - binary_accuracy: 1.0000 - val_loss: 0.7320 - val_binary_accuracy: 0.9130\n",
      "Epoch 97/100\n",
      "44/44 [==============================] - 0s 318us/step - loss: 0.4840 - binary_accuracy: 1.0000 - val_loss: 0.7200 - val_binary_accuracy: 0.9130\n",
      "Epoch 98/100\n",
      "44/44 [==============================] - 0s 546us/step - loss: 0.4729 - binary_accuracy: 1.0000 - val_loss: 0.7418 - val_binary_accuracy: 0.9130\n",
      "Epoch 99/100\n",
      "44/44 [==============================] - 0s 409us/step - loss: 0.4635 - binary_accuracy: 1.0000 - val_loss: 0.7786 - val_binary_accuracy: 0.9130\n",
      "Epoch 100/100\n",
      "44/44 [==============================] - 0s 500us/step - loss: 0.4555 - binary_accuracy: 1.0000 - val_loss: 0.7556 - val_binary_accuracy: 0.9130\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "INPUT_SIZE = (1925,)\n",
    "reg_rate = 0.001\n",
    "model_in = Input(shape=INPUT_SIZE)\n",
    "classifier = Dense(128, activation=\"tanh\", kernel_regularizer=L1L2(l1=reg_rate, l2=reg_rate))(model_in)\n",
    "classifier = Dense(64, activation=\"tanh\", kernel_regularizer=L1L2(l1=reg_rate, l2=reg_rate))(classifier)\n",
    "classifier = Dense(32, activation=\"tanh\", kernel_regularizer=L1L2(l1=reg_rate, l2=reg_rate))(classifier)\n",
    "#classifier = Dropout(0.5)(classifier)\n",
    "classifier = Dense(1, activation=\"sigmoid\", kernel_regularizer=L1L2(l1=reg_rate, l2=reg_rate))(classifier)\n",
    "\n",
    "model = Model(inputs=[model_in], outputs=[classifier])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"binary_accuracy\"])\n",
    "\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "callbacks = [ EarlyStopping(monitor=\"loss\", patience=50, min_delta=0.0)]\n",
    "\n",
    "evaluation = model.fit(x_t_scaled, y_t, shuffle=True,\n",
    "                        epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1,\n",
    "                        validation_data = (x_v_scaled, y_v),\n",
    "                        callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      1.00      0.95        21\n",
      "        1.0       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.83      0.91      0.87        23\n",
      "\n",
      "[[21  0]\n",
      " [ 2  0]]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "v_p_k = model.predict(x_v_scaled)\n",
    "v_p_k = [1.0 if v  >= 0.5 else 0.0 for v in v_p_k]\n",
    "print(classification_report(y_v.flatten(), v_p_k))\n",
    "print(confusion_matrix(y_v.flatten(), v_p_k))\n",
    "print(v_p_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Sequential Model Compostion\n",
    "\n",
    "Same as above just with sequential model composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.3735 - binary_accuracy: 0.8409\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - 0s 841us/step - loss: 0.1109 - binary_accuracy: 0.9545\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - 0s 818us/step - loss: 0.0147 - binary_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - 0s 705us/step - loss: 0.0053 - binary_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - 0s 727us/step - loss: 0.0043 - binary_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - 0s 636us/step - loss: 0.0012 - binary_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - 0s 727us/step - loss: 6.4714e-04 - binary_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - 0s 614us/step - loss: 4.7020e-04 - binary_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - 0s 714us/step - loss: 3.1407e-04 - binary_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - 0s 841us/step - loss: 2.6236e-04 - binary_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128,activation=\"relu\",input_shape=(x_t.shape[1],)))\n",
    "model.add(Dense(64,activation=\"relu\"))\n",
    "model.add(Dense(32,activation=\"relu\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"binary_accuracy\"])\n",
    "\n",
    "epoch_count=10\n",
    "batch_size=10\n",
    "\n",
    "history = model.fit(x=x_t_scaled,y=y_t,batch_size=batch_size,epochs=epoch_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.95      0.93        21\n",
      "        1.0       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.83      0.87      0.85        23\n",
      "\n",
      "[[20  1]\n",
      " [ 2  0]]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "v_p_k = model.predict(x_v_scaled)\n",
    "v_p_k = [1.0 if v  >= 0.5 else 0.0 for v in v_p_k]\n",
    "print(classification_report(y_v.flatten(), v_p_k))\n",
    "print(confusion_matrix(y_v.flatten(), v_p_k))\n",
    "print(v_p_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Convolutional Neural Network\n",
    "\n",
    "As the problem may be a pattern problem; lets give a whirl at a convolutional network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44, 1925)\n",
      "(44, 1)\n",
      "(23, 1925)\n",
      "(23, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_t.shape)\n",
    "print(y_t.shape)\n",
    "print(x_v.shape)\n",
    "print(y_v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t_c = x_t_scaled.reshape(44, 77, 5, 5)\n",
    "x_v_c = x_v_scaled.reshape(23, 77, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = (77, 5, 5)\n",
    "reg_rate = 0.001\n",
    "model_in = Input(shape=INPUT_SIZE)\n",
    "classifier = Conv2D(128, (3,3), activation=\"tanh\", kernel_regularizer=L1L2(l1=reg_rate, l2=reg_rate))(model_in)\n",
    "classifier = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(classifier)\n",
    "#classifier = Conv2D(64, (2,2), activation=\"tanh\", kernel_regularizer=L1L2(l1=reg_rate, l2=reg_rate))(classifier)\n",
    "#classifier = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(classifier)\n",
    "classifier = Flatten()(classifier)\n",
    "classifier = Dense(1, activation=\"sigmoid\", kernel_regularizer=L1L2(l1=reg_rate, l2=reg_rate))(classifier)\n",
    "\n",
    "model = Model(inputs=[model_in], outputs=[classifier])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 44 samples, validate on 23 samples\n",
      "Epoch 1/200\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.8022 - acc: 0.7727 - val_loss: 0.6073 - val_acc: 0.9130\n",
      "Epoch 2/200\n",
      "44/44 [==============================] - 0s 756us/step - loss: 0.5245 - acc: 0.9318 - val_loss: 0.6903 - val_acc: 0.9130\n",
      "Epoch 3/200\n",
      "44/44 [==============================] - 0s 794us/step - loss: 0.5174 - acc: 0.9318 - val_loss: 0.7571 - val_acc: 0.9130\n",
      "Epoch 4/200\n",
      "44/44 [==============================] - 0s 796us/step - loss: 0.4878 - acc: 0.9318 - val_loss: 0.7844 - val_acc: 0.9130\n",
      "Epoch 5/200\n",
      "44/44 [==============================] - 0s 773us/step - loss: 0.4442 - acc: 0.9318 - val_loss: 0.7898 - val_acc: 0.9130\n",
      "Epoch 6/200\n",
      "44/44 [==============================] - 0s 818us/step - loss: 0.3907 - acc: 0.9773 - val_loss: 0.8024 - val_acc: 0.9130\n",
      "Epoch 7/200\n",
      "44/44 [==============================] - 0s 772us/step - loss: 0.3674 - acc: 0.9773 - val_loss: 0.8310 - val_acc: 0.9130\n",
      "Epoch 8/200\n",
      "44/44 [==============================] - 0s 817us/step - loss: 0.3417 - acc: 0.9773 - val_loss: 0.8624 - val_acc: 0.9130\n",
      "Epoch 9/200\n",
      "44/44 [==============================] - 0s 750us/step - loss: 0.3297 - acc: 0.9773 - val_loss: 0.9040 - val_acc: 0.9130\n",
      "Epoch 10/200\n",
      "44/44 [==============================] - 0s 841us/step - loss: 0.3169 - acc: 0.9773 - val_loss: 0.9458 - val_acc: 0.8696\n",
      "Epoch 11/200\n",
      "44/44 [==============================] - 0s 773us/step - loss: 0.3114 - acc: 1.0000 - val_loss: 0.9794 - val_acc: 0.8696\n",
      "Epoch 12/200\n",
      "44/44 [==============================] - 0s 864us/step - loss: 0.3079 - acc: 1.0000 - val_loss: 0.9992 - val_acc: 0.8696\n",
      "Epoch 13/200\n",
      "44/44 [==============================] - 0s 773us/step - loss: 0.3040 - acc: 1.0000 - val_loss: 1.0096 - val_acc: 0.8696\n",
      "Epoch 14/200\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.2967 - acc: 1.0000 - val_loss: 1.0164 - val_acc: 0.8696\n",
      "Epoch 15/200\n",
      "44/44 [==============================] - 0s 750us/step - loss: 0.2914 - acc: 1.0000 - val_loss: 1.0127 - val_acc: 0.8696\n",
      "Epoch 16/200\n",
      "44/44 [==============================] - 0s 682us/step - loss: 0.2852 - acc: 1.0000 - val_loss: 1.0052 - val_acc: 0.8696\n",
      "Epoch 17/200\n",
      "44/44 [==============================] - 0s 750us/step - loss: 0.2792 - acc: 1.0000 - val_loss: 0.9890 - val_acc: 0.9130\n",
      "Epoch 18/200\n",
      "44/44 [==============================] - 0s 684us/step - loss: 0.2747 - acc: 1.0000 - val_loss: 0.9742 - val_acc: 0.9130\n",
      "Epoch 19/200\n",
      "44/44 [==============================] - 0s 795us/step - loss: 0.2709 - acc: 1.0000 - val_loss: 0.9644 - val_acc: 0.9130\n",
      "Epoch 20/200\n",
      "44/44 [==============================] - 0s 636us/step - loss: 0.2676 - acc: 1.0000 - val_loss: 0.9571 - val_acc: 0.9130\n",
      "Epoch 21/200\n",
      "44/44 [==============================] - 0s 721us/step - loss: 0.2639 - acc: 1.0000 - val_loss: 0.9506 - val_acc: 0.9130\n",
      "Epoch 22/200\n",
      "44/44 [==============================] - 0s 682us/step - loss: 0.2598 - acc: 1.0000 - val_loss: 0.9406 - val_acc: 0.9130\n",
      "Epoch 23/200\n",
      "44/44 [==============================] - 0s 818us/step - loss: 0.2554 - acc: 1.0000 - val_loss: 0.9324 - val_acc: 0.9130\n",
      "Epoch 24/200\n",
      "44/44 [==============================] - 0s 750us/step - loss: 0.2508 - acc: 1.0000 - val_loss: 0.9300 - val_acc: 0.9130\n",
      "Epoch 25/200\n",
      "44/44 [==============================] - 0s 773us/step - loss: 0.2466 - acc: 1.0000 - val_loss: 0.9278 - val_acc: 0.9130\n",
      "Epoch 26/200\n",
      "44/44 [==============================] - 0s 750us/step - loss: 0.2424 - acc: 1.0000 - val_loss: 0.9254 - val_acc: 0.9130\n",
      "Epoch 27/200\n",
      "44/44 [==============================] - 0s 704us/step - loss: 0.2388 - acc: 1.0000 - val_loss: 0.9233 - val_acc: 0.9130\n",
      "Epoch 28/200\n",
      "44/44 [==============================] - 0s 796us/step - loss: 0.2350 - acc: 1.0000 - val_loss: 0.9259 - val_acc: 0.9130\n",
      "Epoch 29/200\n",
      "44/44 [==============================] - 0s 795us/step - loss: 0.2313 - acc: 1.0000 - val_loss: 0.9283 - val_acc: 0.9130\n",
      "Epoch 30/200\n",
      "44/44 [==============================] - 0s 795us/step - loss: 0.2278 - acc: 1.0000 - val_loss: 0.9246 - val_acc: 0.9130\n",
      "Epoch 31/200\n",
      "44/44 [==============================] - 0s 705us/step - loss: 0.2241 - acc: 1.0000 - val_loss: 0.9124 - val_acc: 0.9130\n",
      "Epoch 32/200\n",
      "44/44 [==============================] - 0s 794us/step - loss: 0.2204 - acc: 1.0000 - val_loss: 0.8990 - val_acc: 0.9130\n",
      "Epoch 33/200\n",
      "44/44 [==============================] - 0s 818us/step - loss: 0.2172 - acc: 1.0000 - val_loss: 0.8917 - val_acc: 0.9130\n",
      "Epoch 34/200\n",
      "44/44 [==============================] - 0s 727us/step - loss: 0.2144 - acc: 1.0000 - val_loss: 0.8877 - val_acc: 0.9130\n",
      "Epoch 35/200\n",
      "44/44 [==============================] - 0s 773us/step - loss: 0.2111 - acc: 1.0000 - val_loss: 0.8862 - val_acc: 0.9130\n",
      "Epoch 36/200\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.2076 - acc: 1.0000 - val_loss: 0.8872 - val_acc: 0.9130\n",
      "Epoch 37/200\n",
      "44/44 [==============================] - 0s 727us/step - loss: 0.2041 - acc: 1.0000 - val_loss: 0.8883 - val_acc: 0.9130\n",
      "Epoch 38/200\n",
      "44/44 [==============================] - 0s 773us/step - loss: 0.2010 - acc: 1.0000 - val_loss: 0.8839 - val_acc: 0.9130\n",
      "Epoch 39/200\n",
      "44/44 [==============================] - 0s 773us/step - loss: 0.1981 - acc: 1.0000 - val_loss: 0.8787 - val_acc: 0.9130\n",
      "Epoch 40/200\n",
      "44/44 [==============================] - 0s 747us/step - loss: 0.1947 - acc: 1.0000 - val_loss: 0.8749 - val_acc: 0.9130\n",
      "Epoch 41/200\n",
      "44/44 [==============================] - 0s 658us/step - loss: 0.1922 - acc: 1.0000 - val_loss: 0.8634 - val_acc: 0.9130\n",
      "Epoch 42/200\n",
      "44/44 [==============================] - 0s 755us/step - loss: 0.1894 - acc: 1.0000 - val_loss: 0.8590 - val_acc: 0.9130\n",
      "Epoch 43/200\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.1870 - acc: 1.0000 - val_loss: 0.8571 - val_acc: 0.9130\n",
      "Epoch 44/200\n",
      "44/44 [==============================] - 0s 682us/step - loss: 0.1838 - acc: 1.0000 - val_loss: 0.8592 - val_acc: 0.9130\n",
      "Epoch 45/200\n",
      "44/44 [==============================] - 0s 727us/step - loss: 0.1809 - acc: 1.0000 - val_loss: 0.8684 - val_acc: 0.9130\n",
      "Epoch 46/200\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.1784 - acc: 1.0000 - val_loss: 0.8757 - val_acc: 0.9130\n",
      "Epoch 47/200\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.1764 - acc: 1.0000 - val_loss: 0.8752 - val_acc: 0.9130\n",
      "Epoch 48/200\n",
      "44/44 [==============================] - 0s 773us/step - loss: 0.1742 - acc: 1.0000 - val_loss: 0.8636 - val_acc: 0.9130\n",
      "Epoch 49/200\n",
      "44/44 [==============================] - 0s 752us/step - loss: 0.1717 - acc: 1.0000 - val_loss: 0.8525 - val_acc: 0.9130\n",
      "Epoch 50/200\n",
      "44/44 [==============================] - 0s 795us/step - loss: 0.1688 - acc: 1.0000 - val_loss: 0.8394 - val_acc: 0.9130\n",
      "Epoch 51/200\n",
      "44/44 [==============================] - 0s 727us/step - loss: 0.1672 - acc: 1.0000 - val_loss: 0.8311 - val_acc: 0.9130\n",
      "Epoch 52/200\n",
      "44/44 [==============================] - 0s 705us/step - loss: 0.1659 - acc: 1.0000 - val_loss: 0.8322 - val_acc: 0.9130\n",
      "Epoch 53/200\n",
      "44/44 [==============================] - 0s 614us/step - loss: 0.1645 - acc: 1.0000 - val_loss: 0.8437 - val_acc: 0.9130\n",
      "Epoch 54/200\n",
      "44/44 [==============================] - 0s 706us/step - loss: 0.1615 - acc: 1.0000 - val_loss: 0.8493 - val_acc: 0.9130\n",
      "Epoch 55/200\n",
      "44/44 [==============================] - 0s 682us/step - loss: 0.1606 - acc: 1.0000 - val_loss: 0.8475 - val_acc: 0.9130\n",
      "Epoch 56/200\n",
      "44/44 [==============================] - 0s 704us/step - loss: 0.1601 - acc: 1.0000 - val_loss: 0.8510 - val_acc: 0.9130\n",
      "Epoch 57/200\n",
      "44/44 [==============================] - 0s 704us/step - loss: 0.1583 - acc: 1.0000 - val_loss: 0.8450 - val_acc: 0.9130\n",
      "Epoch 58/200\n",
      "44/44 [==============================] - 0s 636us/step - loss: 0.1558 - acc: 1.0000 - val_loss: 0.8449 - val_acc: 0.9130\n",
      "Epoch 59/200\n",
      "44/44 [==============================] - 0s 682us/step - loss: 0.1527 - acc: 1.0000 - val_loss: 0.8333 - val_acc: 0.9130\n",
      "Epoch 60/200\n",
      "44/44 [==============================] - 0s 697us/step - loss: 0.1513 - acc: 1.0000 - val_loss: 0.8273 - val_acc: 0.9130\n",
      "Epoch 61/200\n",
      "44/44 [==============================] - 0s 705us/step - loss: 0.1495 - acc: 1.0000 - val_loss: 0.8250 - val_acc: 0.9130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/200\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.1477 - acc: 1.0000 - val_loss: 0.8404 - val_acc: 0.9130\n",
      "Epoch 63/200\n",
      "44/44 [==============================] - 0s 705us/step - loss: 0.1454 - acc: 1.0000 - val_loss: 0.8510 - val_acc: 0.9130\n",
      "Epoch 64/200\n",
      "44/44 [==============================] - 0s 704us/step - loss: 0.1445 - acc: 1.0000 - val_loss: 0.8627 - val_acc: 0.9130\n",
      "Epoch 65/200\n",
      "44/44 [==============================] - 0s 682us/step - loss: 0.1433 - acc: 1.0000 - val_loss: 0.8928 - val_acc: 0.9130\n",
      "Epoch 66/200\n",
      "44/44 [==============================] - 0s 661us/step - loss: 0.1489 - acc: 1.0000 - val_loss: 0.8775 - val_acc: 0.9130\n",
      "Epoch 67/200\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.1442 - acc: 1.0000 - val_loss: 0.8257 - val_acc: 0.9130\n",
      "Epoch 68/200\n",
      "44/44 [==============================] - 0s 614us/step - loss: 0.1410 - acc: 1.0000 - val_loss: 0.8026 - val_acc: 0.9130\n",
      "Epoch 69/200\n",
      "44/44 [==============================] - 0s 727us/step - loss: 0.1418 - acc: 1.0000 - val_loss: 0.7991 - val_acc: 0.9130\n",
      "Epoch 70/200\n",
      "44/44 [==============================] - 0s 637us/step - loss: 0.1407 - acc: 1.0000 - val_loss: 0.8091 - val_acc: 0.9130\n",
      "Epoch 71/200\n",
      "44/44 [==============================] - 0s 636us/step - loss: 0.1365 - acc: 1.0000 - val_loss: 0.8402 - val_acc: 0.9130\n",
      "Epoch 72/200\n",
      "44/44 [==============================] - 0s 660us/step - loss: 0.1344 - acc: 1.0000 - val_loss: 0.8985 - val_acc: 0.9130\n",
      "Epoch 73/200\n",
      "44/44 [==============================] - 0s 614us/step - loss: 0.1422 - acc: 1.0000 - val_loss: 0.9193 - val_acc: 0.9130\n",
      "Epoch 74/200\n",
      "44/44 [==============================] - 0s 636us/step - loss: 0.1424 - acc: 1.0000 - val_loss: 0.8957 - val_acc: 0.9130\n",
      "Epoch 75/200\n",
      "44/44 [==============================] - 0s 614us/step - loss: 0.1351 - acc: 1.0000 - val_loss: 0.8683 - val_acc: 0.9130\n",
      "Epoch 76/200\n",
      "44/44 [==============================] - 0s 636us/step - loss: 0.1305 - acc: 1.0000 - val_loss: 0.8457 - val_acc: 0.9130\n",
      "Epoch 77/200\n",
      "44/44 [==============================] - 0s 636us/step - loss: 0.1307 - acc: 1.0000 - val_loss: 0.8450 - val_acc: 0.9130\n",
      "Epoch 78/200\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.1302 - acc: 1.0000 - val_loss: 0.8576 - val_acc: 0.9130\n",
      "Epoch 79/200\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.1287 - acc: 1.0000 - val_loss: 0.8629 - val_acc: 0.9130\n",
      "Epoch 80/200\n",
      "44/44 [==============================] - 0s 613us/step - loss: 0.1264 - acc: 1.0000 - val_loss: 0.8721 - val_acc: 0.9130\n",
      "Epoch 81/200\n",
      "44/44 [==============================] - 0s 682us/step - loss: 0.1252 - acc: 1.0000 - val_loss: 0.9043 - val_acc: 0.9130\n",
      "Epoch 82/200\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.1300 - acc: 1.0000 - val_loss: 0.9155 - val_acc: 0.9130\n",
      "Epoch 83/200\n",
      "44/44 [==============================] - 0s 639us/step - loss: 0.1289 - acc: 1.0000 - val_loss: 0.9042 - val_acc: 0.8696\n",
      "Epoch 84/200\n",
      "44/44 [==============================] - 0s 636us/step - loss: 0.1245 - acc: 1.0000 - val_loss: 0.8816 - val_acc: 0.9130\n",
      "Epoch 85/200\n",
      "44/44 [==============================] - 0s 636us/step - loss: 0.1212 - acc: 1.0000 - val_loss: 0.8773 - val_acc: 0.8696\n",
      "Epoch 86/200\n",
      "44/44 [==============================] - 0s 636us/step - loss: 0.1215 - acc: 1.0000 - val_loss: 0.8698 - val_acc: 0.9130\n",
      "Epoch 87/200\n",
      "44/44 [==============================] - 0s 660us/step - loss: 0.1223 - acc: 1.0000 - val_loss: 0.8606 - val_acc: 0.9130\n",
      "Epoch 88/200\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.1208 - acc: 1.0000 - val_loss: 0.8539 - val_acc: 0.9130\n",
      "Epoch 89/200\n",
      "44/44 [==============================] - 0s 637us/step - loss: 0.1187 - acc: 1.0000 - val_loss: 0.8471 - val_acc: 0.9130\n",
      "Epoch 90/200\n",
      "44/44 [==============================] - 0s 676us/step - loss: 0.1171 - acc: 1.0000 - val_loss: 0.8529 - val_acc: 0.9130\n",
      "Epoch 91/200\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.1162 - acc: 1.0000 - val_loss: 0.8622 - val_acc: 0.9130\n",
      "Epoch 92/200\n",
      "44/44 [==============================] - 0s 614us/step - loss: 0.1152 - acc: 1.0000 - val_loss: 0.8621 - val_acc: 0.9130\n",
      "Epoch 93/200\n",
      "44/44 [==============================] - 0s 636us/step - loss: 0.1140 - acc: 1.0000 - val_loss: 0.8563 - val_acc: 0.9130\n",
      "Epoch 94/200\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.1135 - acc: 1.0000 - val_loss: 0.8555 - val_acc: 0.9130\n",
      "Epoch 95/200\n",
      "44/44 [==============================] - 0s 636us/step - loss: 0.1125 - acc: 1.0000 - val_loss: 0.8702 - val_acc: 0.9130\n",
      "Epoch 96/200\n",
      "44/44 [==============================] - 0s 727us/step - loss: 0.1120 - acc: 1.0000 - val_loss: 0.8798 - val_acc: 0.9130\n",
      "Epoch 97/200\n",
      "44/44 [==============================] - 0s 682us/step - loss: 0.1114 - acc: 1.0000 - val_loss: 0.8909 - val_acc: 0.9130\n",
      "Epoch 98/200\n",
      "44/44 [==============================] - 0s 591us/step - loss: 0.1107 - acc: 1.0000 - val_loss: 0.8823 - val_acc: 0.9130\n",
      "Epoch 99/200\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.1095 - acc: 1.0000 - val_loss: 0.8738 - val_acc: 0.9130\n",
      "Epoch 100/200\n",
      "44/44 [==============================] - 0s 614us/step - loss: 0.1084 - acc: 1.0000 - val_loss: 0.8666 - val_acc: 0.9130\n",
      "Epoch 101/200\n",
      "44/44 [==============================] - 0s 705us/step - loss: 0.1078 - acc: 1.0000 - val_loss: 0.8691 - val_acc: 0.9130\n",
      "Epoch 102/200\n",
      "44/44 [==============================] - 0s 613us/step - loss: 0.1071 - acc: 1.0000 - val_loss: 0.8716 - val_acc: 0.9130\n",
      "Epoch 103/200\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.1065 - acc: 1.0000 - val_loss: 0.8571 - val_acc: 0.9130\n",
      "Epoch 104/200\n",
      "44/44 [==============================] - 0s 660us/step - loss: 0.1055 - acc: 1.0000 - val_loss: 0.8345 - val_acc: 0.9130\n",
      "Epoch 105/200\n",
      "44/44 [==============================] - 0s 636us/step - loss: 0.1058 - acc: 1.0000 - val_loss: 0.8243 - val_acc: 0.9130\n",
      "Epoch 106/200\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.1059 - acc: 1.0000 - val_loss: 0.8208 - val_acc: 0.9130\n",
      "Epoch 107/200\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.1051 - acc: 1.0000 - val_loss: 0.8300 - val_acc: 0.9130\n",
      "Epoch 108/200\n",
      "44/44 [==============================] - 0s 636us/step - loss: 0.1038 - acc: 1.0000 - val_loss: 0.8570 - val_acc: 0.9130\n",
      "Epoch 109/200\n",
      "44/44 [==============================] - 0s 636us/step - loss: 0.1016 - acc: 1.0000 - val_loss: 0.9072 - val_acc: 0.9130\n",
      "Epoch 110/200\n",
      "44/44 [==============================] - 0s 613us/step - loss: 0.1097 - acc: 1.0000 - val_loss: 0.9503 - val_acc: 0.8696\n",
      "Epoch 111/200\n",
      "44/44 [==============================] - 0s 636us/step - loss: 0.1146 - acc: 1.0000 - val_loss: 0.9520 - val_acc: 0.8696\n",
      "Epoch 112/200\n",
      "44/44 [==============================] - 0s 614us/step - loss: 0.1098 - acc: 1.0000 - val_loss: 0.9236 - val_acc: 0.8696\n",
      "Epoch 113/200\n",
      "44/44 [==============================] - 0s 636us/step - loss: 0.1021 - acc: 1.0000 - val_loss: 0.8937 - val_acc: 0.9130\n",
      "Epoch 114/200\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.1021 - acc: 1.0000 - val_loss: 0.8692 - val_acc: 0.9130\n",
      "Epoch 115/200\n",
      "44/44 [==============================] - 0s 614us/step - loss: 0.1020 - acc: 1.0000 - val_loss: 0.8664 - val_acc: 0.9130\n",
      "Epoch 116/200\n",
      "44/44 [==============================] - 0s 704us/step - loss: 0.1022 - acc: 1.0000 - val_loss: 0.8655 - val_acc: 0.9130\n",
      "Epoch 117/200\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.1000 - acc: 1.0000 - val_loss: 0.8763 - val_acc: 0.9130\n",
      "Epoch 118/200\n",
      "44/44 [==============================] - 0s 614us/step - loss: 0.0989 - acc: 1.0000 - val_loss: 0.9048 - val_acc: 0.9130\n",
      "Epoch 119/200\n",
      "44/44 [==============================] - 0s 636us/step - loss: 0.1010 - acc: 1.0000 - val_loss: 0.9201 - val_acc: 0.9130\n",
      "Epoch 120/200\n",
      "44/44 [==============================] - 0s 591us/step - loss: 0.1028 - acc: 1.0000 - val_loss: 0.9188 - val_acc: 0.9130\n",
      "Epoch 121/200\n",
      "44/44 [==============================] - 0s 637us/step - loss: 0.1001 - acc: 1.0000 - val_loss: 0.9003 - val_acc: 0.9130\n",
      "Epoch 122/200\n",
      "44/44 [==============================] - 0s 613us/step - loss: 0.0969 - acc: 1.0000 - val_loss: 0.8843 - val_acc: 0.9130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/200\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.0950 - acc: 1.0000 - val_loss: 0.8760 - val_acc: 0.9130\n",
      "Epoch 124/200\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.0946 - acc: 1.0000 - val_loss: 0.8721 - val_acc: 0.9130\n",
      "Epoch 125/200\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.0936 - acc: 1.0000 - val_loss: 0.8750 - val_acc: 0.9130\n",
      "Epoch 126/200\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.0927 - acc: 1.0000 - val_loss: 0.8736 - val_acc: 0.9130\n",
      "Epoch 127/200\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.0919 - acc: 1.0000 - val_loss: 0.8710 - val_acc: 0.9130\n",
      "Epoch 128/200\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.0912 - acc: 1.0000 - val_loss: 0.8709 - val_acc: 0.9130\n",
      "Epoch 129/200\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.0906 - acc: 1.0000 - val_loss: 0.8667 - val_acc: 0.9130\n",
      "Epoch 130/200\n",
      "44/44 [==============================] - 0s 682us/step - loss: 0.0900 - acc: 1.0000 - val_loss: 0.8675 - val_acc: 0.9130\n",
      "Epoch 131/200\n",
      "44/44 [==============================] - 0s 636us/step - loss: 0.0894 - acc: 1.0000 - val_loss: 0.8683 - val_acc: 0.9130\n",
      "Epoch 132/200\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.0888 - acc: 1.0000 - val_loss: 0.8648 - val_acc: 0.9130\n",
      "Epoch 133/200\n",
      "44/44 [==============================] - 0s 682us/step - loss: 0.0882 - acc: 1.0000 - val_loss: 0.8611 - val_acc: 0.9130\n",
      "Epoch 134/200\n",
      "44/44 [==============================] - 0s 637us/step - loss: 0.0877 - acc: 1.0000 - val_loss: 0.8572 - val_acc: 0.9130\n",
      "Epoch 135/200\n",
      "44/44 [==============================] - 0s 636us/step - loss: 0.0872 - acc: 1.0000 - val_loss: 0.8538 - val_acc: 0.9130\n",
      "Epoch 136/200\n",
      "44/44 [==============================] - 0s 623us/step - loss: 0.0867 - acc: 1.0000 - val_loss: 0.8576 - val_acc: 0.9130\n",
      "Epoch 137/200\n",
      "44/44 [==============================] - 0s 636us/step - loss: 0.0865 - acc: 1.0000 - val_loss: 0.8668 - val_acc: 0.9130\n",
      "Epoch 138/200\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.0862 - acc: 1.0000 - val_loss: 0.8667 - val_acc: 0.9130\n",
      "Epoch 139/200\n",
      "44/44 [==============================] - 0s 705us/step - loss: 0.0855 - acc: 1.0000 - val_loss: 0.8604 - val_acc: 0.9130\n",
      "Epoch 140/200\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.0851 - acc: 1.0000 - val_loss: 0.8531 - val_acc: 0.9130\n",
      "Epoch 141/200\n",
      "44/44 [==============================] - 0s 684us/step - loss: 0.0844 - acc: 1.0000 - val_loss: 0.8518 - val_acc: 0.9130\n",
      "Epoch 142/200\n",
      "44/44 [==============================] - 0s 614us/step - loss: 0.0839 - acc: 1.0000 - val_loss: 0.8563 - val_acc: 0.9130\n",
      "Epoch 143/200\n",
      "44/44 [==============================] - 0s 614us/step - loss: 0.0836 - acc: 1.0000 - val_loss: 0.8564 - val_acc: 0.9130\n",
      "Epoch 144/200\n",
      "44/44 [==============================] - 0s 655us/step - loss: 0.0829 - acc: 1.0000 - val_loss: 0.8474 - val_acc: 0.9130\n",
      "Epoch 145/200\n",
      "44/44 [==============================] - 0s 591us/step - loss: 0.0826 - acc: 1.0000 - val_loss: 0.8382 - val_acc: 0.9130\n",
      "Epoch 146/200\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.0830 - acc: 1.0000 - val_loss: 0.8373 - val_acc: 0.9130\n",
      "Epoch 147/200\n",
      "44/44 [==============================] - 0s 727us/step - loss: 0.0826 - acc: 1.0000 - val_loss: 0.8493 - val_acc: 0.9130\n",
      "Epoch 148/200\n",
      "44/44 [==============================] - 0s 707us/step - loss: 0.0823 - acc: 1.0000 - val_loss: 0.8677 - val_acc: 0.9130\n",
      "Epoch 149/200\n",
      "44/44 [==============================] - 0s 636us/step - loss: 0.0821 - acc: 1.0000 - val_loss: 0.8817 - val_acc: 0.9130\n",
      "Epoch 150/200\n",
      "44/44 [==============================] - 0s 680us/step - loss: 0.0813 - acc: 1.0000 - val_loss: 0.8780 - val_acc: 0.9130\n",
      "Epoch 151/200\n",
      "44/44 [==============================] - 0s 639us/step - loss: 0.0805 - acc: 1.0000 - val_loss: 0.8711 - val_acc: 0.9130\n",
      "Epoch 152/200\n",
      "44/44 [==============================] - 0s 637us/step - loss: 0.0799 - acc: 1.0000 - val_loss: 0.8686 - val_acc: 0.9130\n",
      "Epoch 153/200\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.0796 - acc: 1.0000 - val_loss: 0.8686 - val_acc: 0.9130\n",
      "Epoch 154/200\n",
      "44/44 [==============================] - 0s 591us/step - loss: 0.0796 - acc: 1.0000 - val_loss: 0.8857 - val_acc: 0.9130\n",
      "Epoch 155/200\n",
      "44/44 [==============================] - 0s 657us/step - loss: 0.0796 - acc: 1.0000 - val_loss: 0.8993 - val_acc: 0.9130\n",
      "Epoch 156/200\n",
      "44/44 [==============================] - 0s 773us/step - loss: 0.0791 - acc: 1.0000 - val_loss: 0.8984 - val_acc: 0.8696\n",
      "Epoch 157/200\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.0782 - acc: 1.0000 - val_loss: 0.8900 - val_acc: 0.8696\n",
      "Epoch 158/200\n",
      "44/44 [==============================] - 0s 704us/step - loss: 0.0782 - acc: 1.0000 - val_loss: 0.8799 - val_acc: 0.8696\n",
      "Epoch 159/200\n",
      "44/44 [==============================] - 0s 637us/step - loss: 0.0776 - acc: 1.0000 - val_loss: 0.8787 - val_acc: 0.8696\n",
      "Epoch 160/200\n",
      "44/44 [==============================] - 0s 682us/step - loss: 0.0772 - acc: 1.0000 - val_loss: 0.8847 - val_acc: 0.9130\n",
      "Epoch 161/200\n",
      "44/44 [==============================] - 0s 750us/step - loss: 0.0767 - acc: 1.0000 - val_loss: 0.8851 - val_acc: 0.9130\n",
      "Epoch 162/200\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.0762 - acc: 1.0000 - val_loss: 0.8858 - val_acc: 0.9130\n",
      "Epoch 163/200\n",
      "44/44 [==============================] - 0s 614us/step - loss: 0.0759 - acc: 1.0000 - val_loss: 0.8997 - val_acc: 0.9130\n",
      "Epoch 164/200\n",
      "44/44 [==============================] - 0s 704us/step - loss: 0.0761 - acc: 1.0000 - val_loss: 0.9039 - val_acc: 0.9130\n",
      "Epoch 165/200\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.0763 - acc: 1.0000 - val_loss: 0.8995 - val_acc: 0.9130\n",
      "Epoch 166/200\n",
      "44/44 [==============================] - 0s 864us/step - loss: 0.0756 - acc: 1.0000 - val_loss: 0.8907 - val_acc: 0.9130\n",
      "Epoch 167/200\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.0749 - acc: 1.0000 - val_loss: 0.8920 - val_acc: 0.9130\n",
      "Epoch 168/200\n",
      "44/44 [==============================] - 0s 614us/step - loss: 0.0744 - acc: 1.0000 - val_loss: 0.8960 - val_acc: 0.9130\n",
      "Epoch 169/200\n",
      "44/44 [==============================] - 0s 682us/step - loss: 0.0739 - acc: 1.0000 - val_loss: 0.9085 - val_acc: 0.9130\n",
      "Epoch 170/200\n",
      "44/44 [==============================] - 0s 636us/step - loss: 0.0735 - acc: 1.0000 - val_loss: 0.9165 - val_acc: 0.9130\n",
      "Epoch 171/200\n",
      "44/44 [==============================] - 0s 661us/step - loss: 0.0731 - acc: 1.0000 - val_loss: 0.9133 - val_acc: 0.8696\n",
      "Epoch 172/200\n",
      "44/44 [==============================] - 0s 728us/step - loss: 0.0724 - acc: 1.0000 - val_loss: 0.9056 - val_acc: 0.9130\n",
      "Epoch 173/200\n",
      "44/44 [==============================] - 0s 636us/step - loss: 0.0720 - acc: 1.0000 - val_loss: 0.8998 - val_acc: 0.9130\n",
      "Epoch 174/200\n",
      "44/44 [==============================] - 0s 636us/step - loss: 0.0719 - acc: 1.0000 - val_loss: 0.8970 - val_acc: 0.9130\n",
      "Epoch 175/200\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.0714 - acc: 1.0000 - val_loss: 0.8955 - val_acc: 0.9130\n",
      "Epoch 176/200\n",
      "44/44 [==============================] - 0s 789us/step - loss: 0.0710 - acc: 1.0000 - val_loss: 0.8947 - val_acc: 0.9130\n",
      "Epoch 177/200\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.0706 - acc: 1.0000 - val_loss: 0.8907 - val_acc: 0.9130\n",
      "Epoch 178/200\n",
      "44/44 [==============================] - 0s 682us/step - loss: 0.0703 - acc: 1.0000 - val_loss: 0.8833 - val_acc: 0.9130\n",
      "Epoch 179/200\n",
      "44/44 [==============================] - 0s 727us/step - loss: 0.0700 - acc: 1.0000 - val_loss: 0.8788 - val_acc: 0.9130\n",
      "Epoch 180/200\n",
      "44/44 [==============================] - 0s 705us/step - loss: 0.0698 - acc: 1.0000 - val_loss: 0.8763 - val_acc: 0.9130\n",
      "Epoch 181/200\n",
      "44/44 [==============================] - 0s 750us/step - loss: 0.0694 - acc: 1.0000 - val_loss: 0.8760 - val_acc: 0.9130\n",
      "Epoch 182/200\n",
      "44/44 [==============================] - 0s 704us/step - loss: 0.0692 - acc: 1.0000 - val_loss: 0.8711 - val_acc: 0.9130\n",
      "Epoch 183/200\n",
      "44/44 [==============================] - 0s 682us/step - loss: 0.0689 - acc: 1.0000 - val_loss: 0.8734 - val_acc: 0.9130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/200\n",
      "44/44 [==============================] - 0s 682us/step - loss: 0.0686 - acc: 1.0000 - val_loss: 0.8828 - val_acc: 0.9130\n",
      "Epoch 185/200\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.0688 - acc: 1.0000 - val_loss: 0.8955 - val_acc: 0.9130\n",
      "Epoch 186/200\n",
      "44/44 [==============================] - 0s 682us/step - loss: 0.0692 - acc: 1.0000 - val_loss: 0.9110 - val_acc: 0.8696\n",
      "Epoch 187/200\n",
      "44/44 [==============================] - 0s 709us/step - loss: 0.0691 - acc: 1.0000 - val_loss: 0.9169 - val_acc: 0.8696\n",
      "Epoch 188/200\n",
      "44/44 [==============================] - 0s 682us/step - loss: 0.0688 - acc: 1.0000 - val_loss: 0.9133 - val_acc: 0.8696\n",
      "Epoch 189/200\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.0681 - acc: 1.0000 - val_loss: 0.9067 - val_acc: 0.9130\n",
      "Epoch 190/200\n",
      "44/44 [==============================] - 0s 636us/step - loss: 0.0675 - acc: 1.0000 - val_loss: 0.9007 - val_acc: 0.9130\n",
      "Epoch 191/200\n",
      "44/44 [==============================] - 0s 729us/step - loss: 0.0672 - acc: 1.0000 - val_loss: 0.8931 - val_acc: 0.9130\n",
      "Epoch 192/200\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.0669 - acc: 1.0000 - val_loss: 0.8922 - val_acc: 0.9130\n",
      "Epoch 193/200\n",
      "44/44 [==============================] - 0s 746us/step - loss: 0.0665 - acc: 1.0000 - val_loss: 0.8917 - val_acc: 0.9130\n",
      "Epoch 194/200\n",
      "44/44 [==============================] - 0s 636us/step - loss: 0.0662 - acc: 1.0000 - val_loss: 0.8879 - val_acc: 0.9130\n",
      "Epoch 195/200\n",
      "44/44 [==============================] - 0s 636us/step - loss: 0.0659 - acc: 1.0000 - val_loss: 0.8827 - val_acc: 0.9130\n",
      "Epoch 196/200\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.0656 - acc: 1.0000 - val_loss: 0.8768 - val_acc: 0.9130\n",
      "Epoch 197/200\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.0657 - acc: 1.0000 - val_loss: 0.8791 - val_acc: 0.9130\n",
      "Epoch 198/200\n",
      "44/44 [==============================] - 0s 614us/step - loss: 0.0654 - acc: 1.0000 - val_loss: 0.8801 - val_acc: 0.9130\n",
      "Epoch 199/200\n",
      "44/44 [==============================] - 0s 682us/step - loss: 0.0651 - acc: 1.0000 - val_loss: 0.8819 - val_acc: 0.9130\n",
      "Epoch 200/200\n",
      "44/44 [==============================] - 0s 727us/step - loss: 0.0648 - acc: 1.0000 - val_loss: 0.8839 - val_acc: 0.9130\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 200\n",
    "BATCH_SIZE = 20\n",
    "callbacks = [ EarlyStopping(monitor=\"loss\", patience=10, min_delta=0.0) ]\n",
    "\n",
    "evaluation = model.fit(x_t_c, y_t, shuffle=True,\n",
    "                        epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1,\n",
    "                        validation_data = (x_v_c, y_v),\n",
    "                        callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      1.00      0.95        21\n",
      "        1.0       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.83      0.91      0.87        23\n",
      "\n",
      "[[21  0]\n",
      " [ 2  0]]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "v_p_kc = model.predict(x_v_c)\n",
    "v_p_kc = [1.0 if v  >= 0.5 else 0.0 for v in v_p_kc]\n",
    "print(classification_report(y_v.flatten(), v_p_kc))\n",
    "print(confusion_matrix(y_v.flatten(), v_p_kc))\n",
    "print(v_p_kc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_p_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
