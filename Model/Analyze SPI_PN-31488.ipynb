{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Data for Quality and get preliminary Results\n",
    "\n",
    "We test for validation of columns, quantity and quality of data points, ability to arrange data points such that analysis can be done via machine learning.\n",
    "\n",
    "## Important Notes\n",
    "This is not production quality code.  Code here is exploratory analytics code which needs to be wrapped up into proper functions as data differences and issues/exceptions are discovered.  This code can serve as reference for production code, but should not ever be treated as production code.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Key Libraries Required\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define data location & load data.\n",
    "base_dir = \"C:/Users/vmadmin/Documents/Work/spi/dataspi/\"\n",
    "good_file = \"GOOD_aug27_redo.csv\"\n",
    "bad_file = \"L7SPIresults_Defects_ONLY_query-impala-39690.csv\"\n",
    "\n",
    "good = pd.read_csv(base_dir + good_file)\n",
    "bad = pd.read_csv(base_dir + bad_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plcng_plant_cd</th>\n",
       "      <th>mach_id</th>\n",
       "      <th>pcb_side_inspd</th>\n",
       "      <th>wo_num</th>\n",
       "      <th>defct_dttm</th>\n",
       "      <th>intrvl_key</th>\n",
       "      <th>plcng_area_cd</th>\n",
       "      <th>plcng_prcs_cd</th>\n",
       "      <th>plcng_wrk_ctr_cd</th>\n",
       "      <th>fndng_plant_cd</th>\n",
       "      <th>...</th>\n",
       "      <th>pad_stncl_hgt</th>\n",
       "      <th>pad_spi_result</th>\n",
       "      <th>pad_spi_defct_type</th>\n",
       "      <th>solder_paste_vol_pct</th>\n",
       "      <th>solder_paste_hgt</th>\n",
       "      <th>solder_paste_area_pct</th>\n",
       "      <th>cmpnt_part_num</th>\n",
       "      <th>pkg_type</th>\n",
       "      <th>stncl_surf_area_ratio</th>\n",
       "      <th>extract_dttm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>127</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>113.5076</td>\n",
       "      <td>153.6871</td>\n",
       "      <td>93.79748</td>\n",
       "      <td>PN-27795-U5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>8/28/2018 2:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>127</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>105.2033</td>\n",
       "      <td>137.0668</td>\n",
       "      <td>97.47670</td>\n",
       "      <td>PN-27795-U5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>8/28/2018 2:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>127</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>106.6394</td>\n",
       "      <td>163.5016</td>\n",
       "      <td>82.83224</td>\n",
       "      <td>PN-27795-U5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>8/28/2018 2:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>127</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>113.9531</td>\n",
       "      <td>148.7802</td>\n",
       "      <td>97.27131</td>\n",
       "      <td>PN-27795-U5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>8/28/2018 2:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>127</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>110.2563</td>\n",
       "      <td>148.6627</td>\n",
       "      <td>94.19012</td>\n",
       "      <td>PN-27795-U5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>8/28/2018 2:54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   plcng_plant_cd  mach_id  pcb_side_inspd  wo_num  defct_dttm  intrvl_key  \\\n",
       "0             NaN      NaN             NaN     NaN         NaN         NaN   \n",
       "1             NaN      NaN             NaN     NaN         NaN         NaN   \n",
       "2             NaN      NaN             NaN     NaN         NaN         NaN   \n",
       "3             NaN      NaN             NaN     NaN         NaN         NaN   \n",
       "4             NaN      NaN             NaN     NaN         NaN         NaN   \n",
       "\n",
       "   plcng_area_cd  plcng_prcs_cd  plcng_wrk_ctr_cd  fndng_plant_cd  \\\n",
       "0            NaN            NaN               NaN             NaN   \n",
       "1            NaN            NaN               NaN             NaN   \n",
       "2            NaN            NaN               NaN             NaN   \n",
       "3            NaN            NaN               NaN             NaN   \n",
       "4            NaN            NaN               NaN             NaN   \n",
       "\n",
       "        ...        pad_stncl_hgt  pad_spi_result  pad_spi_defct_type  \\\n",
       "0       ...                  127            GOOD                GOOD   \n",
       "1       ...                  127            GOOD                GOOD   \n",
       "2       ...                  127            GOOD                GOOD   \n",
       "3       ...                  127            GOOD                GOOD   \n",
       "4       ...                  127            GOOD                GOOD   \n",
       "\n",
       "   solder_paste_vol_pct solder_paste_hgt  solder_paste_area_pct  \\\n",
       "0              113.5076         153.6871               93.79748   \n",
       "1              105.2033         137.0668               97.47670   \n",
       "2              106.6394         163.5016               82.83224   \n",
       "3              113.9531         148.7802               97.27131   \n",
       "4              110.2563         148.6627               94.19012   \n",
       "\n",
       "   cmpnt_part_num  pkg_type  stncl_surf_area_ratio    extract_dttm  \n",
       "0     PN-27795-U5         0                 0.9055  8/28/2018 2:54  \n",
       "1     PN-27795-U5         0                 0.9055  8/28/2018 2:54  \n",
       "2     PN-27795-U5         0                 0.9055  8/28/2018 2:54  \n",
       "3     PN-27795-U5         0                 0.9055  8/28/2018 2:54  \n",
       "4     PN-27795-U5         0                 0.9055  8/28/2018 2:54  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get a feel for what is in the data.\n",
    "good.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plcng_plant_cd</th>\n",
       "      <th>mach_id</th>\n",
       "      <th>pcb_side_inspd</th>\n",
       "      <th>wo_num</th>\n",
       "      <th>defct_dttm</th>\n",
       "      <th>intrvl_key</th>\n",
       "      <th>plcng_area_cd</th>\n",
       "      <th>plcng_prcs_cd</th>\n",
       "      <th>plcng_wrk_ctr_cd</th>\n",
       "      <th>fndng_plant_cd</th>\n",
       "      <th>...</th>\n",
       "      <th>solder_paste_offst_y_axis</th>\n",
       "      <th>pad_stncl_hgt</th>\n",
       "      <th>pad_spi_result</th>\n",
       "      <th>pad_spi_defct_type</th>\n",
       "      <th>solder_paste_vol_pct</th>\n",
       "      <th>solder_paste_hgt</th>\n",
       "      <th>solder_paste_area_pct</th>\n",
       "      <th>pkg_type</th>\n",
       "      <th>stncl_surf_area_ratio</th>\n",
       "      <th>extract_dttm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1020</td>\n",
       "      <td>FP9</td>\n",
       "      <td>TOP</td>\n",
       "      <td>4009351183</td>\n",
       "      <td>6/24/2018 15:56</td>\n",
       "      <td>1529855100</td>\n",
       "      <td>TWB_SM3</td>\n",
       "      <td>TWB_PCBA_SM3_TOP_FP</td>\n",
       "      <td>TWB_PCBA_TOP_FP9</td>\n",
       "      <td>1020</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.45</td>\n",
       "      <td>127</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>127.3716</td>\n",
       "      <td>165.5654</td>\n",
       "      <td>97.70272</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>7/4/2018 13:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1020</td>\n",
       "      <td>FP9</td>\n",
       "      <td>TOP</td>\n",
       "      <td>4009376503</td>\n",
       "      <td>7/3/2018 8:56</td>\n",
       "      <td>1530607500</td>\n",
       "      <td>TWB_SM3</td>\n",
       "      <td>TWB_PCBA_SM3_TOP_FP</td>\n",
       "      <td>TWB_PCBA_TOP_FP9</td>\n",
       "      <td>1020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.92</td>\n",
       "      <td>127</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>130.2810</td>\n",
       "      <td>159.0643</td>\n",
       "      <td>104.01890</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>7/4/2018 14:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1020</td>\n",
       "      <td>FP9</td>\n",
       "      <td>TOP</td>\n",
       "      <td>4009376503</td>\n",
       "      <td>7/3/2018 8:56</td>\n",
       "      <td>1530607500</td>\n",
       "      <td>TWB_SM3</td>\n",
       "      <td>TWB_PCBA_SM3_TOP_FP</td>\n",
       "      <td>TWB_PCBA_TOP_FP9</td>\n",
       "      <td>1020</td>\n",
       "      <td>...</td>\n",
       "      <td>4.82</td>\n",
       "      <td>127</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>132.1127</td>\n",
       "      <td>160.2906</td>\n",
       "      <td>104.67440</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>7/4/2018 14:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1020</td>\n",
       "      <td>FP9</td>\n",
       "      <td>TOP</td>\n",
       "      <td>4009376503</td>\n",
       "      <td>7/6/2018 14:51</td>\n",
       "      <td>1530888300</td>\n",
       "      <td>TWB_SM3</td>\n",
       "      <td>TWB_PCBA_SM3_TOP_FP</td>\n",
       "      <td>TWB_PCBA_TOP_FP9</td>\n",
       "      <td>1020</td>\n",
       "      <td>...</td>\n",
       "      <td>1.51</td>\n",
       "      <td>127</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>130.4016</td>\n",
       "      <td>170.2945</td>\n",
       "      <td>97.24921</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>7/4/2018 14:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1020</td>\n",
       "      <td>FP9</td>\n",
       "      <td>TOP</td>\n",
       "      <td>4009376503</td>\n",
       "      <td>7/6/2018 14:51</td>\n",
       "      <td>1530888300</td>\n",
       "      <td>TWB_SM3</td>\n",
       "      <td>TWB_PCBA_SM3_TOP_FP</td>\n",
       "      <td>TWB_PCBA_TOP_FP9</td>\n",
       "      <td>1020</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.27</td>\n",
       "      <td>127</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>123.9029</td>\n",
       "      <td>166.4613</td>\n",
       "      <td>94.53050</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>7/4/2018 14:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   plcng_plant_cd mach_id pcb_side_inspd      wo_num       defct_dttm  \\\n",
       "0            1020     FP9            TOP  4009351183  6/24/2018 15:56   \n",
       "1            1020     FP9            TOP  4009376503    7/3/2018 8:56   \n",
       "2            1020     FP9            TOP  4009376503    7/3/2018 8:56   \n",
       "3            1020     FP9            TOP  4009376503   7/6/2018 14:51   \n",
       "4            1020     FP9            TOP  4009376503   7/6/2018 14:51   \n",
       "\n",
       "   intrvl_key plcng_area_cd        plcng_prcs_cd  plcng_wrk_ctr_cd  \\\n",
       "0  1529855100       TWB_SM3  TWB_PCBA_SM3_TOP_FP  TWB_PCBA_TOP_FP9   \n",
       "1  1530607500       TWB_SM3  TWB_PCBA_SM3_TOP_FP  TWB_PCBA_TOP_FP9   \n",
       "2  1530607500       TWB_SM3  TWB_PCBA_SM3_TOP_FP  TWB_PCBA_TOP_FP9   \n",
       "3  1530888300       TWB_SM3  TWB_PCBA_SM3_TOP_FP  TWB_PCBA_TOP_FP9   \n",
       "4  1530888300       TWB_SM3  TWB_PCBA_SM3_TOP_FP  TWB_PCBA_TOP_FP9   \n",
       "\n",
       "   fndng_plant_cd       ...       solder_paste_offst_y_axis pad_stncl_hgt  \\\n",
       "0            1020       ...                          -11.45           127   \n",
       "1            1020       ...                            0.92           127   \n",
       "2            1020       ...                            4.82           127   \n",
       "3            1020       ...                            1.51           127   \n",
       "4            1020       ...                           -2.27           127   \n",
       "\n",
       "  pad_spi_result pad_spi_defct_type solder_paste_vol_pct solder_paste_hgt  \\\n",
       "0           GOOD               GOOD             127.3716         165.5654   \n",
       "1           GOOD               GOOD             130.2810         159.0643   \n",
       "2           GOOD               GOOD             132.1127         160.2906   \n",
       "3           GOOD               GOOD             130.4016         170.2945   \n",
       "4           GOOD               GOOD             123.9029         166.4613   \n",
       "\n",
       "  solder_paste_area_pct pkg_type stncl_surf_area_ratio    extract_dttm  \n",
       "0              97.70272        0                0.9055  7/4/2018 13:15  \n",
       "1             104.01890        0                0.9055  7/4/2018 14:17  \n",
       "2             104.67440        0                0.9055  7/4/2018 14:17  \n",
       "3              97.24921        0                0.9055  7/4/2018 14:19  \n",
       "4              94.53050        0                0.9055  7/4/2018 14:19  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get a feel for what is in the bad data\n",
    "bad.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89094, 39)\n",
      "(33700, 38)\n"
     ]
    }
   ],
   "source": [
    "#How many good/ bad do we have (pins)\n",
    "print(good.shape)\n",
    "print(bad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plcng_plant_cd' 'mach_id' 'pcb_side_inspd' 'wo_num' 'defct_dttm'\n",
      " 'intrvl_key' 'plcng_area_cd' 'plcng_prcs_cd' 'plcng_wrk_ctr_cd'\n",
      " 'fndng_plant_cd' 'fndng_area_cd' 'fndng_prcs_cd' 'bld_part_no'\n",
      " 'bld_serial_no' 'barcd' 'assy_part_no' 'assy_serial_no' 'defct_cd'\n",
      " 'failed_test_code' 'fail_type' 'cmpnt_part_no' 'spi_test_id' 'ref_id'\n",
      " 'silkscrn_nbr' 'cmpntpin_nbr' 'cmpntpin_size_x_axis'\n",
      " 'cmpntpin_size_y_axis' 'solder_paste_offst_x_axis'\n",
      " 'solder_paste_offst_y_axis' 'pad_stncl_hgt' 'pad_spi_result'\n",
      " 'pad_spi_defct_type' 'solder_paste_vol_pct' 'solder_paste_hgt'\n",
      " 'solder_paste_area_pct' 'cmpnt_part_num' 'pkg_type'\n",
      " 'stncl_surf_area_ratio' 'extract_dttm']\n",
      "['cmpnt_part_num']\n"
     ]
    }
   ],
   "source": [
    "# See what full list of columns are and if there is a difference in columns between the two\n",
    "print(good.columns.values)\n",
    "print(list(set(good) - set(bad)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cmpnt_part_num']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(good) - set(bad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(x):\n",
    "    r = x.split(\"-\") \n",
    "    if(len(r) > 2):\n",
    "        x = '-'.join(r[0:1])\n",
    "    return x\n",
    "bad[\"cmpnt_part_no\"] = bad[\"cmpnt_part_no\"].apply(lambda x: combine(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'00F5DA97', '00F4B3F9', '00F15667', '00F11AD9', '00F11AED', '00F40BC9', '00F11D43', '00F39057', '00F5D9D9', '00F11BC5', '00F7DED8', '00F6F799', '00F11A77', '00F0B7F2', '00F409A1', '00F75C74', '00F45F61', '00F38E59', '00F01584', '00F87339', '00F7C0F9', '00F2970E', '00F75A7E', '00F11909', '00F01822', '00F5FD84', '00F407CF', '00F08C10', '00F5D9D5', '00F75A04', '00F5DB75', '00F21545', '00F5FD50', '00F11D75', '00F87323', '00F11F8B', '00F7C38B', '00F75A1C', '00F69D9F', '00F296AA', '00F6F87D', '00F0BA04', '00F01806', '00F11ADD', '00F11B29', '00F6F7DB', '00F29AA2', '00F29584', '00F29A28', '00F019A4', '00F75C6A', '00F4B2FB', '00F0B9F4', '00F4B5DF', '00F40CAB', '00F11B0D', '00F40B13', '00F151BF', '00F0B9E8', '00F01554', '00F40F3D', '00F4B44F', '00F0B986', '00F11F71', '00F11C41', '00F11905', '00F7C00F', '00F015C0', '00F40F19', '00F7DE52', '00F407D7', '00F75A70', '00F15471', '00F872D1', '00F15277', '00F86E67', '00F7C077', '00F40B7D', '00F87211', '00F11851', '00F38C71', '00F7BBA3', '00F11BE7', '00F11AC7', '00F7BA65', '00F7C4BD', '00F29678', '00F1562B'}\n",
      "{1, 2}\n",
      "{'U25', 'U20', 'U13', 'U5', 'U6', 'U11', 'U12', 'U26', 'U23', 'U4'}\n",
      "{'PN-31488', 'PN', 'PN-271803', 'PN-419257', 'PN-29537', 'PN-27724', '94474092', 'PN-27795'}\n"
     ]
    }
   ],
   "source": [
    "print(set(bad[\"barcd\"]))\n",
    "print(set(bad[\"silkscrn_nbr\"]))\n",
    "print(set(bad[\"ref_id\"]))\n",
    "print(set(bad[\"cmpnt_part_no\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Bad Data and Get Data Counts For Each Component\n",
    "\n",
    "We need to get a feel for how much data we actually have and which components we have a decent shot of dealing with using standard machine learning approaches.\n",
    "\n",
    "It is possible to solve all components using non standard approaches; however deeper analysis will need to be done to validate the approaches which could be applied.  This should be done both at a theoretical and practical level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This looks at bad currently.  For good I need to change first groupby to use \"cmpnt_part_num not \"cmpnt_part_no\".\n",
    "bad_vals = []\n",
    "for k, v in bad.groupby(\"cmpnt_part_no\"):\n",
    "    for k, v1 in v.groupby(\"barcd\"):\n",
    "        for k, v2 in v1.groupby(\"silkscrn_nbr\"):\n",
    "            for k, v3 in v2.groupby(\"ref_id\"):\n",
    "                for k, v4 in v3.groupby(\"defct_dttm\"):\n",
    "                    vals = v4.sort_values(\"cmpntpin_nbr\")[[\"solder_paste_offst_x_axis\", \n",
    "                                                       \"solder_paste_offst_y_axis\", \n",
    "                                                       \"solder_paste_vol_pct\",\n",
    "                                                       \"solder_paste_hgt\",\n",
    "                                                       \"solder_paste_area_pct\",\n",
    "                                                        \"ref_id\",\n",
    "                                                        \"cmpntpin_nbr\",\n",
    "                                                        \"cmpnt_part_no\"]]\n",
    "                    addition = {\"defect\" : True, \"pin_data\" : vals, \n",
    "                                \"ref_id\" : list(set(v4[\"ref_id\"]))[0],\n",
    "                               \"cmpnt_part_no\" : list(set(v4[\"cmpnt_part_no\"]))[0]}\n",
    "                    bad_vals.append(addition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref id: PN-31488 count: 23\n",
      "ref id: PN count: 3\n",
      "ref id: PN-271803 count: 10\n",
      "ref id: PN-419257 count: 27\n",
      "ref id: PN-29537 count: 6\n",
      "ref id: PN-27724 count: 27\n",
      "ref id: 94474092 count: 31\n",
      "ref id: PN-27795 count: 34\n"
     ]
    }
   ],
   "source": [
    "ref_ids = list(set(bad[\"cmpnt_part_no\"]))\n",
    "for ref_id in ref_ids:\n",
    "    num_ids = len([x for x in bad_vals if x[\"cmpnt_part_no\"] == ref_id])\n",
    "    print(\"ref id: {} count: {}\".format(ref_id, num_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Good Data and Get Data Counts For Each Component\n",
    "\n",
    "We need to get a feel for how much data we actually have and which components we have a decent shot of dealing with using standard machine learning approaches.\n",
    "\n",
    "It is possible to solve all components using non standard approaches; however deeper analysis will need to be done to validate the approaches which could be applied.  This should be done both at a theoretical and practical level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This looks at bad currently.  For good I need to change first groupby to use \"cmpnt_part_num not \"cmpnt_part_no\".\n",
    "#good[\"cmpnt_part_num\"] = good[\"cmpnt_part_num\"].apply(lambda x: combine(x))\n",
    "good_vals = []\n",
    "for k, v in good.groupby(\"cmpnt_part_num\"):\n",
    "    for k, v1 in v.groupby(\"barcd\"):\n",
    "        for k, v2 in v1.groupby(\"silkscrn_nbr\"):\n",
    "            for k, v3 in v2.groupby(\"ref_id\"):\n",
    "                for k, v4 in v3.groupby(\"spi_test_id\"):\n",
    "                    vals = v4.sort_values(\"cmpntpin_nbr\")[[\"solder_paste_offst_x_axis\", \n",
    "                                                       \"solder_paste_offst_y_axis\", \n",
    "                                                       \"solder_paste_vol_pct\",\n",
    "                                                       \"solder_paste_hgt\",\n",
    "                                                       \"solder_paste_area_pct\",\n",
    "                                                        \"ref_id\",\n",
    "                                                        \"cmpntpin_nbr\",\n",
    "                                                        \"cmpnt_part_num\"]]\n",
    "                    addition = {\"defect\" : False, \"pin_data\" : vals, \n",
    "                                \"ref_id\" : list(set(v4[\"ref_id\"]))[0],\n",
    "                               \"cmpnt_part_num\" : list(set(v4[\"cmpnt_part_num\"]))[0]}\n",
    "                    good_vals.append(addition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref id: PN-27795-U5 count: 62\n",
      "ref id: PN-271803 count: 186\n",
      "ref id: PN-27724 count: 62\n",
      "ref id: 94474092 count: 62\n",
      "ref id: PN-31488-U6 count: 62\n",
      "ref id: 94485092 count: 186\n"
     ]
    }
   ],
   "source": [
    "ref_ids = list(set(good[\"cmpnt_part_num\"]))\n",
    "for ref_id in ref_ids:\n",
    "    num_ids = len([x for x in good_vals if x[\"cmpnt_part_num\"] == ref_id])\n",
    "    print(\"ref id: {} count: {}\".format(ref_id, num_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Section - Get Numpy Arrays for what I Need\n",
    "\n",
    "This section is about extracting the numpy arrays for what we need and dealing with encoding stuff to numerical features if necessary.\n",
    "\n",
    "We are focusing on component PN-27795 which exists ONLY for ref_id U5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "good_27795 = [x for x in good_vals if x[\"cmpnt_part_num\"] == 'PN-31488-U6']\n",
    "bad_27795 = [x for x in bad_vals if x[\"cmpnt_part_no\"] == 'PN-31488']\n",
    "\n",
    "print(len(good_27795))\n",
    "print(len(bad_27795))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(721,)\n",
      "(721,)\n"
     ]
    }
   ],
   "source": [
    "row_1 = good_27795[0][\"pin_data\"][[\"solder_paste_offst_x_axis\", \n",
    "                                                       \"solder_paste_offst_y_axis\", \n",
    "                                                       \"solder_paste_vol_pct\",\n",
    "                                                       \"solder_paste_hgt\",\n",
    "                                                       \"solder_paste_area_pct\"]].values.flatten()\n",
    "row_1 = np.append(row_1, [0])\n",
    "print(row_1.shape)\n",
    "row_2 = good_27795[1][\"pin_data\"][[\"solder_paste_offst_x_axis\", \n",
    "                                                       \"solder_paste_offst_y_axis\", \n",
    "                                                       \"solder_paste_vol_pct\",\n",
    "                                                       \"solder_paste_hgt\",\n",
    "                                                       \"solder_paste_area_pct\"]].values.flatten()\n",
    "row_2 = np.append(row_2, [0])\n",
    "print(row_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = np.vstack([row_1, row_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(721,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 721)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to Data Shapes for Training\n",
    "\n",
    "We will convert the good & bad to data shapes required for training and then do a train/test split to prep for a simplistic keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ml_data(row, is_good):\n",
    "    prep = row[\"pin_data\"][[\"solder_paste_offst_x_axis\", \n",
    "                            \"solder_paste_offst_y_axis\", \n",
    "                            \"solder_paste_vol_pct\",\n",
    "                            \"solder_paste_hgt\",\n",
    "                            \"solder_paste_area_pct\"]].values.flatten()\n",
    "    if(is_good):\n",
    "        prep = np.append(prep, [0.0])\n",
    "    else:\n",
    "        prep = np.append(prep, [1.0])\n",
    "    return prep\n",
    "\n",
    "good_complete_data = get_ml_data(good_27795.pop(0), is_good=True)\n",
    "for data in good_27795:\n",
    "    good_complete_data = np.vstack([good_complete_data, get_ml_data(data, is_good=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62, 721)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_complete_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_complete_data = get_ml_data(bad_27795.pop(0), is_good=False)\n",
    "for data in bad_27795:\n",
    "    bad_complete_data = np.vstack([bad_complete_data, get_ml_data(data, is_good=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 721)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_complete_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 720 into shape (16,16,5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-a77baf79e648>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbad_complete_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 720 into shape (16,16,5)"
     ]
    }
   ],
   "source": [
    "bad_complete_data[0][:-1].reshape(16,16,5)[:][:][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85, 721)\n"
     ]
    }
   ],
   "source": [
    "full_data = np.append(bad_complete_data, good_complete_data, axis=0)\n",
    "print(full_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85, 720)\n",
      "(85, 1)\n"
     ]
    }
   ],
   "source": [
    "#verify sizes for x vs y to extract input vs output.  Last column is the output or y value.\n",
    "print(full_data[:,:-1].shape)\n",
    "print(full_data[:,-1:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prep for ml learning\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 720)\n",
      "(56, 1)\n",
      "(29, 720)\n",
      "(29, 1)\n"
     ]
    }
   ],
   "source": [
    "x_t, x_v, y_t, y_v = train_test_split(full_data[:,:-1], full_data[:,-1:], test_size = 0.33)\n",
    "print(x_t.shape)\n",
    "print(y_t.shape)\n",
    "print(x_v.shape)\n",
    "print(y_v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_t_scaled = scaler.fit_transform(x_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.31337709 -0.30313041 -0.09266099 ... -1.10414683 -1.29136234\n",
      "   0.33061958]\n",
      " [ 0.3285854  -0.43329485  0.36105841 ...  1.14876949  1.07692813\n",
      "  -0.02219478]\n",
      " [ 0.40852304 -0.66573136  2.03891292 ... -0.44896437 -0.95437772\n",
      "   0.72819177]\n",
      " ...\n",
      " [ 0.85142082  0.05017308 -1.45525708 ...  0.56721445  0.88716964\n",
      "  -0.47198996]\n",
      " [-0.89424456 -0.19899885 -1.02118184 ... -1.19606115 -1.02026245\n",
      "  -0.19668421]\n",
      " [ 0.14926581 -0.02606609  0.28954961 ...  1.43380655  1.11105853\n",
      "   0.26706978]]\n",
      "[[-6.520000e+00 -6.600000e-01  1.099250e+02 ...  1.117072e+02\n",
      "   1.414439e+02  1.003000e+02]\n",
      " [ 1.080000e+00 -1.360000e+00  1.121654e+02 ...  1.318994e+02\n",
      "   1.704487e+02  9.827721e+01]\n",
      " [ 1.450000e+00 -2.610000e+00  1.204504e+02 ...  1.175794e+02\n",
      "   1.455710e+02  1.025794e+02]\n",
      " ...\n",
      " [ 3.500000e+00  1.240000e+00  1.031967e+02 ...  1.266871e+02\n",
      "   1.681247e+02  9.569840e+01]\n",
      " [-4.580000e+00 -1.000000e-01  1.053401e+02 ...  1.108834e+02\n",
      "   1.447641e+02  9.727681e+01]\n",
      " [ 2.500000e-01  8.300000e-01  1.118123e+02 ...  1.344541e+02\n",
      "   1.708667e+02  9.993565e+01]]\n",
      "[0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "x_v_scaled = scaler.transform(x_v)\n",
    "print(x_v_scaled)\n",
    "print(x_v)\n",
    "print(y_v.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical Machine Learning\n",
    "\n",
    "Lets set a benchmark with classical machine learning from scikit.  We should see some level of performance from this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC()\n",
    "svm.fit(x_t_scaled, y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_p = svm.predict(x_v_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.69      1.00      0.82        20\n",
      "        1.0       0.00      0.00      0.00         9\n",
      "\n",
      "avg / total       0.48      0.69      0.56        29\n",
      "\n",
      "[[20  0]\n",
      " [ 9  0]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_v.flatten(), v_p))\n",
    "print(confusion_matrix(y_v.flatten(), v_p))\n",
    "print(v_p.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try a Random Forest Classifier\n",
    "\n",
    "Just another model to give a whirl at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(x_t_scaled, y_t)\n",
    "v_p = rfc.predict(x_v_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.95      0.86        20\n",
      "        1.0       0.80      0.44      0.57         9\n",
      "\n",
      "avg / total       0.79      0.79      0.77        29\n",
      "\n",
      "[[19  1]\n",
      " [ 5  4]]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_v.flatten(), v_p))\n",
    "print(confusion_matrix(y_v.flatten(), v_p))\n",
    "print(v_p.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Dense Neural Network\n",
    "\n",
    "Lets give a shot at a dense neural network and see if we can get any decent results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers import Input, Dense, Dropout, Conv2D, Flatten, MaxPooling2D\n",
    "from keras.regularizers import L1L2\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 720)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 56 samples, validate on 29 samples\n",
      "Epoch 1/100\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 5.8827 - binary_accuracy: 0.5893 - val_loss: 5.7611 - val_binary_accuracy: 0.6207\n",
      "Epoch 2/100\n",
      "56/56 [==============================] - 0s 232us/step - loss: 5.5165 - binary_accuracy: 0.8393 - val_loss: 5.6075 - val_binary_accuracy: 0.6552\n",
      "Epoch 3/100\n",
      "56/56 [==============================] - 0s 214us/step - loss: 5.2842 - binary_accuracy: 0.9464 - val_loss: 5.4727 - val_binary_accuracy: 0.7931\n",
      "Epoch 4/100\n",
      "56/56 [==============================] - 0s 230us/step - loss: 5.1255 - binary_accuracy: 0.9821 - val_loss: 5.3379 - val_binary_accuracy: 0.8276\n",
      "Epoch 5/100\n",
      "56/56 [==============================] - 0s 286us/step - loss: 4.9644 - binary_accuracy: 1.0000 - val_loss: 5.2050 - val_binary_accuracy: 0.8276\n",
      "Epoch 6/100\n",
      "56/56 [==============================] - 0s 322us/step - loss: 4.8054 - binary_accuracy: 1.0000 - val_loss: 5.0918 - val_binary_accuracy: 0.7586\n",
      "Epoch 7/100\n",
      "56/56 [==============================] - 0s 269us/step - loss: 4.6518 - binary_accuracy: 1.0000 - val_loss: 4.9666 - val_binary_accuracy: 0.7931\n",
      "Epoch 8/100\n",
      "56/56 [==============================] - 0s 371us/step - loss: 4.4982 - binary_accuracy: 1.0000 - val_loss: 4.8475 - val_binary_accuracy: 0.7931\n",
      "Epoch 9/100\n",
      "56/56 [==============================] - 0s 232us/step - loss: 4.3476 - binary_accuracy: 1.0000 - val_loss: 4.7286 - val_binary_accuracy: 0.7931\n",
      "Epoch 10/100\n",
      "56/56 [==============================] - 0s 250us/step - loss: 4.1994 - binary_accuracy: 1.0000 - val_loss: 4.6132 - val_binary_accuracy: 0.7241\n",
      "Epoch 11/100\n",
      "56/56 [==============================] - 0s 286us/step - loss: 4.0517 - binary_accuracy: 1.0000 - val_loss: 4.4990 - val_binary_accuracy: 0.6897\n",
      "Epoch 12/100\n",
      "56/56 [==============================] - 0s 232us/step - loss: 3.9049 - binary_accuracy: 1.0000 - val_loss: 4.3708 - val_binary_accuracy: 0.6897\n",
      "Epoch 13/100\n",
      "56/56 [==============================] - 0s 268us/step - loss: 3.7587 - binary_accuracy: 1.0000 - val_loss: 4.2323 - val_binary_accuracy: 0.6897\n",
      "Epoch 14/100\n",
      "56/56 [==============================] - 0s 232us/step - loss: 3.6136 - binary_accuracy: 1.0000 - val_loss: 4.0915 - val_binary_accuracy: 0.7241\n",
      "Epoch 15/100\n",
      "56/56 [==============================] - 0s 250us/step - loss: 3.4698 - binary_accuracy: 1.0000 - val_loss: 3.9574 - val_binary_accuracy: 0.7241\n",
      "Epoch 16/100\n",
      "56/56 [==============================] - 0s 232us/step - loss: 3.3275 - binary_accuracy: 1.0000 - val_loss: 3.8370 - val_binary_accuracy: 0.6897\n",
      "Epoch 17/100\n",
      "56/56 [==============================] - 0s 268us/step - loss: 3.1880 - binary_accuracy: 1.0000 - val_loss: 3.7207 - val_binary_accuracy: 0.7241\n",
      "Epoch 18/100\n",
      "56/56 [==============================] - 0s 214us/step - loss: 3.0506 - binary_accuracy: 1.0000 - val_loss: 3.5904 - val_binary_accuracy: 0.7241\n",
      "Epoch 19/100\n",
      "56/56 [==============================] - 0s 214us/step - loss: 2.9158 - binary_accuracy: 1.0000 - val_loss: 3.4535 - val_binary_accuracy: 0.7241\n",
      "Epoch 20/100\n",
      "56/56 [==============================] - 0s 250us/step - loss: 2.7841 - binary_accuracy: 1.0000 - val_loss: 3.3221 - val_binary_accuracy: 0.7241\n",
      "Epoch 21/100\n",
      "56/56 [==============================] - 0s 251us/step - loss: 2.6555 - binary_accuracy: 1.0000 - val_loss: 3.2000 - val_binary_accuracy: 0.7241\n",
      "Epoch 22/100\n",
      "56/56 [==============================] - 0s 268us/step - loss: 2.5299 - binary_accuracy: 1.0000 - val_loss: 3.0977 - val_binary_accuracy: 0.7241\n",
      "Epoch 23/100\n",
      "56/56 [==============================] - 0s 268us/step - loss: 2.4078 - binary_accuracy: 1.0000 - val_loss: 2.9910 - val_binary_accuracy: 0.7241\n",
      "Epoch 24/100\n",
      "56/56 [==============================] - 0s 250us/step - loss: 2.2902 - binary_accuracy: 1.0000 - val_loss: 2.8729 - val_binary_accuracy: 0.7241\n",
      "Epoch 25/100\n",
      "56/56 [==============================] - 0s 268us/step - loss: 2.1769 - binary_accuracy: 1.0000 - val_loss: 2.7645 - val_binary_accuracy: 0.7586\n",
      "Epoch 26/100\n",
      "56/56 [==============================] - 0s 232us/step - loss: 2.0672 - binary_accuracy: 1.0000 - val_loss: 2.6784 - val_binary_accuracy: 0.7586\n",
      "Epoch 27/100\n",
      "56/56 [==============================] - 0s 193us/step - loss: 1.9621 - binary_accuracy: 1.0000 - val_loss: 2.5774 - val_binary_accuracy: 0.7586\n",
      "Epoch 28/100\n",
      "56/56 [==============================] - 0s 204us/step - loss: 1.8611 - binary_accuracy: 1.0000 - val_loss: 2.4708 - val_binary_accuracy: 0.7586\n",
      "Epoch 29/100\n",
      "56/56 [==============================] - 0s 205us/step - loss: 1.7648 - binary_accuracy: 1.0000 - val_loss: 2.3609 - val_binary_accuracy: 0.7931\n",
      "Epoch 30/100\n",
      "56/56 [==============================] - 0s 232us/step - loss: 1.6735 - binary_accuracy: 1.0000 - val_loss: 2.2728 - val_binary_accuracy: 0.7931\n",
      "Epoch 31/100\n",
      "56/56 [==============================] - 0s 214us/step - loss: 1.5859 - binary_accuracy: 1.0000 - val_loss: 2.2094 - val_binary_accuracy: 0.7586\n",
      "Epoch 32/100\n",
      "56/56 [==============================] - 0s 205us/step - loss: 1.5037 - binary_accuracy: 1.0000 - val_loss: 2.1224 - val_binary_accuracy: 0.7586\n",
      "Epoch 33/100\n",
      "56/56 [==============================] - 0s 196us/step - loss: 1.4257 - binary_accuracy: 1.0000 - val_loss: 2.0267 - val_binary_accuracy: 0.7931\n",
      "Epoch 34/100\n",
      "56/56 [==============================] - 0s 268us/step - loss: 1.3525 - binary_accuracy: 1.0000 - val_loss: 1.9645 - val_binary_accuracy: 0.7931\n",
      "Epoch 35/100\n",
      "56/56 [==============================] - 0s 304us/step - loss: 1.2833 - binary_accuracy: 1.0000 - val_loss: 1.9060 - val_binary_accuracy: 0.7586\n",
      "Epoch 36/100\n",
      "56/56 [==============================] - 0s 250us/step - loss: 1.2188 - binary_accuracy: 1.0000 - val_loss: 1.8245 - val_binary_accuracy: 0.7931\n",
      "Epoch 37/100\n",
      "56/56 [==============================] - 0s 196us/step - loss: 1.1584 - binary_accuracy: 1.0000 - val_loss: 1.7735 - val_binary_accuracy: 0.7586\n",
      "Epoch 38/100\n",
      "56/56 [==============================] - 0s 196us/step - loss: 1.1020 - binary_accuracy: 1.0000 - val_loss: 1.7372 - val_binary_accuracy: 0.7586\n",
      "Epoch 39/100\n",
      "56/56 [==============================] - 0s 214us/step - loss: 1.0491 - binary_accuracy: 1.0000 - val_loss: 1.6400 - val_binary_accuracy: 0.7931\n",
      "Epoch 40/100\n",
      "56/56 [==============================] - 0s 196us/step - loss: 0.9993 - binary_accuracy: 1.0000 - val_loss: 1.6377 - val_binary_accuracy: 0.7586\n",
      "Epoch 41/100\n",
      "56/56 [==============================] - 0s 214us/step - loss: 0.9541 - binary_accuracy: 1.0000 - val_loss: 1.5591 - val_binary_accuracy: 0.7931\n",
      "Epoch 42/100\n",
      "56/56 [==============================] - 0s 214us/step - loss: 0.9103 - binary_accuracy: 1.0000 - val_loss: 1.5084 - val_binary_accuracy: 0.7586\n",
      "Epoch 43/100\n",
      "56/56 [==============================] - 0s 214us/step - loss: 0.8720 - binary_accuracy: 1.0000 - val_loss: 1.5331 - val_binary_accuracy: 0.7931\n",
      "Epoch 44/100\n",
      "56/56 [==============================] - 0s 196us/step - loss: 0.8556 - binary_accuracy: 0.9821 - val_loss: 1.9450 - val_binary_accuracy: 0.6897\n",
      "Epoch 45/100\n",
      "56/56 [==============================] - 0s 266us/step - loss: 0.8885 - binary_accuracy: 0.9821 - val_loss: 1.6545 - val_binary_accuracy: 0.6897\n",
      "Epoch 46/100\n",
      "56/56 [==============================] - 0s 250us/step - loss: 0.8539 - binary_accuracy: 1.0000 - val_loss: 1.6143 - val_binary_accuracy: 0.7586\n",
      "Epoch 47/100\n",
      "56/56 [==============================] - 0s 232us/step - loss: 0.9332 - binary_accuracy: 0.9464 - val_loss: 1.7157 - val_binary_accuracy: 0.7241\n",
      "Epoch 48/100\n",
      "56/56 [==============================] - 0s 214us/step - loss: 0.9155 - binary_accuracy: 0.9643 - val_loss: 1.5587 - val_binary_accuracy: 0.7241\n",
      "Epoch 49/100\n",
      "56/56 [==============================] - 0s 340us/step - loss: 0.8262 - binary_accuracy: 0.9821 - val_loss: 1.5298 - val_binary_accuracy: 0.7586\n",
      "Epoch 50/100\n",
      "56/56 [==============================] - 0s 286us/step - loss: 0.8253 - binary_accuracy: 0.9821 - val_loss: 1.7856 - val_binary_accuracy: 0.6897\n",
      "Epoch 51/100\n",
      "56/56 [==============================] - 0s 339us/step - loss: 0.8243 - binary_accuracy: 0.9821 - val_loss: 1.4029 - val_binary_accuracy: 0.8276\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 250us/step - loss: 0.7690 - binary_accuracy: 1.0000 - val_loss: 1.4023 - val_binary_accuracy: 0.8621\n",
      "Epoch 53/100\n",
      "56/56 [==============================] - 0s 232us/step - loss: 0.7586 - binary_accuracy: 1.0000 - val_loss: 1.4450 - val_binary_accuracy: 0.8621\n",
      "Epoch 54/100\n",
      "56/56 [==============================] - 0s 196us/step - loss: 0.7464 - binary_accuracy: 1.0000 - val_loss: 1.4052 - val_binary_accuracy: 0.8276\n",
      "Epoch 55/100\n",
      "56/56 [==============================] - 0s 232us/step - loss: 0.7106 - binary_accuracy: 1.0000 - val_loss: 1.3502 - val_binary_accuracy: 0.8276\n",
      "Epoch 56/100\n",
      "56/56 [==============================] - 0s 250us/step - loss: 0.6847 - binary_accuracy: 1.0000 - val_loss: 1.2958 - val_binary_accuracy: 0.8276\n",
      "Epoch 57/100\n",
      "56/56 [==============================] - 0s 268us/step - loss: 0.6587 - binary_accuracy: 1.0000 - val_loss: 1.2506 - val_binary_accuracy: 0.8276\n",
      "Epoch 58/100\n",
      "56/56 [==============================] - 0s 304us/step - loss: 0.6338 - binary_accuracy: 1.0000 - val_loss: 1.2148 - val_binary_accuracy: 0.8621\n",
      "Epoch 59/100\n",
      "56/56 [==============================] - 0s 321us/step - loss: 0.6106 - binary_accuracy: 1.0000 - val_loss: 1.1849 - val_binary_accuracy: 0.8621\n",
      "Epoch 60/100\n",
      "56/56 [==============================] - 0s 210us/step - loss: 0.5893 - binary_accuracy: 1.0000 - val_loss: 1.1594 - val_binary_accuracy: 0.8621\n",
      "Epoch 61/100\n",
      "56/56 [==============================] - 0s 214us/step - loss: 0.5690 - binary_accuracy: 1.0000 - val_loss: 1.1391 - val_binary_accuracy: 0.8621\n",
      "Epoch 62/100\n",
      "56/56 [==============================] - 0s 196us/step - loss: 0.5497 - binary_accuracy: 1.0000 - val_loss: 1.1214 - val_binary_accuracy: 0.8621\n",
      "Epoch 63/100\n",
      "56/56 [==============================] - 0s 214us/step - loss: 0.5317 - binary_accuracy: 1.0000 - val_loss: 1.1048 - val_binary_accuracy: 0.8621\n",
      "Epoch 64/100\n",
      "56/56 [==============================] - 0s 179us/step - loss: 0.5147 - binary_accuracy: 1.0000 - val_loss: 1.0903 - val_binary_accuracy: 0.8621\n",
      "Epoch 65/100\n",
      "56/56 [==============================] - 0s 232us/step - loss: 0.4987 - binary_accuracy: 1.0000 - val_loss: 1.0747 - val_binary_accuracy: 0.8621\n",
      "Epoch 66/100\n",
      "56/56 [==============================] - 0s 304us/step - loss: 0.4835 - binary_accuracy: 1.0000 - val_loss: 1.0626 - val_binary_accuracy: 0.8276\n",
      "Epoch 67/100\n",
      "56/56 [==============================] - 0s 268us/step - loss: 0.4692 - binary_accuracy: 1.0000 - val_loss: 1.0501 - val_binary_accuracy: 0.8276\n",
      "Epoch 68/100\n",
      "56/56 [==============================] - 0s 197us/step - loss: 0.4558 - binary_accuracy: 1.0000 - val_loss: 1.0366 - val_binary_accuracy: 0.8276\n",
      "Epoch 69/100\n",
      "56/56 [==============================] - 0s 214us/step - loss: 0.4430 - binary_accuracy: 1.0000 - val_loss: 1.0261 - val_binary_accuracy: 0.8276\n",
      "Epoch 70/100\n",
      "56/56 [==============================] - 0s 214us/step - loss: 0.4309 - binary_accuracy: 1.0000 - val_loss: 1.0153 - val_binary_accuracy: 0.8276\n",
      "Epoch 71/100\n",
      "56/56 [==============================] - 0s 214us/step - loss: 0.4193 - binary_accuracy: 1.0000 - val_loss: 1.0065 - val_binary_accuracy: 0.8276\n",
      "Epoch 72/100\n",
      "56/56 [==============================] - 0s 210us/step - loss: 0.4084 - binary_accuracy: 1.0000 - val_loss: 0.9993 - val_binary_accuracy: 0.8276\n",
      "Epoch 73/100\n",
      "56/56 [==============================] - 0s 268us/step - loss: 0.3979 - binary_accuracy: 1.0000 - val_loss: 0.9975 - val_binary_accuracy: 0.8276\n",
      "Epoch 74/100\n",
      "56/56 [==============================] - 0s 214us/step - loss: 0.3879 - binary_accuracy: 1.0000 - val_loss: 0.9854 - val_binary_accuracy: 0.8276\n",
      "Epoch 75/100\n",
      "56/56 [==============================] - 0s 214us/step - loss: 0.3781 - binary_accuracy: 1.0000 - val_loss: 0.9829 - val_binary_accuracy: 0.8276\n",
      "Epoch 76/100\n",
      "56/56 [==============================] - 0s 214us/step - loss: 0.3691 - binary_accuracy: 1.0000 - val_loss: 0.9819 - val_binary_accuracy: 0.8276\n",
      "Epoch 77/100\n",
      "56/56 [==============================] - 0s 268us/step - loss: 0.3602 - binary_accuracy: 1.0000 - val_loss: 0.9711 - val_binary_accuracy: 0.8276\n",
      "Epoch 78/100\n",
      "56/56 [==============================] - 0s 268us/step - loss: 0.3517 - binary_accuracy: 1.0000 - val_loss: 0.9689 - val_binary_accuracy: 0.8276\n",
      "Epoch 79/100\n",
      "56/56 [==============================] - 0s 196us/step - loss: 0.3435 - binary_accuracy: 1.0000 - val_loss: 0.9676 - val_binary_accuracy: 0.8276\n",
      "Epoch 80/100\n",
      "56/56 [==============================] - 0s 214us/step - loss: 0.3356 - binary_accuracy: 1.0000 - val_loss: 0.9581 - val_binary_accuracy: 0.8276\n",
      "Epoch 81/100\n",
      "56/56 [==============================] - 0s 214us/step - loss: 0.3280 - binary_accuracy: 1.0000 - val_loss: 0.9526 - val_binary_accuracy: 0.8276\n",
      "Epoch 82/100\n",
      "56/56 [==============================] - 0s 232us/step - loss: 0.3209 - binary_accuracy: 1.0000 - val_loss: 0.9578 - val_binary_accuracy: 0.7931\n",
      "Epoch 83/100\n",
      "56/56 [==============================] - 0s 214us/step - loss: 0.3135 - binary_accuracy: 1.0000 - val_loss: 0.9415 - val_binary_accuracy: 0.8276\n",
      "Epoch 84/100\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.3088 - binary_accuracy: 1.000 - 0s 268us/step - loss: 0.3067 - binary_accuracy: 1.0000 - val_loss: 0.9399 - val_binary_accuracy: 0.8276\n",
      "Epoch 85/100\n",
      "56/56 [==============================] - 0s 214us/step - loss: 0.3002 - binary_accuracy: 1.0000 - val_loss: 0.9426 - val_binary_accuracy: 0.7931\n",
      "Epoch 86/100\n",
      "56/56 [==============================] - 0s 248us/step - loss: 0.2938 - binary_accuracy: 1.0000 - val_loss: 0.9302 - val_binary_accuracy: 0.7931\n",
      "Epoch 87/100\n",
      "56/56 [==============================] - 0s 250us/step - loss: 0.2877 - binary_accuracy: 1.0000 - val_loss: 0.9319 - val_binary_accuracy: 0.7931\n",
      "Epoch 88/100\n",
      "56/56 [==============================] - 0s 232us/step - loss: 0.2816 - binary_accuracy: 1.0000 - val_loss: 0.9303 - val_binary_accuracy: 0.7931\n",
      "Epoch 89/100\n",
      "56/56 [==============================] - 0s 214us/step - loss: 0.2760 - binary_accuracy: 1.0000 - val_loss: 0.9166 - val_binary_accuracy: 0.7931\n",
      "Epoch 90/100\n",
      "56/56 [==============================] - 0s 196us/step - loss: 0.2703 - binary_accuracy: 1.0000 - val_loss: 0.9183 - val_binary_accuracy: 0.7931\n",
      "Epoch 91/100\n",
      "56/56 [==============================] - 0s 214us/step - loss: 0.2651 - binary_accuracy: 1.0000 - val_loss: 0.9231 - val_binary_accuracy: 0.7931\n",
      "Epoch 92/100\n",
      "56/56 [==============================] - 0s 179us/step - loss: 0.2597 - binary_accuracy: 1.0000 - val_loss: 0.9047 - val_binary_accuracy: 0.7931\n",
      "Epoch 93/100\n",
      "56/56 [==============================] - 0s 232us/step - loss: 0.2549 - binary_accuracy: 1.0000 - val_loss: 0.8992 - val_binary_accuracy: 0.7931\n",
      "Epoch 94/100\n",
      "56/56 [==============================] - 0s 232us/step - loss: 0.2501 - binary_accuracy: 1.0000 - val_loss: 0.9044 - val_binary_accuracy: 0.7931\n",
      "Epoch 95/100\n",
      "56/56 [==============================] - 0s 196us/step - loss: 0.2453 - binary_accuracy: 1.0000 - val_loss: 0.8954 - val_binary_accuracy: 0.7931\n",
      "Epoch 96/100\n",
      "56/56 [==============================] - 0s 214us/step - loss: 0.2410 - binary_accuracy: 1.0000 - val_loss: 0.8927 - val_binary_accuracy: 0.7931\n",
      "Epoch 97/100\n",
      "56/56 [==============================] - 0s 214us/step - loss: 0.2365 - binary_accuracy: 1.0000 - val_loss: 0.8763 - val_binary_accuracy: 0.7931\n",
      "Epoch 98/100\n",
      "56/56 [==============================] - 0s 214us/step - loss: 0.2329 - binary_accuracy: 1.0000 - val_loss: 0.8866 - val_binary_accuracy: 0.7931\n",
      "Epoch 99/100\n",
      "56/56 [==============================] - 0s 196us/step - loss: 0.2282 - binary_accuracy: 1.0000 - val_loss: 0.8685 - val_binary_accuracy: 0.7931\n",
      "Epoch 100/100\n",
      "56/56 [==============================] - 0s 196us/step - loss: 0.2245 - binary_accuracy: 1.0000 - val_loss: 0.8737 - val_binary_accuracy: 0.7931\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "INPUT_SIZE = (720,)\n",
    "reg_rate = 0.001\n",
    "model_in = Input(shape=INPUT_SIZE)\n",
    "classifier = Dense(128, activation=\"tanh\", kernel_regularizer=L1L2(l1=reg_rate, l2=reg_rate))(model_in)\n",
    "classifier = Dense(64, activation=\"tanh\", kernel_regularizer=L1L2(l1=reg_rate, l2=reg_rate))(classifier)\n",
    "classifier = Dense(32, activation=\"tanh\", kernel_regularizer=L1L2(l1=reg_rate, l2=reg_rate))(classifier)\n",
    "#classifier = Dropout(0.5)(classifier)\n",
    "classifier = Dense(1, activation=\"sigmoid\", kernel_regularizer=L1L2(l1=reg_rate, l2=reg_rate))(classifier)\n",
    "\n",
    "model = Model(inputs=[model_in], outputs=[classifier])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"binary_accuracy\"])\n",
    "\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "callbacks = [ EarlyStopping(monitor=\"loss\", patience=50, min_delta=0.0)]\n",
    "\n",
    "evaluation = model.fit(x_t_scaled, y_t, shuffle=True,\n",
    "                        epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1,\n",
    "                        validation_data = (x_v_scaled, y_v),\n",
    "                        callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.77      1.00      0.87        20\n",
      "        1.0       1.00      0.33      0.50         9\n",
      "\n",
      "avg / total       0.84      0.79      0.75        29\n",
      "\n",
      "[[20  0]\n",
      " [ 6  3]]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "v_p_k = model.predict(x_v_scaled)\n",
    "v_p_k = [1.0 if v  >= 0.5 else 0.0 for v in v_p_k]\n",
    "print(classification_report(y_v.flatten(), v_p_k))\n",
    "print(confusion_matrix(y_v.flatten(), v_p_k))\n",
    "print(v_p_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Sequential Model Compostion\n",
    "\n",
    "Same as above just with sequential model composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 0.6198 - binary_accuracy: 0.5893\n",
      "Epoch 2/10\n",
      "56/56 [==============================] - 0s 304us/step - loss: 0.2290 - binary_accuracy: 0.9643\n",
      "Epoch 3/10\n",
      "56/56 [==============================] - 0s 303us/step - loss: 0.0976 - binary_accuracy: 0.9821\n",
      "Epoch 4/10\n",
      "56/56 [==============================] - 0s 339us/step - loss: 0.0495 - binary_accuracy: 0.9821\n",
      "Epoch 5/10\n",
      "56/56 [==============================] - 0s 393us/step - loss: 0.0252 - binary_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "56/56 [==============================] - 0s 321us/step - loss: 0.0144 - binary_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "56/56 [==============================] - 0s 268us/step - loss: 0.0093 - binary_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "56/56 [==============================] - 0s 382us/step - loss: 0.0061 - binary_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "56/56 [==============================] - 0s 321us/step - loss: 0.0045 - binary_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "56/56 [==============================] - 0s 339us/step - loss: 0.0034 - binary_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128,activation=\"relu\",input_shape=(x_t.shape[1],)))\n",
    "model.add(Dense(64,activation=\"relu\"))\n",
    "model.add(Dense(32,activation=\"relu\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"binary_accuracy\"])\n",
    "\n",
    "epoch_count=10\n",
    "batch_size=10\n",
    "\n",
    "history = model.fit(x=x_t_scaled,y=y_t,batch_size=batch_size,epochs=epoch_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      1.00      0.89        20\n",
      "        1.0       1.00      0.44      0.62         9\n",
      "\n",
      "avg / total       0.86      0.83      0.80        29\n",
      "\n",
      "[[20  0]\n",
      " [ 5  4]]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "v_p_k = model.predict(x_v_scaled)\n",
    "v_p_k = [1.0 if v  >= 0.5 else 0.0 for v in v_p_k]\n",
    "print(classification_report(y_v.flatten(), v_p_k))\n",
    "print(confusion_matrix(y_v.flatten(), v_p_k))\n",
    "print(v_p_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Convolutional Neural Network\n",
    "\n",
    "As the problem may be a pattern problem; lets give a whirl at a convolutional network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 720)\n",
      "(56, 1)\n",
      "(29, 720)\n",
      "(29, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_t.shape)\n",
    "print(y_t.shape)\n",
    "print(x_v.shape)\n",
    "print(y_v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t_c = x_t_scaled.reshape(56, 12, 12, 5)\n",
    "x_v_c = x_v_scaled.reshape(29, 12, 12, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = (12, 12, 5)\n",
    "reg_rate = 0.001\n",
    "model_in = Input(shape=INPUT_SIZE)\n",
    "classifier = Conv2D(128, (3,3), activation=\"tanh\", kernel_regularizer=L1L2(l1=reg_rate, l2=reg_rate))(model_in)\n",
    "classifier = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(classifier)\n",
    "classifier = Conv2D(64, (2,2), activation=\"tanh\", kernel_regularizer=L1L2(l1=reg_rate, l2=reg_rate))(classifier)\n",
    "classifier = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(classifier)\n",
    "classifier = Flatten()(classifier)\n",
    "classifier = Dense(1, activation=\"sigmoid\", kernel_regularizer=L1L2(l1=reg_rate, l2=reg_rate))(classifier)\n",
    "\n",
    "model = Model(inputs=[model_in], outputs=[classifier])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 56 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 2.3172 - acc: 0.7321 - val_loss: 2.3947 - val_acc: 0.6897\n",
      "Epoch 2/200\n",
      "56/56 [==============================] - 0s 554us/step - loss: 2.1827 - acc: 0.7857 - val_loss: 2.3777 - val_acc: 0.6897\n",
      "Epoch 3/200\n",
      "56/56 [==============================] - 0s 625us/step - loss: 2.0702 - acc: 0.8036 - val_loss: 2.3091 - val_acc: 0.6897\n",
      "Epoch 4/200\n",
      "56/56 [==============================] - 0s 571us/step - loss: 1.9957 - acc: 0.8393 - val_loss: 2.2305 - val_acc: 0.7241\n",
      "Epoch 5/200\n",
      "56/56 [==============================] - 0s 500us/step - loss: 1.9326 - acc: 0.9107 - val_loss: 2.1693 - val_acc: 0.7586\n",
      "Epoch 6/200\n",
      "56/56 [==============================] - 0s 482us/step - loss: 1.8813 - acc: 0.9107 - val_loss: 2.1434 - val_acc: 0.7586\n",
      "Epoch 7/200\n",
      "56/56 [==============================] - 0s 571us/step - loss: 1.8149 - acc: 0.9107 - val_loss: 2.1305 - val_acc: 0.7586\n",
      "Epoch 8/200\n",
      "56/56 [==============================] - 0s 645us/step - loss: 1.7656 - acc: 0.9286 - val_loss: 2.1027 - val_acc: 0.7241\n",
      "Epoch 9/200\n",
      "56/56 [==============================] - 0s 643us/step - loss: 1.7143 - acc: 0.9286 - val_loss: 2.0554 - val_acc: 0.7241\n",
      "Epoch 10/200\n",
      "56/56 [==============================] - 0s 607us/step - loss: 1.6665 - acc: 0.9464 - val_loss: 2.0109 - val_acc: 0.7586\n",
      "Epoch 11/200\n",
      "56/56 [==============================] - 0s 517us/step - loss: 1.6211 - acc: 0.9286 - val_loss: 1.9732 - val_acc: 0.7241\n",
      "Epoch 12/200\n",
      "56/56 [==============================] - 0s 427us/step - loss: 1.5752 - acc: 0.9464 - val_loss: 1.9293 - val_acc: 0.7586\n",
      "Epoch 13/200\n",
      "56/56 [==============================] - 0s 464us/step - loss: 1.5314 - acc: 0.9821 - val_loss: 1.8957 - val_acc: 0.7586\n",
      "Epoch 14/200\n",
      "56/56 [==============================] - 0s 482us/step - loss: 1.4875 - acc: 0.9821 - val_loss: 1.8583 - val_acc: 0.7586\n",
      "Epoch 15/200\n",
      "56/56 [==============================] - 0s 625us/step - loss: 1.4450 - acc: 0.9821 - val_loss: 1.8299 - val_acc: 0.7586\n",
      "Epoch 16/200\n",
      "56/56 [==============================] - 0s 589us/step - loss: 1.4022 - acc: 0.9821 - val_loss: 1.7959 - val_acc: 0.7586\n",
      "Epoch 17/200\n",
      "56/56 [==============================] - 0s 513us/step - loss: 1.3620 - acc: 0.9821 - val_loss: 1.7562 - val_acc: 0.7586\n",
      "Epoch 18/200\n",
      "56/56 [==============================] - 0s 465us/step - loss: 1.3222 - acc: 0.9821 - val_loss: 1.7244 - val_acc: 0.7586\n",
      "Epoch 19/200\n",
      "56/56 [==============================] - 0s 446us/step - loss: 1.2827 - acc: 0.9821 - val_loss: 1.6816 - val_acc: 0.7586\n",
      "Epoch 20/200\n",
      "56/56 [==============================] - 0s 464us/step - loss: 1.2487 - acc: 0.9821 - val_loss: 1.6435 - val_acc: 0.7586\n",
      "Epoch 21/200\n",
      "56/56 [==============================] - 0s 553us/step - loss: 1.2083 - acc: 0.9821 - val_loss: 1.6166 - val_acc: 0.7586\n",
      "Epoch 22/200\n",
      "56/56 [==============================] - 0s 589us/step - loss: 1.1737 - acc: 0.9821 - val_loss: 1.5939 - val_acc: 0.7586\n",
      "Epoch 23/200\n",
      "56/56 [==============================] - ETA: 0s - loss: 1.1568 - acc: 0.950 - 0s 607us/step - loss: 1.1392 - acc: 0.9821 - val_loss: 1.5623 - val_acc: 0.7586\n",
      "Epoch 24/200\n",
      "56/56 [==============================] - 0s 482us/step - loss: 1.1044 - acc: 1.0000 - val_loss: 1.5266 - val_acc: 0.7586\n",
      "Epoch 25/200\n",
      "56/56 [==============================] - 0s 446us/step - loss: 1.0737 - acc: 1.0000 - val_loss: 1.4907 - val_acc: 0.7586\n",
      "Epoch 26/200\n",
      "56/56 [==============================] - 0s 446us/step - loss: 1.0397 - acc: 1.0000 - val_loss: 1.4617 - val_acc: 0.7586\n",
      "Epoch 27/200\n",
      "56/56 [==============================] - 0s 518us/step - loss: 1.0060 - acc: 1.0000 - val_loss: 1.4437 - val_acc: 0.7586\n",
      "Epoch 28/200\n",
      "56/56 [==============================] - 0s 554us/step - loss: 0.9769 - acc: 1.0000 - val_loss: 1.4287 - val_acc: 0.7586\n",
      "Epoch 29/200\n",
      "56/56 [==============================] - 0s 500us/step - loss: 0.9481 - acc: 1.0000 - val_loss: 1.3941 - val_acc: 0.7586\n",
      "Epoch 30/200\n",
      "56/56 [==============================] - 0s 518us/step - loss: 0.9181 - acc: 1.0000 - val_loss: 1.3520 - val_acc: 0.7586\n",
      "Epoch 31/200\n",
      "56/56 [==============================] - 0s 511us/step - loss: 0.8931 - acc: 1.0000 - val_loss: 1.3216 - val_acc: 0.7586\n",
      "Epoch 32/200\n",
      "56/56 [==============================] - 0s 429us/step - loss: 0.8672 - acc: 1.0000 - val_loss: 1.3068 - val_acc: 0.7586\n",
      "Epoch 33/200\n",
      "56/56 [==============================] - 0s 535us/step - loss: 0.8393 - acc: 1.0000 - val_loss: 1.2770 - val_acc: 0.7586\n",
      "Epoch 34/200\n",
      "56/56 [==============================] - 0s 481us/step - loss: 0.8132 - acc: 1.0000 - val_loss: 1.2568 - val_acc: 0.7586\n",
      "Epoch 35/200\n",
      "56/56 [==============================] - 0s 464us/step - loss: 0.7907 - acc: 1.0000 - val_loss: 1.2420 - val_acc: 0.7586\n",
      "Epoch 36/200\n",
      "56/56 [==============================] - 0s 536us/step - loss: 0.7685 - acc: 1.0000 - val_loss: 1.2189 - val_acc: 0.7586\n",
      "Epoch 37/200\n",
      "56/56 [==============================] - 0s 641us/step - loss: 0.7471 - acc: 1.0000 - val_loss: 1.1951 - val_acc: 0.7586\n",
      "Epoch 38/200\n",
      "56/56 [==============================] - 0s 464us/step - loss: 0.7284 - acc: 1.0000 - val_loss: 1.1781 - val_acc: 0.7586\n",
      "Epoch 39/200\n",
      "56/56 [==============================] - 0s 500us/step - loss: 0.7064 - acc: 1.0000 - val_loss: 1.1629 - val_acc: 0.7586\n",
      "Epoch 40/200\n",
      "56/56 [==============================] - 0s 464us/step - loss: 0.6903 - acc: 1.0000 - val_loss: 1.1362 - val_acc: 0.7586\n",
      "Epoch 41/200\n",
      "56/56 [==============================] - 0s 625us/step - loss: 0.6723 - acc: 1.0000 - val_loss: 1.1384 - val_acc: 0.7586\n",
      "Epoch 42/200\n",
      "56/56 [==============================] - 0s 467us/step - loss: 0.6549 - acc: 1.0000 - val_loss: 1.1211 - val_acc: 0.7586\n",
      "Epoch 43/200\n",
      "56/56 [==============================] - 0s 446us/step - loss: 0.6373 - acc: 1.0000 - val_loss: 1.0990 - val_acc: 0.7586\n",
      "Epoch 44/200\n",
      "56/56 [==============================] - 0s 483us/step - loss: 0.6234 - acc: 1.0000 - val_loss: 1.0815 - val_acc: 0.7586\n",
      "Epoch 45/200\n",
      "56/56 [==============================] - 0s 500us/step - loss: 0.6082 - acc: 1.0000 - val_loss: 1.0647 - val_acc: 0.7586\n",
      "Epoch 46/200\n",
      "56/56 [==============================] - 0s 446us/step - loss: 0.5952 - acc: 1.0000 - val_loss: 1.0542 - val_acc: 0.7931\n",
      "Epoch 47/200\n",
      "56/56 [==============================] - 0s 536us/step - loss: 0.5812 - acc: 1.0000 - val_loss: 1.0520 - val_acc: 0.7586\n",
      "Epoch 48/200\n",
      "56/56 [==============================] - 0s 536us/step - loss: 0.5701 - acc: 1.0000 - val_loss: 1.0375 - val_acc: 0.7586\n",
      "Epoch 49/200\n",
      "56/56 [==============================] - 0s 446us/step - loss: 0.5611 - acc: 1.0000 - val_loss: 1.0137 - val_acc: 0.7586\n",
      "Epoch 50/200\n",
      "56/56 [==============================] - 0s 446us/step - loss: 0.5469 - acc: 1.0000 - val_loss: 1.0156 - val_acc: 0.7586\n",
      "Epoch 51/200\n",
      "56/56 [==============================] - 0s 536us/step - loss: 0.5370 - acc: 1.0000 - val_loss: 1.0169 - val_acc: 0.7586\n",
      "Epoch 52/200\n",
      "56/56 [==============================] - 0s 464us/step - loss: 0.5273 - acc: 1.0000 - val_loss: 0.9930 - val_acc: 0.7586\n",
      "Epoch 53/200\n",
      "56/56 [==============================] - 0s 481us/step - loss: 0.5176 - acc: 1.0000 - val_loss: 0.9749 - val_acc: 0.7586\n",
      "Epoch 54/200\n",
      "56/56 [==============================] - 0s 518us/step - loss: 0.5063 - acc: 1.0000 - val_loss: 0.9754 - val_acc: 0.7931\n",
      "Epoch 55/200\n",
      "56/56 [==============================] - 0s 536us/step - loss: 0.5004 - acc: 1.0000 - val_loss: 0.9874 - val_acc: 0.7931\n",
      "Epoch 56/200\n",
      "56/56 [==============================] - 0s 483us/step - loss: 0.4905 - acc: 1.0000 - val_loss: 0.9735 - val_acc: 0.7586\n",
      "Epoch 57/200\n",
      "56/56 [==============================] - 0s 464us/step - loss: 0.4825 - acc: 1.0000 - val_loss: 0.9500 - val_acc: 0.7586\n",
      "Epoch 58/200\n",
      "56/56 [==============================] - 0s 536us/step - loss: 0.4745 - acc: 1.0000 - val_loss: 0.9526 - val_acc: 0.7586\n",
      "Epoch 59/200\n",
      "56/56 [==============================] - 0s 462us/step - loss: 0.4690 - acc: 1.0000 - val_loss: 0.9492 - val_acc: 0.7931\n",
      "Epoch 60/200\n",
      "56/56 [==============================] - 0s 445us/step - loss: 0.4640 - acc: 1.0000 - val_loss: 0.9581 - val_acc: 0.7931\n",
      "Epoch 61/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 429us/step - loss: 0.4529 - acc: 1.0000 - val_loss: 0.9529 - val_acc: 0.7586\n",
      "Epoch 62/200\n",
      "56/56 [==============================] - 0s 500us/step - loss: 0.4474 - acc: 1.0000 - val_loss: 0.9382 - val_acc: 0.7586\n",
      "Epoch 63/200\n",
      "56/56 [==============================] - 0s 464us/step - loss: 0.4380 - acc: 1.0000 - val_loss: 0.9203 - val_acc: 0.7931\n",
      "Epoch 64/200\n",
      "56/56 [==============================] - 0s 518us/step - loss: 0.4355 - acc: 1.0000 - val_loss: 0.9237 - val_acc: 0.7931\n",
      "Epoch 65/200\n",
      "56/56 [==============================] - 0s 571us/step - loss: 0.4288 - acc: 1.0000 - val_loss: 0.9248 - val_acc: 0.7586\n",
      "Epoch 66/200\n",
      "56/56 [==============================] - 0s 464us/step - loss: 0.4255 - acc: 1.0000 - val_loss: 0.9509 - val_acc: 0.7586\n",
      "Epoch 67/200\n",
      "56/56 [==============================] - 0s 518us/step - loss: 0.4187 - acc: 1.0000 - val_loss: 0.9204 - val_acc: 0.7586\n",
      "Epoch 68/200\n",
      "56/56 [==============================] - 0s 589us/step - loss: 0.4106 - acc: 1.0000 - val_loss: 0.9061 - val_acc: 0.7931\n",
      "Epoch 69/200\n",
      "56/56 [==============================] - 0s 500us/step - loss: 0.4053 - acc: 1.0000 - val_loss: 0.9150 - val_acc: 0.7586\n",
      "Epoch 70/200\n",
      "56/56 [==============================] - 0s 447us/step - loss: 0.4008 - acc: 1.0000 - val_loss: 0.9106 - val_acc: 0.7241\n",
      "Epoch 71/200\n",
      "56/56 [==============================] - 0s 521us/step - loss: 0.3955 - acc: 1.0000 - val_loss: 0.9147 - val_acc: 0.7586\n",
      "Epoch 72/200\n",
      "56/56 [==============================] - 0s 464us/step - loss: 0.3930 - acc: 1.0000 - val_loss: 0.9197 - val_acc: 0.7241\n",
      "Epoch 73/200\n",
      "56/56 [==============================] - 0s 500us/step - loss: 0.3864 - acc: 1.0000 - val_loss: 0.9006 - val_acc: 0.7931\n",
      "Epoch 74/200\n",
      "56/56 [==============================] - 0s 482us/step - loss: 0.3822 - acc: 1.0000 - val_loss: 0.9058 - val_acc: 0.7931\n",
      "Epoch 75/200\n",
      "56/56 [==============================] - 0s 410us/step - loss: 0.3772 - acc: 1.0000 - val_loss: 0.9044 - val_acc: 0.7586\n",
      "Epoch 76/200\n",
      "56/56 [==============================] - 0s 500us/step - loss: 0.3763 - acc: 1.0000 - val_loss: 0.9149 - val_acc: 0.7586\n",
      "Epoch 77/200\n",
      "56/56 [==============================] - 0s 518us/step - loss: 0.3713 - acc: 1.0000 - val_loss: 0.8971 - val_acc: 0.7241\n",
      "Epoch 78/200\n",
      "56/56 [==============================] - 0s 464us/step - loss: 0.3664 - acc: 1.0000 - val_loss: 0.8916 - val_acc: 0.7586\n",
      "Epoch 79/200\n",
      "56/56 [==============================] - 0s 518us/step - loss: 0.3642 - acc: 1.0000 - val_loss: 0.8896 - val_acc: 0.7586\n",
      "Epoch 80/200\n",
      "56/56 [==============================] - 0s 430us/step - loss: 0.3577 - acc: 1.0000 - val_loss: 0.8976 - val_acc: 0.7586\n",
      "Epoch 81/200\n",
      "56/56 [==============================] - 0s 464us/step - loss: 0.3600 - acc: 1.0000 - val_loss: 0.9034 - val_acc: 0.7241\n",
      "Epoch 82/200\n",
      "56/56 [==============================] - 0s 446us/step - loss: 0.3517 - acc: 1.0000 - val_loss: 0.8884 - val_acc: 0.7241\n",
      "Epoch 83/200\n",
      "56/56 [==============================] - 0s 571us/step - loss: 0.3478 - acc: 1.0000 - val_loss: 0.8876 - val_acc: 0.7931\n",
      "Epoch 84/200\n",
      "56/56 [==============================] - 0s 482us/step - loss: 0.3450 - acc: 1.0000 - val_loss: 0.8995 - val_acc: 0.7586\n",
      "Epoch 85/200\n",
      "56/56 [==============================] - 0s 482us/step - loss: 0.3403 - acc: 1.0000 - val_loss: 0.8967 - val_acc: 0.7241\n",
      "Epoch 86/200\n",
      "56/56 [==============================] - 0s 482us/step - loss: 0.3394 - acc: 1.0000 - val_loss: 0.8872 - val_acc: 0.7586\n",
      "Epoch 87/200\n",
      "56/56 [==============================] - 0s 518us/step - loss: 0.3351 - acc: 1.0000 - val_loss: 0.8804 - val_acc: 0.7586\n",
      "Epoch 88/200\n",
      "56/56 [==============================] - 0s 482us/step - loss: 0.3317 - acc: 1.0000 - val_loss: 0.8930 - val_acc: 0.7241\n",
      "Epoch 89/200\n",
      "56/56 [==============================] - 0s 499us/step - loss: 0.3301 - acc: 1.0000 - val_loss: 0.9022 - val_acc: 0.7241\n",
      "Epoch 90/200\n",
      "56/56 [==============================] - 0s 482us/step - loss: 0.3261 - acc: 1.0000 - val_loss: 0.8847 - val_acc: 0.7241\n",
      "Epoch 91/200\n",
      "56/56 [==============================] - 0s 464us/step - loss: 0.3254 - acc: 1.0000 - val_loss: 0.8839 - val_acc: 0.7586\n",
      "Epoch 92/200\n",
      "56/56 [==============================] - 0s 425us/step - loss: 0.3204 - acc: 1.0000 - val_loss: 0.8889 - val_acc: 0.7241\n",
      "Epoch 93/200\n",
      "56/56 [==============================] - 0s 464us/step - loss: 0.3182 - acc: 1.0000 - val_loss: 0.8818 - val_acc: 0.7241\n",
      "Epoch 94/200\n",
      "56/56 [==============================] - 0s 428us/step - loss: 0.3150 - acc: 1.0000 - val_loss: 0.8808 - val_acc: 0.7241\n",
      "Epoch 95/200\n",
      "56/56 [==============================] - 0s 446us/step - loss: 0.3126 - acc: 1.0000 - val_loss: 0.8671 - val_acc: 0.7241\n",
      "Epoch 96/200\n",
      "56/56 [==============================] - 0s 463us/step - loss: 0.3097 - acc: 1.0000 - val_loss: 0.8814 - val_acc: 0.7241\n",
      "Epoch 97/200\n",
      "56/56 [==============================] - 0s 446us/step - loss: 0.3079 - acc: 1.0000 - val_loss: 0.8782 - val_acc: 0.7241\n",
      "Epoch 98/200\n",
      "56/56 [==============================] - 0s 464us/step - loss: 0.3038 - acc: 1.0000 - val_loss: 0.8760 - val_acc: 0.7241\n",
      "Epoch 99/200\n",
      "56/56 [==============================] - 0s 446us/step - loss: 0.3015 - acc: 1.0000 - val_loss: 0.8745 - val_acc: 0.7241\n",
      "Epoch 100/200\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.2907 - acc: 1.000 - 0s 464us/step - loss: 0.2990 - acc: 1.0000 - val_loss: 0.8775 - val_acc: 0.7241\n",
      "Epoch 101/200\n",
      "56/56 [==============================] - 0s 464us/step - loss: 0.2965 - acc: 1.0000 - val_loss: 0.8703 - val_acc: 0.7241\n",
      "Epoch 102/200\n",
      "56/56 [==============================] - 0s 536us/step - loss: 0.2947 - acc: 1.0000 - val_loss: 0.8824 - val_acc: 0.7241\n",
      "Epoch 103/200\n",
      "56/56 [==============================] - 0s 479us/step - loss: 0.2928 - acc: 1.0000 - val_loss: 0.8763 - val_acc: 0.7241\n",
      "Epoch 104/200\n",
      "56/56 [==============================] - 0s 464us/step - loss: 0.2909 - acc: 1.0000 - val_loss: 0.8745 - val_acc: 0.7241\n",
      "Epoch 105/200\n",
      "56/56 [==============================] - 0s 464us/step - loss: 0.2879 - acc: 1.0000 - val_loss: 0.8686 - val_acc: 0.7241\n",
      "Epoch 106/200\n",
      "56/56 [==============================] - 0s 429us/step - loss: 0.2852 - acc: 1.0000 - val_loss: 0.8746 - val_acc: 0.7241\n",
      "Epoch 107/200\n",
      "56/56 [==============================] - 0s 446us/step - loss: 0.2829 - acc: 1.0000 - val_loss: 0.8665 - val_acc: 0.7241\n",
      "Epoch 108/200\n",
      "56/56 [==============================] - 0s 446us/step - loss: 0.2802 - acc: 1.0000 - val_loss: 0.8624 - val_acc: 0.7241\n",
      "Epoch 109/200\n",
      "56/56 [==============================] - 0s 446us/step - loss: 0.2781 - acc: 1.0000 - val_loss: 0.8702 - val_acc: 0.7241\n",
      "Epoch 110/200\n",
      "56/56 [==============================] - 0s 464us/step - loss: 0.2765 - acc: 1.0000 - val_loss: 0.8672 - val_acc: 0.7241\n",
      "Epoch 111/200\n",
      "56/56 [==============================] - 0s 429us/step - loss: 0.2749 - acc: 1.0000 - val_loss: 0.8630 - val_acc: 0.7241\n",
      "Epoch 112/200\n",
      "56/56 [==============================] - 0s 500us/step - loss: 0.2726 - acc: 1.0000 - val_loss: 0.8692 - val_acc: 0.7241\n",
      "Epoch 113/200\n",
      "56/56 [==============================] - 0s 471us/step - loss: 0.2713 - acc: 1.0000 - val_loss: 0.8664 - val_acc: 0.7241\n",
      "Epoch 114/200\n",
      "56/56 [==============================] - 0s 464us/step - loss: 0.2688 - acc: 1.0000 - val_loss: 0.8655 - val_acc: 0.7241\n",
      "Epoch 115/200\n",
      "56/56 [==============================] - 0s 518us/step - loss: 0.2666 - acc: 1.0000 - val_loss: 0.8705 - val_acc: 0.7241\n",
      "Epoch 116/200\n",
      "56/56 [==============================] - 0s 536us/step - loss: 0.2646 - acc: 1.0000 - val_loss: 0.8659 - val_acc: 0.7241\n",
      "Epoch 117/200\n",
      "56/56 [==============================] - 0s 482us/step - loss: 0.2628 - acc: 1.0000 - val_loss: 0.8598 - val_acc: 0.7241\n",
      "Epoch 118/200\n",
      "56/56 [==============================] - 0s 500us/step - loss: 0.2607 - acc: 1.0000 - val_loss: 0.8657 - val_acc: 0.7241\n",
      "Epoch 119/200\n",
      "56/56 [==============================] - 0s 554us/step - loss: 0.2592 - acc: 1.0000 - val_loss: 0.8681 - val_acc: 0.7241\n",
      "Epoch 120/200\n",
      "56/56 [==============================] - 0s 519us/step - loss: 0.2591 - acc: 1.0000 - val_loss: 0.8683 - val_acc: 0.7241\n",
      "Epoch 121/200\n",
      "56/56 [==============================] - 0s 750us/step - loss: 0.2582 - acc: 1.0000 - val_loss: 0.8549 - val_acc: 0.7586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/200\n",
      "56/56 [==============================] - 0s 536us/step - loss: 0.2545 - acc: 1.0000 - val_loss: 0.8572 - val_acc: 0.7241\n",
      "Epoch 123/200\n",
      "56/56 [==============================] - 0s 482us/step - loss: 0.2543 - acc: 1.0000 - val_loss: 0.8643 - val_acc: 0.7241\n",
      "Epoch 124/200\n",
      "56/56 [==============================] - 0s 518us/step - loss: 0.2526 - acc: 1.0000 - val_loss: 0.8648 - val_acc: 0.7241\n",
      "Epoch 125/200\n",
      "56/56 [==============================] - 0s 464us/step - loss: 0.2497 - acc: 1.0000 - val_loss: 0.8638 - val_acc: 0.7241\n",
      "Epoch 126/200\n",
      "56/56 [==============================] - 0s 481us/step - loss: 0.2482 - acc: 1.0000 - val_loss: 0.8513 - val_acc: 0.7241\n",
      "Epoch 127/200\n",
      "56/56 [==============================] - 0s 589us/step - loss: 0.2488 - acc: 1.0000 - val_loss: 0.8574 - val_acc: 0.7241\n",
      "Epoch 128/200\n",
      "56/56 [==============================] - 0s 482us/step - loss: 0.2458 - acc: 1.0000 - val_loss: 0.8611 - val_acc: 0.7241\n",
      "Epoch 129/200\n",
      "56/56 [==============================] - 0s 571us/step - loss: 0.2437 - acc: 1.0000 - val_loss: 0.8551 - val_acc: 0.7241\n",
      "Epoch 130/200\n",
      "56/56 [==============================] - 0s 536us/step - loss: 0.2419 - acc: 1.0000 - val_loss: 0.8588 - val_acc: 0.7241\n",
      "Epoch 131/200\n",
      "56/56 [==============================] - 0s 464us/step - loss: 0.2407 - acc: 1.0000 - val_loss: 0.8614 - val_acc: 0.7241\n",
      "Epoch 132/200\n",
      "56/56 [==============================] - 0s 482us/step - loss: 0.2396 - acc: 1.0000 - val_loss: 0.8640 - val_acc: 0.7241\n",
      "Epoch 133/200\n",
      "56/56 [==============================] - 0s 554us/step - loss: 0.2373 - acc: 1.0000 - val_loss: 0.8544 - val_acc: 0.7241\n",
      "Epoch 134/200\n",
      "56/56 [==============================] - 0s 482us/step - loss: 0.2361 - acc: 1.0000 - val_loss: 0.8581 - val_acc: 0.7241\n",
      "Epoch 135/200\n",
      "56/56 [==============================] - 0s 536us/step - loss: 0.2345 - acc: 1.0000 - val_loss: 0.8603 - val_acc: 0.7241\n",
      "Epoch 136/200\n",
      "56/56 [==============================] - 0s 572us/step - loss: 0.2344 - acc: 1.0000 - val_loss: 0.8604 - val_acc: 0.7241\n",
      "Epoch 137/200\n",
      "56/56 [==============================] - 0s 482us/step - loss: 0.2314 - acc: 1.0000 - val_loss: 0.8559 - val_acc: 0.7241\n",
      "Epoch 138/200\n",
      "56/56 [==============================] - 0s 464us/step - loss: 0.2318 - acc: 1.0000 - val_loss: 0.8577 - val_acc: 0.7241\n",
      "Epoch 139/200\n",
      "56/56 [==============================] - 0s 499us/step - loss: 0.2292 - acc: 1.0000 - val_loss: 0.8562 - val_acc: 0.7241\n",
      "Epoch 140/200\n",
      "56/56 [==============================] - 0s 500us/step - loss: 0.2301 - acc: 1.0000 - val_loss: 0.8520 - val_acc: 0.7241\n",
      "Epoch 141/200\n",
      "56/56 [==============================] - 0s 444us/step - loss: 0.2291 - acc: 1.0000 - val_loss: 0.8501 - val_acc: 0.7241\n",
      "Epoch 142/200\n",
      "56/56 [==============================] - 0s 423us/step - loss: 0.2263 - acc: 1.0000 - val_loss: 0.8512 - val_acc: 0.7241\n",
      "Epoch 143/200\n",
      "56/56 [==============================] - 0s 482us/step - loss: 0.2254 - acc: 1.0000 - val_loss: 0.8556 - val_acc: 0.7241\n",
      "Epoch 144/200\n",
      "56/56 [==============================] - 0s 464us/step - loss: 0.2239 - acc: 1.0000 - val_loss: 0.8402 - val_acc: 0.7586\n",
      "Epoch 145/200\n",
      "56/56 [==============================] - 0s 517us/step - loss: 0.2224 - acc: 1.0000 - val_loss: 0.8492 - val_acc: 0.7241\n",
      "Epoch 146/200\n",
      "56/56 [==============================] - 0s 518us/step - loss: 0.2208 - acc: 1.0000 - val_loss: 0.8543 - val_acc: 0.7241\n",
      "Epoch 147/200\n",
      "56/56 [==============================] - 0s 518us/step - loss: 0.2202 - acc: 1.0000 - val_loss: 0.8505 - val_acc: 0.7241\n",
      "Epoch 148/200\n",
      "56/56 [==============================] - 0s 470us/step - loss: 0.2187 - acc: 1.0000 - val_loss: 0.8532 - val_acc: 0.7241\n",
      "Epoch 149/200\n",
      "56/56 [==============================] - 0s 482us/step - loss: 0.2170 - acc: 1.0000 - val_loss: 0.8453 - val_acc: 0.7241\n",
      "Epoch 150/200\n",
      "56/56 [==============================] - 0s 500us/step - loss: 0.2175 - acc: 1.0000 - val_loss: 0.8485 - val_acc: 0.7241\n",
      "Epoch 151/200\n",
      "56/56 [==============================] - 0s 482us/step - loss: 0.2153 - acc: 1.0000 - val_loss: 0.8466 - val_acc: 0.7241\n",
      "Epoch 152/200\n",
      "56/56 [==============================] - 0s 464us/step - loss: 0.2144 - acc: 1.0000 - val_loss: 0.8512 - val_acc: 0.7241\n",
      "Epoch 153/200\n",
      "56/56 [==============================] - 0s 464us/step - loss: 0.2146 - acc: 1.0000 - val_loss: 0.8482 - val_acc: 0.7241\n",
      "Epoch 154/200\n",
      "56/56 [==============================] - 0s 482us/step - loss: 0.2134 - acc: 1.0000 - val_loss: 0.8428 - val_acc: 0.7241\n",
      "Epoch 155/200\n",
      "56/56 [==============================] - 0s 520us/step - loss: 0.2106 - acc: 1.0000 - val_loss: 0.8474 - val_acc: 0.7241\n",
      "Epoch 156/200\n",
      "56/56 [==============================] - 0s 481us/step - loss: 0.2097 - acc: 1.0000 - val_loss: 0.8436 - val_acc: 0.7241\n",
      "Epoch 157/200\n",
      "56/56 [==============================] - 0s 464us/step - loss: 0.2080 - acc: 1.0000 - val_loss: 0.8401 - val_acc: 0.7241\n",
      "Epoch 158/200\n",
      "56/56 [==============================] - 0s 482us/step - loss: 0.2074 - acc: 1.0000 - val_loss: 0.8458 - val_acc: 0.7241\n",
      "Epoch 159/200\n",
      "56/56 [==============================] - 0s 446us/step - loss: 0.2063 - acc: 1.0000 - val_loss: 0.8386 - val_acc: 0.7241\n",
      "Epoch 160/200\n",
      "56/56 [==============================] - 0s 464us/step - loss: 0.2054 - acc: 1.0000 - val_loss: 0.8436 - val_acc: 0.7241\n",
      "Epoch 161/200\n",
      "56/56 [==============================] - 0s 458us/step - loss: 0.2043 - acc: 1.0000 - val_loss: 0.8420 - val_acc: 0.7241\n",
      "Epoch 162/200\n",
      "56/56 [==============================] - 0s 500us/step - loss: 0.2032 - acc: 1.0000 - val_loss: 0.8452 - val_acc: 0.7241\n",
      "Epoch 163/200\n",
      "56/56 [==============================] - 0s 446us/step - loss: 0.2028 - acc: 1.0000 - val_loss: 0.8401 - val_acc: 0.7241\n",
      "Epoch 164/200\n",
      "56/56 [==============================] - 0s 536us/step - loss: 0.2013 - acc: 1.0000 - val_loss: 0.8365 - val_acc: 0.7241\n",
      "Epoch 165/200\n",
      "56/56 [==============================] - 0s 446us/step - loss: 0.2007 - acc: 1.0000 - val_loss: 0.8399 - val_acc: 0.7241\n",
      "Epoch 166/200\n",
      "56/56 [==============================] - 0s 518us/step - loss: 0.1999 - acc: 1.0000 - val_loss: 0.8388 - val_acc: 0.7241\n",
      "Epoch 167/200\n",
      "56/56 [==============================] - 0s 464us/step - loss: 0.1992 - acc: 1.0000 - val_loss: 0.8457 - val_acc: 0.7241\n",
      "Epoch 168/200\n",
      "56/56 [==============================] - 0s 482us/step - loss: 0.1982 - acc: 1.0000 - val_loss: 0.8380 - val_acc: 0.7241\n",
      "Epoch 169/200\n",
      "56/56 [==============================] - 0s 482us/step - loss: 0.1974 - acc: 1.0000 - val_loss: 0.8364 - val_acc: 0.7241\n",
      "Epoch 170/200\n",
      "56/56 [==============================] - 0s 462us/step - loss: 0.1963 - acc: 1.0000 - val_loss: 0.8458 - val_acc: 0.7241\n",
      "Epoch 171/200\n",
      "56/56 [==============================] - 0s 536us/step - loss: 0.1956 - acc: 1.0000 - val_loss: 0.8372 - val_acc: 0.7241\n",
      "Epoch 172/200\n",
      "56/56 [==============================] - 0s 536us/step - loss: 0.1945 - acc: 1.0000 - val_loss: 0.8383 - val_acc: 0.7241\n",
      "Epoch 173/200\n",
      "56/56 [==============================] - 0s 482us/step - loss: 0.1937 - acc: 1.0000 - val_loss: 0.8386 - val_acc: 0.7241\n",
      "Epoch 174/200\n",
      "56/56 [==============================] - 0s 643us/step - loss: 0.1929 - acc: 1.0000 - val_loss: 0.8325 - val_acc: 0.7241\n",
      "Epoch 175/200\n",
      "56/56 [==============================] - 0s 483us/step - loss: 0.1920 - acc: 1.0000 - val_loss: 0.8337 - val_acc: 0.7241\n",
      "Epoch 176/200\n",
      "56/56 [==============================] - 0s 464us/step - loss: 0.1910 - acc: 1.0000 - val_loss: 0.8394 - val_acc: 0.7241\n",
      "Epoch 177/200\n",
      "56/56 [==============================] - 0s 482us/step - loss: 0.1904 - acc: 1.0000 - val_loss: 0.8374 - val_acc: 0.7241\n",
      "Epoch 178/200\n",
      "56/56 [==============================] - 0s 482us/step - loss: 0.1898 - acc: 1.0000 - val_loss: 0.8362 - val_acc: 0.7241\n",
      "Epoch 179/200\n",
      "56/56 [==============================] - 0s 482us/step - loss: 0.1887 - acc: 1.0000 - val_loss: 0.8340 - val_acc: 0.7241\n",
      "Epoch 180/200\n",
      "56/56 [==============================] - 0s 571us/step - loss: 0.1880 - acc: 1.0000 - val_loss: 0.8357 - val_acc: 0.7241\n",
      "Epoch 181/200\n",
      "56/56 [==============================] - 0s 500us/step - loss: 0.1874 - acc: 1.0000 - val_loss: 0.8371 - val_acc: 0.7241\n",
      "Epoch 182/200\n",
      "56/56 [==============================] - 0s 482us/step - loss: 0.1863 - acc: 1.0000 - val_loss: 0.8346 - val_acc: 0.7241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/200\n",
      "56/56 [==============================] - 0s 518us/step - loss: 0.1859 - acc: 1.0000 - val_loss: 0.8338 - val_acc: 0.7241\n",
      "Epoch 184/200\n",
      "56/56 [==============================] - 0s 518us/step - loss: 0.1850 - acc: 1.0000 - val_loss: 0.8347 - val_acc: 0.7241\n",
      "Epoch 185/200\n",
      "56/56 [==============================] - 0s 589us/step - loss: 0.1849 - acc: 1.0000 - val_loss: 0.8389 - val_acc: 0.7241\n",
      "Epoch 186/200\n",
      "56/56 [==============================] - 0s 537us/step - loss: 0.1840 - acc: 1.0000 - val_loss: 0.8341 - val_acc: 0.7241\n",
      "Epoch 187/200\n",
      "56/56 [==============================] - 0s 464us/step - loss: 0.1832 - acc: 1.0000 - val_loss: 0.8357 - val_acc: 0.7241\n",
      "Epoch 188/200\n",
      "56/56 [==============================] - 0s 500us/step - loss: 0.1823 - acc: 1.0000 - val_loss: 0.8333 - val_acc: 0.7241\n",
      "Epoch 189/200\n",
      "56/56 [==============================] - 0s 536us/step - loss: 0.1818 - acc: 1.0000 - val_loss: 0.8317 - val_acc: 0.7241\n",
      "Epoch 190/200\n",
      "56/56 [==============================] - 0s 446us/step - loss: 0.1810 - acc: 1.0000 - val_loss: 0.8277 - val_acc: 0.7241\n",
      "Epoch 191/200\n",
      "56/56 [==============================] - 0s 500us/step - loss: 0.1810 - acc: 1.0000 - val_loss: 0.8261 - val_acc: 0.7241\n",
      "Epoch 192/200\n",
      "56/56 [==============================] - 0s 465us/step - loss: 0.1794 - acc: 1.0000 - val_loss: 0.8271 - val_acc: 0.7241\n",
      "Epoch 193/200\n",
      "56/56 [==============================] - 0s 500us/step - loss: 0.1786 - acc: 1.0000 - val_loss: 0.8243 - val_acc: 0.7241\n",
      "Epoch 194/200\n",
      "56/56 [==============================] - 0s 464us/step - loss: 0.1785 - acc: 1.0000 - val_loss: 0.8272 - val_acc: 0.7241\n",
      "Epoch 195/200\n",
      "56/56 [==============================] - 0s 482us/step - loss: 0.1773 - acc: 1.0000 - val_loss: 0.8255 - val_acc: 0.7241\n",
      "Epoch 196/200\n",
      "56/56 [==============================] - 0s 482us/step - loss: 0.1769 - acc: 1.0000 - val_loss: 0.8249 - val_acc: 0.7241\n",
      "Epoch 197/200\n",
      "56/56 [==============================] - 0s 464us/step - loss: 0.1761 - acc: 1.0000 - val_loss: 0.8298 - val_acc: 0.7241\n",
      "Epoch 198/200\n",
      "56/56 [==============================] - 0s 446us/step - loss: 0.1755 - acc: 1.0000 - val_loss: 0.8269 - val_acc: 0.7241\n",
      "Epoch 199/200\n",
      "56/56 [==============================] - 0s 446us/step - loss: 0.1749 - acc: 1.0000 - val_loss: 0.8300 - val_acc: 0.7241\n",
      "Epoch 200/200\n",
      "56/56 [==============================] - 0s 429us/step - loss: 0.1742 - acc: 1.0000 - val_loss: 0.8311 - val_acc: 0.7241\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 200\n",
    "BATCH_SIZE = 20\n",
    "callbacks = [ EarlyStopping(monitor=\"loss\", patience=10, min_delta=0.0) ]\n",
    "\n",
    "evaluation = model.fit(x_t_c, y_t, shuffle=True,\n",
    "                        epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1,\n",
    "                        validation_data = (x_v_c, y_v),\n",
    "                        callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.85      0.77      0.81        22\n",
      "        1.0       0.44      0.57      0.50         7\n",
      "\n",
      "avg / total       0.75      0.72      0.73        29\n",
      "\n",
      "[[17  5]\n",
      " [ 3  4]]\n",
      "[0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "v_p_kc = model.predict(x_v_c)\n",
    "v_p_kc = [1.0 if v  >= 0.5 else 0.0 for v in v_p_kc]\n",
    "print(classification_report(y_v.flatten(), v_p_kc))\n",
    "print(confusion_matrix(y_v.flatten(), v_p_kc))\n",
    "print(v_p_kc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_p_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
