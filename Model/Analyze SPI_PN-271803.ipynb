{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Data for Quality and get preliminary Results\n",
    "\n",
    "We test for validation of columns, quantity and quality of data points, ability to arrange data points such that analysis can be done via machine learning.\n",
    "\n",
    "## Important Notes\n",
    "This is not production quality code.  Code here is exploratory analytics code which needs to be wrapped up into proper functions as data differences and issues/exceptions are discovered.  This code can serve as reference for production code, but should not ever be treated as production code.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Key Libraries Required\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define data location & load data.\n",
    "base_dir = \"C:/Users/vmadmin/Documents/Work/spi/dataspi/\"\n",
    "good_file = \"GOOD_aug27_redo.csv\"\n",
    "bad_file = \"L7SPIresults_Defects_ONLY_query-impala-39690.csv\"\n",
    "\n",
    "good = pd.read_csv(base_dir + good_file)\n",
    "bad = pd.read_csv(base_dir + bad_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plcng_plant_cd</th>\n",
       "      <th>mach_id</th>\n",
       "      <th>pcb_side_inspd</th>\n",
       "      <th>wo_num</th>\n",
       "      <th>defct_dttm</th>\n",
       "      <th>intrvl_key</th>\n",
       "      <th>plcng_area_cd</th>\n",
       "      <th>plcng_prcs_cd</th>\n",
       "      <th>plcng_wrk_ctr_cd</th>\n",
       "      <th>fndng_plant_cd</th>\n",
       "      <th>...</th>\n",
       "      <th>pad_stncl_hgt</th>\n",
       "      <th>pad_spi_result</th>\n",
       "      <th>pad_spi_defct_type</th>\n",
       "      <th>solder_paste_vol_pct</th>\n",
       "      <th>solder_paste_hgt</th>\n",
       "      <th>solder_paste_area_pct</th>\n",
       "      <th>cmpnt_part_num</th>\n",
       "      <th>pkg_type</th>\n",
       "      <th>stncl_surf_area_ratio</th>\n",
       "      <th>extract_dttm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>127</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>113.5076</td>\n",
       "      <td>153.6871</td>\n",
       "      <td>93.79748</td>\n",
       "      <td>PN-27795-U5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>8/28/2018 2:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>127</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>105.2033</td>\n",
       "      <td>137.0668</td>\n",
       "      <td>97.47670</td>\n",
       "      <td>PN-27795-U5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>8/28/2018 2:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>127</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>106.6394</td>\n",
       "      <td>163.5016</td>\n",
       "      <td>82.83224</td>\n",
       "      <td>PN-27795-U5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>8/28/2018 2:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>127</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>113.9531</td>\n",
       "      <td>148.7802</td>\n",
       "      <td>97.27131</td>\n",
       "      <td>PN-27795-U5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>8/28/2018 2:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>127</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>110.2563</td>\n",
       "      <td>148.6627</td>\n",
       "      <td>94.19012</td>\n",
       "      <td>PN-27795-U5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>8/28/2018 2:54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   plcng_plant_cd  mach_id  pcb_side_inspd  wo_num  defct_dttm  intrvl_key  \\\n",
       "0             NaN      NaN             NaN     NaN         NaN         NaN   \n",
       "1             NaN      NaN             NaN     NaN         NaN         NaN   \n",
       "2             NaN      NaN             NaN     NaN         NaN         NaN   \n",
       "3             NaN      NaN             NaN     NaN         NaN         NaN   \n",
       "4             NaN      NaN             NaN     NaN         NaN         NaN   \n",
       "\n",
       "   plcng_area_cd  plcng_prcs_cd  plcng_wrk_ctr_cd  fndng_plant_cd  \\\n",
       "0            NaN            NaN               NaN             NaN   \n",
       "1            NaN            NaN               NaN             NaN   \n",
       "2            NaN            NaN               NaN             NaN   \n",
       "3            NaN            NaN               NaN             NaN   \n",
       "4            NaN            NaN               NaN             NaN   \n",
       "\n",
       "        ...        pad_stncl_hgt  pad_spi_result  pad_spi_defct_type  \\\n",
       "0       ...                  127            GOOD                GOOD   \n",
       "1       ...                  127            GOOD                GOOD   \n",
       "2       ...                  127            GOOD                GOOD   \n",
       "3       ...                  127            GOOD                GOOD   \n",
       "4       ...                  127            GOOD                GOOD   \n",
       "\n",
       "   solder_paste_vol_pct solder_paste_hgt  solder_paste_area_pct  \\\n",
       "0              113.5076         153.6871               93.79748   \n",
       "1              105.2033         137.0668               97.47670   \n",
       "2              106.6394         163.5016               82.83224   \n",
       "3              113.9531         148.7802               97.27131   \n",
       "4              110.2563         148.6627               94.19012   \n",
       "\n",
       "   cmpnt_part_num  pkg_type  stncl_surf_area_ratio    extract_dttm  \n",
       "0     PN-27795-U5         0                 0.9055  8/28/2018 2:54  \n",
       "1     PN-27795-U5         0                 0.9055  8/28/2018 2:54  \n",
       "2     PN-27795-U5         0                 0.9055  8/28/2018 2:54  \n",
       "3     PN-27795-U5         0                 0.9055  8/28/2018 2:54  \n",
       "4     PN-27795-U5         0                 0.9055  8/28/2018 2:54  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get a feel for what is in the data.\n",
    "good.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plcng_plant_cd</th>\n",
       "      <th>mach_id</th>\n",
       "      <th>pcb_side_inspd</th>\n",
       "      <th>wo_num</th>\n",
       "      <th>defct_dttm</th>\n",
       "      <th>intrvl_key</th>\n",
       "      <th>plcng_area_cd</th>\n",
       "      <th>plcng_prcs_cd</th>\n",
       "      <th>plcng_wrk_ctr_cd</th>\n",
       "      <th>fndng_plant_cd</th>\n",
       "      <th>...</th>\n",
       "      <th>solder_paste_offst_y_axis</th>\n",
       "      <th>pad_stncl_hgt</th>\n",
       "      <th>pad_spi_result</th>\n",
       "      <th>pad_spi_defct_type</th>\n",
       "      <th>solder_paste_vol_pct</th>\n",
       "      <th>solder_paste_hgt</th>\n",
       "      <th>solder_paste_area_pct</th>\n",
       "      <th>pkg_type</th>\n",
       "      <th>stncl_surf_area_ratio</th>\n",
       "      <th>extract_dttm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1020</td>\n",
       "      <td>FP9</td>\n",
       "      <td>TOP</td>\n",
       "      <td>4009351183</td>\n",
       "      <td>6/24/2018 15:56</td>\n",
       "      <td>1529855100</td>\n",
       "      <td>TWB_SM3</td>\n",
       "      <td>TWB_PCBA_SM3_TOP_FP</td>\n",
       "      <td>TWB_PCBA_TOP_FP9</td>\n",
       "      <td>1020</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.45</td>\n",
       "      <td>127</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>127.3716</td>\n",
       "      <td>165.5654</td>\n",
       "      <td>97.70272</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>7/4/2018 13:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1020</td>\n",
       "      <td>FP9</td>\n",
       "      <td>TOP</td>\n",
       "      <td>4009376503</td>\n",
       "      <td>7/3/2018 8:56</td>\n",
       "      <td>1530607500</td>\n",
       "      <td>TWB_SM3</td>\n",
       "      <td>TWB_PCBA_SM3_TOP_FP</td>\n",
       "      <td>TWB_PCBA_TOP_FP9</td>\n",
       "      <td>1020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.92</td>\n",
       "      <td>127</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>130.2810</td>\n",
       "      <td>159.0643</td>\n",
       "      <td>104.01890</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>7/4/2018 14:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1020</td>\n",
       "      <td>FP9</td>\n",
       "      <td>TOP</td>\n",
       "      <td>4009376503</td>\n",
       "      <td>7/3/2018 8:56</td>\n",
       "      <td>1530607500</td>\n",
       "      <td>TWB_SM3</td>\n",
       "      <td>TWB_PCBA_SM3_TOP_FP</td>\n",
       "      <td>TWB_PCBA_TOP_FP9</td>\n",
       "      <td>1020</td>\n",
       "      <td>...</td>\n",
       "      <td>4.82</td>\n",
       "      <td>127</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>132.1127</td>\n",
       "      <td>160.2906</td>\n",
       "      <td>104.67440</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>7/4/2018 14:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1020</td>\n",
       "      <td>FP9</td>\n",
       "      <td>TOP</td>\n",
       "      <td>4009376503</td>\n",
       "      <td>7/6/2018 14:51</td>\n",
       "      <td>1530888300</td>\n",
       "      <td>TWB_SM3</td>\n",
       "      <td>TWB_PCBA_SM3_TOP_FP</td>\n",
       "      <td>TWB_PCBA_TOP_FP9</td>\n",
       "      <td>1020</td>\n",
       "      <td>...</td>\n",
       "      <td>1.51</td>\n",
       "      <td>127</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>130.4016</td>\n",
       "      <td>170.2945</td>\n",
       "      <td>97.24921</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>7/4/2018 14:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1020</td>\n",
       "      <td>FP9</td>\n",
       "      <td>TOP</td>\n",
       "      <td>4009376503</td>\n",
       "      <td>7/6/2018 14:51</td>\n",
       "      <td>1530888300</td>\n",
       "      <td>TWB_SM3</td>\n",
       "      <td>TWB_PCBA_SM3_TOP_FP</td>\n",
       "      <td>TWB_PCBA_TOP_FP9</td>\n",
       "      <td>1020</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.27</td>\n",
       "      <td>127</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>123.9029</td>\n",
       "      <td>166.4613</td>\n",
       "      <td>94.53050</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>7/4/2018 14:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   plcng_plant_cd mach_id pcb_side_inspd      wo_num       defct_dttm  \\\n",
       "0            1020     FP9            TOP  4009351183  6/24/2018 15:56   \n",
       "1            1020     FP9            TOP  4009376503    7/3/2018 8:56   \n",
       "2            1020     FP9            TOP  4009376503    7/3/2018 8:56   \n",
       "3            1020     FP9            TOP  4009376503   7/6/2018 14:51   \n",
       "4            1020     FP9            TOP  4009376503   7/6/2018 14:51   \n",
       "\n",
       "   intrvl_key plcng_area_cd        plcng_prcs_cd  plcng_wrk_ctr_cd  \\\n",
       "0  1529855100       TWB_SM3  TWB_PCBA_SM3_TOP_FP  TWB_PCBA_TOP_FP9   \n",
       "1  1530607500       TWB_SM3  TWB_PCBA_SM3_TOP_FP  TWB_PCBA_TOP_FP9   \n",
       "2  1530607500       TWB_SM3  TWB_PCBA_SM3_TOP_FP  TWB_PCBA_TOP_FP9   \n",
       "3  1530888300       TWB_SM3  TWB_PCBA_SM3_TOP_FP  TWB_PCBA_TOP_FP9   \n",
       "4  1530888300       TWB_SM3  TWB_PCBA_SM3_TOP_FP  TWB_PCBA_TOP_FP9   \n",
       "\n",
       "   fndng_plant_cd       ...       solder_paste_offst_y_axis pad_stncl_hgt  \\\n",
       "0            1020       ...                          -11.45           127   \n",
       "1            1020       ...                            0.92           127   \n",
       "2            1020       ...                            4.82           127   \n",
       "3            1020       ...                            1.51           127   \n",
       "4            1020       ...                           -2.27           127   \n",
       "\n",
       "  pad_spi_result pad_spi_defct_type solder_paste_vol_pct solder_paste_hgt  \\\n",
       "0           GOOD               GOOD             127.3716         165.5654   \n",
       "1           GOOD               GOOD             130.2810         159.0643   \n",
       "2           GOOD               GOOD             132.1127         160.2906   \n",
       "3           GOOD               GOOD             130.4016         170.2945   \n",
       "4           GOOD               GOOD             123.9029         166.4613   \n",
       "\n",
       "  solder_paste_area_pct pkg_type stncl_surf_area_ratio    extract_dttm  \n",
       "0              97.70272        0                0.9055  7/4/2018 13:15  \n",
       "1             104.01890        0                0.9055  7/4/2018 14:17  \n",
       "2             104.67440        0                0.9055  7/4/2018 14:17  \n",
       "3              97.24921        0                0.9055  7/4/2018 14:19  \n",
       "4              94.53050        0                0.9055  7/4/2018 14:19  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get a feel for what is in the bad data\n",
    "bad.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89094, 39)\n",
      "(33700, 38)\n"
     ]
    }
   ],
   "source": [
    "#How many good/ bad do we have (pins)\n",
    "print(good.shape)\n",
    "print(bad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plcng_plant_cd' 'mach_id' 'pcb_side_inspd' 'wo_num' 'defct_dttm'\n",
      " 'intrvl_key' 'plcng_area_cd' 'plcng_prcs_cd' 'plcng_wrk_ctr_cd'\n",
      " 'fndng_plant_cd' 'fndng_area_cd' 'fndng_prcs_cd' 'bld_part_no'\n",
      " 'bld_serial_no' 'barcd' 'assy_part_no' 'assy_serial_no' 'defct_cd'\n",
      " 'failed_test_code' 'fail_type' 'cmpnt_part_no' 'spi_test_id' 'ref_id'\n",
      " 'silkscrn_nbr' 'cmpntpin_nbr' 'cmpntpin_size_x_axis'\n",
      " 'cmpntpin_size_y_axis' 'solder_paste_offst_x_axis'\n",
      " 'solder_paste_offst_y_axis' 'pad_stncl_hgt' 'pad_spi_result'\n",
      " 'pad_spi_defct_type' 'solder_paste_vol_pct' 'solder_paste_hgt'\n",
      " 'solder_paste_area_pct' 'cmpnt_part_num' 'pkg_type'\n",
      " 'stncl_surf_area_ratio' 'extract_dttm']\n",
      "['cmpnt_part_num']\n"
     ]
    }
   ],
   "source": [
    "# See what full list of columns are and if there is a difference in columns between the two\n",
    "print(good.columns.values)\n",
    "print(list(set(good) - set(bad)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cmpnt_part_num']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(good) - set(bad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(x):\n",
    "    r = x.split(\"-\") \n",
    "    if(len(r) > 2):\n",
    "        x = '-'.join(r[0:1])\n",
    "    return x\n",
    "bad[\"cmpnt_part_no\"] = bad[\"cmpnt_part_no\"].apply(lambda x: combine(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'00F01554', '00F4B44F', '00F6F7DB', '00F7DE52', '00F11F71', '00F6F799', '00F15471', '00F38E59', '00F87339', '00F11BC5', '00F5FD84', '00F7C4BD', '00F11AD9', '00F29AA2', '00F872D1', '00F11B29', '00F2970E', '00F40F3D', '00F11A77', '00F45F61', '00F40B7D', '00F151BF', '00F7C38B', '00F5FD50', '00F0BA04', '00F01822', '00F01806', '00F11C41', '00F11F8B', '00F5D9D9', '00F75A04', '00F015C0', '00F40BC9', '00F296AA', '00F29A28', '00F7C0F9', '00F86E67', '00F1562B', '00F7DED8', '00F21545', '00F11B0D', '00F7C077', '00F08C10', '00F40CAB', '00F0B9F4', '00F7C00F', '00F7BA65', '00F5DB75', '00F11BE7', '00F75C6A', '00F40F19', '00F11851', '00F75A70', '00F0B986', '00F019A4', '00F6F87D', '00F5D9D5', '00F409A1', '00F11909', '00F75A1C', '00F75C74', '00F69D9F', '00F7BBA3', '00F11ADD', '00F29678', '00F01584', '00F4B3F9', '00F39057', '00F0B7F2', '00F15277', '00F87211', '00F11D75', '00F38C71', '00F11AED', '00F87323', '00F5DA97', '00F407D7', '00F11AC7', '00F40B13', '00F29584', '00F4B2FB', '00F4B5DF', '00F75A7E', '00F0B9E8', '00F15667', '00F11D43', '00F11905', '00F407CF'}\n",
      "{1, 2}\n",
      "{'U26', 'U12', 'U20', 'U23', 'U6', 'U25', 'U11', 'U13', 'U4', 'U5'}\n",
      "{'PN-27724', 'PN-419257', '94474092', 'PN-31488', 'PN-27795', 'PN-271803', 'PN-29537', 'PN'}\n"
     ]
    }
   ],
   "source": [
    "print(set(bad[\"barcd\"]))\n",
    "print(set(bad[\"silkscrn_nbr\"]))\n",
    "print(set(bad[\"ref_id\"]))\n",
    "print(set(bad[\"cmpnt_part_no\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Bad Data and Get Data Counts For Each Component\n",
    "\n",
    "We need to get a feel for how much data we actually have and which components we have a decent shot of dealing with using standard machine learning approaches.\n",
    "\n",
    "It is possible to solve all components using non standard approaches; however deeper analysis will need to be done to validate the approaches which could be applied.  This should be done both at a theoretical and practical level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This looks at bad currently.  For good I need to change first groupby to use \"cmpnt_part_num not \"cmpnt_part_no\".\n",
    "bad_vals = []\n",
    "for k, v in bad.groupby(\"cmpnt_part_no\"):\n",
    "    for k, v1 in v.groupby(\"barcd\"):\n",
    "        for k, v2 in v1.groupby(\"silkscrn_nbr\"):\n",
    "            for k, v3 in v2.groupby(\"ref_id\"):\n",
    "                for k, v4 in v3.groupby(\"defct_dttm\"):\n",
    "                    vals = v4.sort_values(\"cmpntpin_nbr\")[[\"solder_paste_offst_x_axis\", \n",
    "                                                       \"solder_paste_offst_y_axis\", \n",
    "                                                       \"solder_paste_vol_pct\",\n",
    "                                                       \"solder_paste_hgt\",\n",
    "                                                       \"solder_paste_area_pct\",\n",
    "                                                        \"ref_id\",\n",
    "                                                        \"cmpntpin_nbr\",\n",
    "                                                        \"cmpnt_part_no\"]]\n",
    "                    addition = {\"defect\" : True, \"pin_data\" : vals, \n",
    "                                \"ref_id\" : list(set(v4[\"ref_id\"]))[0],\n",
    "                               \"cmpnt_part_no\" : list(set(v4[\"cmpnt_part_no\"]))[0]}\n",
    "                    bad_vals.append(addition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref id: PN-27724 count: 27\n",
      "ref id: PN-419257 count: 27\n",
      "ref id: 94474092 count: 31\n",
      "ref id: PN-31488 count: 23\n",
      "ref id: PN-27795 count: 34\n",
      "ref id: PN-271803 count: 10\n",
      "ref id: PN-29537 count: 6\n",
      "ref id: PN count: 3\n"
     ]
    }
   ],
   "source": [
    "ref_ids = list(set(bad[\"cmpnt_part_no\"]))\n",
    "for ref_id in ref_ids:\n",
    "    num_ids = len([x for x in bad_vals if x[\"cmpnt_part_no\"] == ref_id])\n",
    "    print(\"ref id: {} count: {}\".format(ref_id, num_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Good Data and Get Data Counts For Each Component\n",
    "\n",
    "We need to get a feel for how much data we actually have and which components we have a decent shot of dealing with using standard machine learning approaches.\n",
    "\n",
    "It is possible to solve all components using non standard approaches; however deeper analysis will need to be done to validate the approaches which could be applied.  This should be done both at a theoretical and practical level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This looks at bad currently.  For good I need to change first groupby to use \"cmpnt_part_num not \"cmpnt_part_no\".\n",
    "#good[\"cmpnt_part_num\"] = good[\"cmpnt_part_num\"].apply(lambda x: combine(x))\n",
    "good_vals = []\n",
    "for k, v in good.groupby(\"cmpnt_part_num\"):\n",
    "    for k, v1 in v.groupby(\"barcd\"):\n",
    "        for k, v2 in v1.groupby(\"silkscrn_nbr\"):\n",
    "            for k, v3 in v2.groupby(\"ref_id\"):\n",
    "                for k, v4 in v3.groupby(\"spi_test_id\"):\n",
    "                    vals = v4.sort_values(\"cmpntpin_nbr\")[[\"solder_paste_offst_x_axis\", \n",
    "                                                       \"solder_paste_offst_y_axis\", \n",
    "                                                       \"solder_paste_vol_pct\",\n",
    "                                                       \"solder_paste_hgt\",\n",
    "                                                       \"solder_paste_area_pct\",\n",
    "                                                        \"ref_id\",\n",
    "                                                        \"cmpntpin_nbr\",\n",
    "                                                        \"cmpnt_part_num\"]]\n",
    "                    addition = {\"defect\" : False, \"pin_data\" : vals, \n",
    "                                \"ref_id\" : list(set(v4[\"ref_id\"]))[0],\n",
    "                               \"cmpnt_part_num\" : list(set(v4[\"cmpnt_part_num\"]))[0]}\n",
    "                    good_vals.append(addition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref id: PN-27795-U5 count: 62\n",
      "ref id: PN-27724 count: 62\n",
      "ref id: 94474092 count: 62\n",
      "ref id: 94485092 count: 186\n",
      "ref id: PN-271803 count: 186\n",
      "ref id: PN-31488-U6 count: 62\n"
     ]
    }
   ],
   "source": [
    "ref_ids = list(set(good[\"cmpnt_part_num\"]))\n",
    "for ref_id in ref_ids:\n",
    "    num_ids = len([x for x in good_vals if x[\"cmpnt_part_num\"] == ref_id])\n",
    "    print(\"ref id: {} count: {}\".format(ref_id, num_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Section - Get Numpy Arrays for what I Need\n",
    "\n",
    "This section is about extracting the numpy arrays for what we need and dealing with encoding stuff to numerical features if necessary.\n",
    "\n",
    "We are focusing on component PN-27795 which exists ONLY for ref_id U5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "good_27795 = [x for x in good_vals if x[\"cmpnt_part_num\"] == 'PN-271803']\n",
    "bad_27795 = [x for x in bad_vals if x[\"cmpnt_part_no\"] == 'PN-271803']\n",
    "\n",
    "print(len(good_27795))\n",
    "print(len(bad_27795))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'describe'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-73f7df073443>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgood_27795\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'describe'"
     ]
    }
   ],
   "source": [
    "good_27795.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_27795 = good_27795[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(good_27795))\n",
    "print(len(bad_27795))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(421,)\n",
      "(421,)\n"
     ]
    }
   ],
   "source": [
    "row_1 = good_27795[0][\"pin_data\"][[\"solder_paste_offst_x_axis\", \n",
    "                                                       \"solder_paste_offst_y_axis\", \n",
    "                                                       \"solder_paste_vol_pct\",\n",
    "                                                       \"solder_paste_hgt\",\n",
    "                                                       \"solder_paste_area_pct\"]].values.flatten()\n",
    "row_1 = np.append(row_1, [0])\n",
    "print(row_1.shape)\n",
    "row_2 = good_27795[1][\"pin_data\"][[\"solder_paste_offst_x_axis\", \n",
    "                                                       \"solder_paste_offst_y_axis\", \n",
    "                                                       \"solder_paste_vol_pct\",\n",
    "                                                       \"solder_paste_hgt\",\n",
    "                                                       \"solder_paste_area_pct\"]].values.flatten()\n",
    "row_2 = np.append(row_2, [0])\n",
    "print(row_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = np.vstack([row_1, row_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 421)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to Data Shapes for Training\n",
    "\n",
    "We will convert the good & bad to data shapes required for training and then do a train/test split to prep for a simplistic keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ml_data(row, is_good):\n",
    "    prep = row[\"pin_data\"][[\"solder_paste_offst_x_axis\", \n",
    "                            \"solder_paste_offst_y_axis\", \n",
    "                            \"solder_paste_vol_pct\",\n",
    "                            \"solder_paste_hgt\",\n",
    "                            \"solder_paste_area_pct\"]].values.flatten()\n",
    "    if(is_good):\n",
    "        prep = np.append(prep, [0.0])\n",
    "    else:\n",
    "        prep = np.append(prep, [1.0])\n",
    "    return prep\n",
    "\n",
    "good_complete_data = get_ml_data(good_27795.pop(0), is_good=True)\n",
    "for data in good_27795:\n",
    "    good_complete_data = np.vstack([good_complete_data, get_ml_data(data, is_good=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 421)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_complete_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_complete_data = get_ml_data(bad_27795.pop(0), is_good=False)\n",
    "for data in bad_27795:\n",
    "    bad_complete_data = np.vstack([bad_complete_data, get_ml_data(data, is_good=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 421)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_complete_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 420 into shape (16,16,5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-a77baf79e648>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbad_complete_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 420 into shape (16,16,5)"
     ]
    }
   ],
   "source": [
    "bad_complete_data[0][:-1].reshape(16,16,5)[:][:][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 421)\n"
     ]
    }
   ],
   "source": [
    "full_data = np.append(bad_complete_data, good_complete_data, axis=0)\n",
    "print(full_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 420)\n",
      "(30, 1)\n"
     ]
    }
   ],
   "source": [
    "#verify sizes for x vs y to extract input vs output.  Last column is the output or y value.\n",
    "print(full_data[:,:-1].shape)\n",
    "print(full_data[:,-1:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prep for ml learning\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 420)\n",
      "(15, 1)\n",
      "(15, 420)\n",
      "(15, 1)\n"
     ]
    }
   ],
   "source": [
    "x_t, x_v, y_t, y_v = train_test_split(full_data[:,:-1], full_data[:,-1:], test_size = 0.50)\n",
    "print(x_t.shape)\n",
    "print(y_t.shape)\n",
    "print(x_v.shape)\n",
    "print(y_v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_t_scaled = scaler.fit_transform(x_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01151067 -0.38258273  0.1978501  ...  0.87734942  0.58955527\n",
      "   0.4376862 ]\n",
      " [-0.40506608 -0.2570002   1.48125707 ...  2.38139035  0.48955193\n",
      "   2.5771568 ]\n",
      " [-0.78875519 -0.52719291 -0.56446829 ... -0.76943409 -1.9077474\n",
      "   1.50377731]\n",
      " ...\n",
      " [-0.50783995 -0.19420894  0.59877102 ... -1.35064317 -1.73068249\n",
      "   0.32798257]\n",
      " [-0.54620886 -0.18850064 -1.12210297 ...  0.63165815  0.05589836\n",
      "   0.78278563]\n",
      " [ 0.60211785  0.35188478 -0.41811778 ...  0.09161451 -1.25007361\n",
      "   1.82952129]]\n",
      "[[ -4.92     -8.4     112.1399  ... 116.2529  165.1933   89.37478]\n",
      " [ -7.96     -7.74    122.1835  ... 128.0414  164.1576   99.05883]\n",
      " [-10.76     -9.16    106.1742  ... 103.3456  139.3296   94.20031]\n",
      " ...\n",
      " [ -8.71     -7.41    115.2774  ...  98.79015 141.1634   88.87822]\n",
      " [ -8.99     -7.38    101.8103  ... 114.3272  159.6664   90.93683]\n",
      " [ -0.61     -4.54    107.3195  ... 110.0944  146.1409   95.67475]]\n",
      "[0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "x_v_scaled = scaler.transform(x_v)\n",
    "print(x_v_scaled)\n",
    "print(x_v)\n",
    "print(y_v.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical Machine Learning\n",
    "\n",
    "Lets set a benchmark with classical machine learning from scikit.  We should see some level of performance from this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC()\n",
    "svm.fit(x_t_scaled, y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_p = svm.predict(x_v_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.92      0.85        12\n",
      "        1.0       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.63      0.73      0.68        15\n",
      "\n",
      "[[11  1]\n",
      " [ 3  0]]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_v.flatten(), v_p))\n",
    "print(confusion_matrix(y_v.flatten(), v_p))\n",
    "print(v_p.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try a Random Forest Classifier\n",
    "\n",
    "Just another model to give a whirl at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(x_t_scaled, y_t)\n",
    "v_p = rfc.predict(x_v_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      1.00      0.89        12\n",
      "        1.0       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.64      0.80      0.71        15\n",
      "\n",
      "[[12  0]\n",
      " [ 3  0]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_v.flatten(), v_p))\n",
    "print(confusion_matrix(y_v.flatten(), v_p))\n",
    "print(v_p.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Dense Neural Network\n",
    "\n",
    "Lets give a shot at a dense neural network and see if we can get any decent results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers import Input, Dense, Dropout, Conv2D, Flatten, MaxPooling2D\n",
    "from keras.regularizers import L1L2\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 420)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15 samples, validate on 15 samples\n",
      "Epoch 1/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 4.8478 - binary_accuracy: 0.4000 - val_loss: 4.7559 - val_binary_accuracy: 0.6000\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 379us/step - loss: 4.5629 - binary_accuracy: 0.8667 - val_loss: 4.7254 - val_binary_accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 201us/step - loss: 4.4010 - binary_accuracy: 1.0000 - val_loss: 4.7127 - val_binary_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 266us/step - loss: 4.2958 - binary_accuracy: 1.0000 - val_loss: 4.7076 - val_binary_accuracy: 0.6667\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 200us/step - loss: 4.2192 - binary_accuracy: 1.0000 - val_loss: 4.7056 - val_binary_accuracy: 0.6667\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 200us/step - loss: 4.1583 - binary_accuracy: 1.0000 - val_loss: 4.7046 - val_binary_accuracy: 0.6667\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 312us/step - loss: 4.1063 - binary_accuracy: 1.0000 - val_loss: 4.7034 - val_binary_accuracy: 0.6667\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 267us/step - loss: 4.0594 - binary_accuracy: 1.0000 - val_loss: 4.7010 - val_binary_accuracy: 0.6667\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 475us/step - loss: 4.0154 - binary_accuracy: 1.0000 - val_loss: 4.6973 - val_binary_accuracy: 0.6667\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 334us/step - loss: 3.9732 - binary_accuracy: 1.0000 - val_loss: 4.6918 - val_binary_accuracy: 0.6667\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 333us/step - loss: 3.9319 - binary_accuracy: 1.0000 - val_loss: 4.6845 - val_binary_accuracy: 0.6667\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 333us/step - loss: 3.8912 - binary_accuracy: 1.0000 - val_loss: 4.6752 - val_binary_accuracy: 0.6667\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 267us/step - loss: 3.8505 - binary_accuracy: 1.0000 - val_loss: 4.6640 - val_binary_accuracy: 0.6667\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 408us/step - loss: 3.8097 - binary_accuracy: 1.0000 - val_loss: 4.6509 - val_binary_accuracy: 0.6667\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 333us/step - loss: 3.7688 - binary_accuracy: 1.0000 - val_loss: 4.6360 - val_binary_accuracy: 0.6667\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 400us/step - loss: 3.7278 - binary_accuracy: 1.0000 - val_loss: 4.6193 - val_binary_accuracy: 0.6667\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 267us/step - loss: 3.6866 - binary_accuracy: 1.0000 - val_loss: 4.6008 - val_binary_accuracy: 0.6667\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 267us/step - loss: 3.6452 - binary_accuracy: 1.0000 - val_loss: 4.5808 - val_binary_accuracy: 0.6667\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 267us/step - loss: 3.6036 - binary_accuracy: 1.0000 - val_loss: 4.5592 - val_binary_accuracy: 0.6667\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 266us/step - loss: 3.5619 - binary_accuracy: 1.0000 - val_loss: 4.5361 - val_binary_accuracy: 0.6667\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 200us/step - loss: 3.5201 - binary_accuracy: 1.0000 - val_loss: 4.5114 - val_binary_accuracy: 0.6667\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 267us/step - loss: 3.4781 - binary_accuracy: 1.0000 - val_loss: 4.4852 - val_binary_accuracy: 0.6667\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 268us/step - loss: 3.4360 - binary_accuracy: 1.0000 - val_loss: 4.4574 - val_binary_accuracy: 0.6667\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 200us/step - loss: 3.3933 - binary_accuracy: 1.0000 - val_loss: 4.4287 - val_binary_accuracy: 0.6667\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 473us/step - loss: 3.3511 - binary_accuracy: 1.0000 - val_loss: 4.3988 - val_binary_accuracy: 0.6667\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 333us/step - loss: 3.3090 - binary_accuracy: 1.0000 - val_loss: 4.3678 - val_binary_accuracy: 0.6667\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 600us/step - loss: 3.2668 - binary_accuracy: 1.0000 - val_loss: 4.3357 - val_binary_accuracy: 0.6667\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 333us/step - loss: 3.2246 - binary_accuracy: 1.0000 - val_loss: 4.3027 - val_binary_accuracy: 0.6667\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 265us/step - loss: 3.1824 - binary_accuracy: 1.0000 - val_loss: 4.2688 - val_binary_accuracy: 0.6667\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 253us/step - loss: 3.1404 - binary_accuracy: 1.0000 - val_loss: 4.2341 - val_binary_accuracy: 0.6667\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 467us/step - loss: 3.0985 - binary_accuracy: 1.0000 - val_loss: 4.1988 - val_binary_accuracy: 0.6667\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 333us/step - loss: 3.0567 - binary_accuracy: 1.0000 - val_loss: 4.1628 - val_binary_accuracy: 0.6667\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 267us/step - loss: 3.0151 - binary_accuracy: 1.0000 - val_loss: 4.1261 - val_binary_accuracy: 0.6667\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 333us/step - loss: 2.9736 - binary_accuracy: 1.0000 - val_loss: 4.0890 - val_binary_accuracy: 0.6667\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 267us/step - loss: 2.9323 - binary_accuracy: 1.0000 - val_loss: 4.0513 - val_binary_accuracy: 0.6667\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 267us/step - loss: 2.8913 - binary_accuracy: 1.0000 - val_loss: 4.0131 - val_binary_accuracy: 0.6667\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 333us/step - loss: 2.8504 - binary_accuracy: 1.0000 - val_loss: 3.9744 - val_binary_accuracy: 0.6667\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 140us/step - loss: 2.8098 - binary_accuracy: 1.0000 - val_loss: 3.9353 - val_binary_accuracy: 0.6667\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 240us/step - loss: 2.7694 - binary_accuracy: 1.0000 - val_loss: 3.8957 - val_binary_accuracy: 0.6667\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 267us/step - loss: 2.7293 - binary_accuracy: 1.0000 - val_loss: 3.8558 - val_binary_accuracy: 0.6667\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 267us/step - loss: 2.6894 - binary_accuracy: 1.0000 - val_loss: 3.8158 - val_binary_accuracy: 0.6667\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 333us/step - loss: 2.6498 - binary_accuracy: 1.0000 - val_loss: 3.7757 - val_binary_accuracy: 0.6667\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 333us/step - loss: 2.6103 - binary_accuracy: 1.0000 - val_loss: 3.7356 - val_binary_accuracy: 0.6667\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 266us/step - loss: 2.5711 - binary_accuracy: 1.0000 - val_loss: 3.6956 - val_binary_accuracy: 0.6667\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 266us/step - loss: 2.5321 - binary_accuracy: 1.0000 - val_loss: 3.6558 - val_binary_accuracy: 0.6667\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 333us/step - loss: 2.4934 - binary_accuracy: 1.0000 - val_loss: 3.6160 - val_binary_accuracy: 0.6667\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 333us/step - loss: 2.4549 - binary_accuracy: 1.0000 - val_loss: 3.5764 - val_binary_accuracy: 0.6667\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 467us/step - loss: 2.4168 - binary_accuracy: 1.0000 - val_loss: 3.5370 - val_binary_accuracy: 0.6667\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 326us/step - loss: 2.3790 - binary_accuracy: 1.0000 - val_loss: 3.4978 - val_binary_accuracy: 0.6667\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 268us/step - loss: 2.3416 - binary_accuracy: 1.0000 - val_loss: 3.4587 - val_binary_accuracy: 0.6667\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 266us/step - loss: 2.3045 - binary_accuracy: 1.0000 - val_loss: 3.4198 - val_binary_accuracy: 0.6667\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 400us/step - loss: 2.2678 - binary_accuracy: 1.0000 - val_loss: 3.3810 - val_binary_accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 800us/step - loss: 2.2315 - binary_accuracy: 1.0000 - val_loss: 3.3426 - val_binary_accuracy: 0.6667\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 267us/step - loss: 2.1955 - binary_accuracy: 1.0000 - val_loss: 3.3047 - val_binary_accuracy: 0.6667\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 200us/step - loss: 2.1599 - binary_accuracy: 1.0000 - val_loss: 3.2671 - val_binary_accuracy: 0.6667\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 200us/step - loss: 2.1246 - binary_accuracy: 1.0000 - val_loss: 3.2296 - val_binary_accuracy: 0.6667\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 267us/step - loss: 2.0896 - binary_accuracy: 1.0000 - val_loss: 3.1923 - val_binary_accuracy: 0.6667\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 333us/step - loss: 2.0550 - binary_accuracy: 1.0000 - val_loss: 3.1550 - val_binary_accuracy: 0.6667\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 266us/step - loss: 2.0207 - binary_accuracy: 1.0000 - val_loss: 3.1181 - val_binary_accuracy: 0.6667\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 288us/step - loss: 1.9868 - binary_accuracy: 1.0000 - val_loss: 3.0815 - val_binary_accuracy: 0.6667\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 267us/step - loss: 1.9533 - binary_accuracy: 1.0000 - val_loss: 3.0453 - val_binary_accuracy: 0.6667\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 200us/step - loss: 1.9202 - binary_accuracy: 1.0000 - val_loss: 3.0094 - val_binary_accuracy: 0.6667\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 200us/step - loss: 1.8874 - binary_accuracy: 1.0000 - val_loss: 2.9735 - val_binary_accuracy: 0.6667\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 199us/step - loss: 1.8548 - binary_accuracy: 1.0000 - val_loss: 2.9382 - val_binary_accuracy: 0.6667\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 266us/step - loss: 1.8227 - binary_accuracy: 1.0000 - val_loss: 2.9033 - val_binary_accuracy: 0.6667\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 200us/step - loss: 1.7911 - binary_accuracy: 1.0000 - val_loss: 2.8691 - val_binary_accuracy: 0.6667\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 466us/step - loss: 1.7598 - binary_accuracy: 1.0000 - val_loss: 2.8352 - val_binary_accuracy: 0.6667\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 400us/step - loss: 1.7289 - binary_accuracy: 1.0000 - val_loss: 2.8016 - val_binary_accuracy: 0.6667\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 333us/step - loss: 1.6984 - binary_accuracy: 1.0000 - val_loss: 2.7684 - val_binary_accuracy: 0.6667\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 266us/step - loss: 1.6682 - binary_accuracy: 1.0000 - val_loss: 2.7356 - val_binary_accuracy: 0.6667\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 334us/step - loss: 1.6384 - binary_accuracy: 1.0000 - val_loss: 2.7034 - val_binary_accuracy: 0.6667\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 270us/step - loss: 1.6090 - binary_accuracy: 1.0000 - val_loss: 2.6714 - val_binary_accuracy: 0.6667\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 267us/step - loss: 1.5800 - binary_accuracy: 1.0000 - val_loss: 2.6397 - val_binary_accuracy: 0.6667\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 333us/step - loss: 1.5512 - binary_accuracy: 1.0000 - val_loss: 2.6085 - val_binary_accuracy: 0.6667\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 267us/step - loss: 1.5229 - binary_accuracy: 1.0000 - val_loss: 2.5776 - val_binary_accuracy: 0.6667\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 261us/step - loss: 1.4951 - binary_accuracy: 1.0000 - val_loss: 2.5470 - val_binary_accuracy: 0.6667\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 267us/step - loss: 1.4676 - binary_accuracy: 1.0000 - val_loss: 2.5167 - val_binary_accuracy: 0.6667\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 200us/step - loss: 1.4406 - binary_accuracy: 1.0000 - val_loss: 2.4872 - val_binary_accuracy: 0.6667\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 266us/step - loss: 1.4139 - binary_accuracy: 1.0000 - val_loss: 2.4580 - val_binary_accuracy: 0.6667\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 256us/step - loss: 1.3876 - binary_accuracy: 1.0000 - val_loss: 2.4296 - val_binary_accuracy: 0.6667\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 267us/step - loss: 1.3618 - binary_accuracy: 1.0000 - val_loss: 2.4019 - val_binary_accuracy: 0.6667\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 267us/step - loss: 1.3364 - binary_accuracy: 1.0000 - val_loss: 2.3749 - val_binary_accuracy: 0.6667\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 269us/step - loss: 1.3114 - binary_accuracy: 1.0000 - val_loss: 2.3484 - val_binary_accuracy: 0.6667\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 267us/step - loss: 1.2868 - binary_accuracy: 1.0000 - val_loss: 2.3227 - val_binary_accuracy: 0.6667\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 267us/step - loss: 1.2626 - binary_accuracy: 1.0000 - val_loss: 2.2977 - val_binary_accuracy: 0.6667\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 202us/step - loss: 1.2386 - binary_accuracy: 1.0000 - val_loss: 2.2733 - val_binary_accuracy: 0.6667\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 266us/step - loss: 1.2151 - binary_accuracy: 1.0000 - val_loss: 2.2494 - val_binary_accuracy: 0.6667\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 200us/step - loss: 1.1920 - binary_accuracy: 1.0000 - val_loss: 2.2259 - val_binary_accuracy: 0.6667\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 267us/step - loss: 1.1692 - binary_accuracy: 1.0000 - val_loss: 2.2033 - val_binary_accuracy: 0.6667\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 333us/step - loss: 1.1470 - binary_accuracy: 1.0000 - val_loss: 2.1813 - val_binary_accuracy: 0.6667\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 267us/step - loss: 1.1207 - binary_accuracy: 1.0000 - val_loss: 2.1596 - val_binary_accuracy: 0.6667\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 266us/step - loss: 1.1038 - binary_accuracy: 1.0000 - val_loss: 2.1382 - val_binary_accuracy: 0.6667\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 333us/step - loss: 1.0828 - binary_accuracy: 1.0000 - val_loss: 2.1171 - val_binary_accuracy: 0.6667\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 267us/step - loss: 1.0623 - binary_accuracy: 1.0000 - val_loss: 2.0963 - val_binary_accuracy: 0.6667\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 266us/step - loss: 1.0420 - binary_accuracy: 1.0000 - val_loss: 2.0760 - val_binary_accuracy: 0.6667\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 200us/step - loss: 1.0223 - binary_accuracy: 1.0000 - val_loss: 2.0565 - val_binary_accuracy: 0.6667\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 200us/step - loss: 1.0028 - binary_accuracy: 1.0000 - val_loss: 2.0375 - val_binary_accuracy: 0.6667\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 204us/step - loss: 0.9837 - binary_accuracy: 1.0000 - val_loss: 2.0183 - val_binary_accuracy: 0.6667\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 334us/step - loss: 0.9649 - binary_accuracy: 1.0000 - val_loss: 1.9992 - val_binary_accuracy: 0.6667\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 288us/step - loss: 0.9467 - binary_accuracy: 1.0000 - val_loss: 1.9804 - val_binary_accuracy: 0.6667\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "INPUT_SIZE = (420,)\n",
    "reg_rate = 0.001\n",
    "model_in = Input(shape=INPUT_SIZE)\n",
    "classifier = Dense(128, activation=\"tanh\", kernel_regularizer=L1L2(l1=reg_rate, l2=reg_rate))(model_in)\n",
    "classifier = Dense(64, activation=\"tanh\", kernel_regularizer=L1L2(l1=reg_rate, l2=reg_rate))(classifier)\n",
    "classifier = Dense(32, activation=\"tanh\", kernel_regularizer=L1L2(l1=reg_rate, l2=reg_rate))(classifier)\n",
    "#classifier = Dropout(0.5)(classifier)\n",
    "classifier = Dense(1, activation=\"sigmoid\", kernel_regularizer=L1L2(l1=reg_rate, l2=reg_rate))(classifier)\n",
    "\n",
    "model = Model(inputs=[model_in], outputs=[classifier])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"binary_accuracy\"])\n",
    "\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "callbacks = [ EarlyStopping(monitor=\"loss\", patience=50, min_delta=0.0)]\n",
    "\n",
    "evaluation = model.fit(x_t_scaled, y_t, shuffle=True,\n",
    "                        epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1,\n",
    "                        validation_data = (x_v_scaled, y_v),\n",
    "                        callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.77      0.83      0.80        12\n",
      "        1.0       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.62      0.67      0.64        15\n",
      "\n",
      "[[10  2]\n",
      " [ 3  0]]\n",
      "[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "v_p_k = model.predict(x_v_scaled)\n",
    "v_p_k = [1.0 if v  >= 0.5 else 0.0 for v in v_p_k]\n",
    "print(classification_report(y_v.flatten(), v_p_k))\n",
    "print(confusion_matrix(y_v.flatten(), v_p_k))\n",
    "print(v_p_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Sequential Model Compostion\n",
    "\n",
    "Same as above just with sequential model composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.5595 - binary_accuracy: 0.8000\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 404us/step - loss: 0.2596 - binary_accuracy: 0.9333\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 852us/step - loss: 0.1463 - binary_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 337us/step - loss: 0.0893 - binary_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 332us/step - loss: 0.0541 - binary_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 401us/step - loss: 0.0346 - binary_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 733us/step - loss: 0.0215 - binary_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 0s 533us/step - loss: 0.0151 - binary_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 0s 467us/step - loss: 0.0099 - binary_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 0s 348us/step - loss: 0.0073 - binary_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128,activation=\"relu\",input_shape=(x_t.shape[1],)))\n",
    "model.add(Dense(64,activation=\"relu\"))\n",
    "model.add(Dense(32,activation=\"relu\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"binary_accuracy\"])\n",
    "\n",
    "epoch_count=10\n",
    "batch_size=10\n",
    "\n",
    "history = model.fit(x=x_t_scaled,y=y_t,batch_size=batch_size,epochs=epoch_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.92      0.85        12\n",
      "        1.0       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.63      0.73      0.68        15\n",
      "\n",
      "[[11  1]\n",
      " [ 3  0]]\n",
      "[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "v_p_k = model.predict(x_v_scaled)\n",
    "v_p_k = [1.0 if v  >= 0.5 else 0.0 for v in v_p_k]\n",
    "print(classification_report(y_v.flatten(), v_p_k))\n",
    "print(confusion_matrix(y_v.flatten(), v_p_k))\n",
    "print(v_p_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Convolutional Neural Network\n",
    "\n",
    "As the problem may be a pattern problem; lets give a whirl at a convolutional network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 420)\n",
      "(15, 1)\n",
      "(15, 420)\n",
      "(15, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_t.shape)\n",
    "print(y_t.shape)\n",
    "print(x_v.shape)\n",
    "print(y_v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t_c = x_t_scaled.reshape(15, 14, 6, 5)\n",
    "x_v_c = x_v_scaled.reshape(15, 14, 6, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = (14, 6, 5)\n",
    "reg_rate = 0.001\n",
    "model_in = Input(shape=INPUT_SIZE)\n",
    "classifier = Conv2D(128, (3,3), activation=\"tanh\", kernel_regularizer=L1L2(l1=reg_rate, l2=reg_rate))(model_in)\n",
    "classifier = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(classifier)\n",
    "classifier = Conv2D(64, (2,2), activation=\"tanh\", kernel_regularizer=L1L2(l1=reg_rate, l2=reg_rate))(classifier)\n",
    "#classifier = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(classifier)\n",
    "classifier = Flatten()(classifier)\n",
    "classifier = Dense(1, activation=\"sigmoid\", kernel_regularizer=L1L2(l1=reg_rate, l2=reg_rate))(classifier)\n",
    "\n",
    "model = Model(inputs=[model_in], outputs=[classifier])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15 samples, validate on 15 samples\n",
      "Epoch 1/200\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 2.4251 - acc: 0.5333 - val_loss: 2.3995 - val_acc: 0.7333\n",
      "Epoch 2/200\n",
      "15/15 [==============================] - 0s 464us/step - loss: 2.2427 - acc: 0.8667 - val_loss: 2.4042 - val_acc: 0.7333\n",
      "Epoch 3/200\n",
      "15/15 [==============================] - 0s 397us/step - loss: 2.1282 - acc: 0.9333 - val_loss: 2.3923 - val_acc: 0.7333\n",
      "Epoch 4/200\n",
      "15/15 [==============================] - 0s 397us/step - loss: 2.0430 - acc: 1.0000 - val_loss: 2.3817 - val_acc: 0.7333\n",
      "Epoch 5/200\n",
      "15/15 [==============================] - 0s 467us/step - loss: 1.9752 - acc: 1.0000 - val_loss: 2.3802 - val_acc: 0.7333\n",
      "Epoch 6/200\n",
      "15/15 [==============================] - 0s 531us/step - loss: 1.9202 - acc: 1.0000 - val_loss: 2.3854 - val_acc: 0.7333\n",
      "Epoch 7/200\n",
      "15/15 [==============================] - 0s 472us/step - loss: 1.8739 - acc: 1.0000 - val_loss: 2.3924 - val_acc: 0.7333\n",
      "Epoch 8/200\n",
      "15/15 [==============================] - 0s 467us/step - loss: 1.8331 - acc: 1.0000 - val_loss: 2.3983 - val_acc: 0.7333\n",
      "Epoch 9/200\n",
      "15/15 [==============================] - 0s 472us/step - loss: 1.7964 - acc: 1.0000 - val_loss: 2.4017 - val_acc: 0.7333\n",
      "Epoch 10/200\n",
      "15/15 [==============================] - 0s 464us/step - loss: 1.7632 - acc: 1.0000 - val_loss: 2.4027 - val_acc: 0.7333\n",
      "Epoch 11/200\n",
      "15/15 [==============================] - 0s 466us/step - loss: 1.7330 - acc: 1.0000 - val_loss: 2.4017 - val_acc: 0.7333\n",
      "Epoch 12/200\n",
      "15/15 [==============================] - 0s 467us/step - loss: 1.7055 - acc: 1.0000 - val_loss: 2.3985 - val_acc: 0.7333\n",
      "Epoch 13/200\n",
      "15/15 [==============================] - 0s 602us/step - loss: 1.6799 - acc: 1.0000 - val_loss: 2.3936 - val_acc: 0.7333\n",
      "Epoch 14/200\n",
      "15/15 [==============================] - 0s 467us/step - loss: 1.6556 - acc: 1.0000 - val_loss: 2.3872 - val_acc: 0.7333\n",
      "Epoch 15/200\n",
      "15/15 [==============================] - 0s 467us/step - loss: 1.6322 - acc: 1.0000 - val_loss: 2.3793 - val_acc: 0.7333\n",
      "Epoch 16/200\n",
      "15/15 [==============================] - 0s 476us/step - loss: 1.6095 - acc: 1.0000 - val_loss: 2.3704 - val_acc: 0.7333\n",
      "Epoch 17/200\n",
      "15/15 [==============================] - 0s 465us/step - loss: 1.5872 - acc: 1.0000 - val_loss: 2.3604 - val_acc: 0.7333\n",
      "Epoch 18/200\n",
      "15/15 [==============================] - 0s 152us/step - loss: 1.5650 - acc: 1.0000 - val_loss: 2.3495 - val_acc: 0.7333\n",
      "Epoch 19/200\n",
      "15/15 [==============================] - 0s 525us/step - loss: 1.5433 - acc: 1.0000 - val_loss: 2.3378 - val_acc: 0.7333\n",
      "Epoch 20/200\n",
      "15/15 [==============================] - 0s 474us/step - loss: 1.5216 - acc: 1.0000 - val_loss: 2.3250 - val_acc: 0.7333\n",
      "Epoch 21/200\n",
      "15/15 [==============================] - 0s 466us/step - loss: 1.4999 - acc: 1.0000 - val_loss: 2.3113 - val_acc: 0.7333\n",
      "Epoch 22/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 1.4783 - acc: 1.0000 - val_loss: 2.2967 - val_acc: 0.7333\n",
      "Epoch 23/200\n",
      "15/15 [==============================] - 0s 467us/step - loss: 1.4567 - acc: 1.0000 - val_loss: 2.2811 - val_acc: 0.7333\n",
      "Epoch 24/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 1.4350 - acc: 1.0000 - val_loss: 2.2644 - val_acc: 0.7333\n",
      "Epoch 25/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 1.4134 - acc: 1.0000 - val_loss: 2.2468 - val_acc: 0.7333\n",
      "Epoch 26/200\n",
      "15/15 [==============================] - 0s 466us/step - loss: 1.3917 - acc: 1.0000 - val_loss: 2.2283 - val_acc: 0.7333\n",
      "Epoch 27/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 1.3701 - acc: 1.0000 - val_loss: 2.2091 - val_acc: 0.7333\n",
      "Epoch 28/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 1.3485 - acc: 1.0000 - val_loss: 2.1891 - val_acc: 0.7333\n",
      "Epoch 29/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 1.3270 - acc: 1.0000 - val_loss: 2.1685 - val_acc: 0.7333\n",
      "Epoch 30/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 1.3055 - acc: 1.0000 - val_loss: 2.1473 - val_acc: 0.7333\n",
      "Epoch 31/200\n",
      "15/15 [==============================] - 0s 467us/step - loss: 1.2841 - acc: 1.0000 - val_loss: 2.1258 - val_acc: 0.7333\n",
      "Epoch 32/200\n",
      "15/15 [==============================] - 0s 402us/step - loss: 1.2629 - acc: 1.0000 - val_loss: 2.1040 - val_acc: 0.7333\n",
      "Epoch 33/200\n",
      "15/15 [==============================] - 0s 470us/step - loss: 1.2417 - acc: 1.0000 - val_loss: 2.0818 - val_acc: 0.7333\n",
      "Epoch 34/200\n",
      "15/15 [==============================] - 0s 467us/step - loss: 1.2206 - acc: 1.0000 - val_loss: 2.0595 - val_acc: 0.7333\n",
      "Epoch 35/200\n",
      "15/15 [==============================] - 0s 600us/step - loss: 1.1996 - acc: 1.0000 - val_loss: 2.0368 - val_acc: 0.7333\n",
      "Epoch 36/200\n",
      "15/15 [==============================] - 0s 533us/step - loss: 1.1788 - acc: 1.0000 - val_loss: 2.0140 - val_acc: 0.7333\n",
      "Epoch 37/200\n",
      "15/15 [==============================] - 0s 467us/step - loss: 1.1581 - acc: 1.0000 - val_loss: 1.9913 - val_acc: 0.7333\n",
      "Epoch 38/200\n",
      "15/15 [==============================] - 0s 334us/step - loss: 1.1376 - acc: 1.0000 - val_loss: 1.9686 - val_acc: 0.7333\n",
      "Epoch 39/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 1.1173 - acc: 1.0000 - val_loss: 1.9461 - val_acc: 0.7333\n",
      "Epoch 40/200\n",
      "15/15 [==============================] - 0s 467us/step - loss: 1.0973 - acc: 1.0000 - val_loss: 1.9237 - val_acc: 0.7333\n",
      "Epoch 41/200\n",
      "15/15 [==============================] - 0s 600us/step - loss: 1.0775 - acc: 1.0000 - val_loss: 1.9014 - val_acc: 0.7333\n",
      "Epoch 42/200\n",
      "15/15 [==============================] - 0s 534us/step - loss: 1.0579 - acc: 1.0000 - val_loss: 1.8792 - val_acc: 0.7333\n",
      "Epoch 43/200\n",
      "15/15 [==============================] - 0s 466us/step - loss: 1.0383 - acc: 1.0000 - val_loss: 1.8574 - val_acc: 0.7333\n",
      "Epoch 44/200\n",
      "15/15 [==============================] - 0s 467us/step - loss: 1.0191 - acc: 1.0000 - val_loss: 1.8359 - val_acc: 0.7333\n",
      "Epoch 45/200\n",
      "15/15 [==============================] - 0s 333us/step - loss: 1.0002 - acc: 1.0000 - val_loss: 1.8147 - val_acc: 0.7333\n",
      "Epoch 46/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.9815 - acc: 1.0000 - val_loss: 1.7938 - val_acc: 0.7333\n",
      "Epoch 47/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.9630 - acc: 1.0000 - val_loss: 1.7732 - val_acc: 0.7333\n",
      "Epoch 48/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.9448 - acc: 1.0000 - val_loss: 1.7528 - val_acc: 0.7333\n",
      "Epoch 49/200\n",
      "15/15 [==============================] - 0s 333us/step - loss: 0.9268 - acc: 1.0000 - val_loss: 1.7328 - val_acc: 0.7333\n",
      "Epoch 50/200\n",
      "15/15 [==============================] - 0s 467us/step - loss: 0.9090 - acc: 1.0000 - val_loss: 1.7132 - val_acc: 0.7333\n",
      "Epoch 51/200\n",
      "15/15 [==============================] - 0s 800us/step - loss: 0.8914 - acc: 1.0000 - val_loss: 1.6939 - val_acc: 0.7333\n",
      "Epoch 52/200\n",
      "15/15 [==============================] - 0s 533us/step - loss: 0.8741 - acc: 1.0000 - val_loss: 1.6751 - val_acc: 0.7333\n",
      "Epoch 53/200\n",
      "15/15 [==============================] - 0s 467us/step - loss: 0.8570 - acc: 1.0000 - val_loss: 1.6566 - val_acc: 0.7333\n",
      "Epoch 54/200\n",
      "15/15 [==============================] - 0s 467us/step - loss: 0.8402 - acc: 1.0000 - val_loss: 1.6387 - val_acc: 0.7333\n",
      "Epoch 55/200\n",
      "15/15 [==============================] - 0s 374us/step - loss: 0.8236 - acc: 1.0000 - val_loss: 1.6212 - val_acc: 0.7333\n",
      "Epoch 56/200\n",
      "15/15 [==============================] - 0s 467us/step - loss: 0.8072 - acc: 1.0000 - val_loss: 1.6043 - val_acc: 0.7333\n",
      "Epoch 57/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.7912 - acc: 1.0000 - val_loss: 1.5880 - val_acc: 0.7333\n",
      "Epoch 58/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.7754 - acc: 1.0000 - val_loss: 1.5720 - val_acc: 0.7333\n",
      "Epoch 59/200\n",
      "15/15 [==============================] - 0s 399us/step - loss: 0.7599 - acc: 1.0000 - val_loss: 1.5565 - val_acc: 0.7333\n",
      "Epoch 60/200\n",
      "15/15 [==============================] - 0s 533us/step - loss: 0.7447 - acc: 1.0000 - val_loss: 1.5413 - val_acc: 0.7333\n",
      "Epoch 61/200\n",
      "15/15 [==============================] - 0s 468us/step - loss: 0.7297 - acc: 1.0000 - val_loss: 1.5266 - val_acc: 0.7333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/200\n",
      "15/15 [==============================] - 0s 467us/step - loss: 0.7150 - acc: 1.0000 - val_loss: 1.5122 - val_acc: 0.7333\n",
      "Epoch 63/200\n",
      "15/15 [==============================] - 0s 401us/step - loss: 0.7004 - acc: 1.0000 - val_loss: 1.4983 - val_acc: 0.7333\n",
      "Epoch 64/200\n",
      "15/15 [==============================] - 0s 381us/step - loss: 0.6862 - acc: 1.0000 - val_loss: 1.4847 - val_acc: 0.7333\n",
      "Epoch 65/200\n",
      "15/15 [==============================] - 0s 467us/step - loss: 0.6721 - acc: 1.0000 - val_loss: 1.4716 - val_acc: 0.7333\n",
      "Epoch 66/200\n",
      "15/15 [==============================] - 0s 401us/step - loss: 0.6583 - acc: 1.0000 - val_loss: 1.4589 - val_acc: 0.7333\n",
      "Epoch 67/200\n",
      "15/15 [==============================] - 0s 467us/step - loss: 0.6446 - acc: 1.0000 - val_loss: 1.4468 - val_acc: 0.7333\n",
      "Epoch 68/200\n",
      "15/15 [==============================] - 0s 534us/step - loss: 0.6313 - acc: 1.0000 - val_loss: 1.4352 - val_acc: 0.7333\n",
      "Epoch 69/200\n",
      "15/15 [==============================] - 0s 466us/step - loss: 0.6182 - acc: 1.0000 - val_loss: 1.4240 - val_acc: 0.7333\n",
      "Epoch 70/200\n",
      "15/15 [==============================] - 0s 533us/step - loss: 0.6053 - acc: 1.0000 - val_loss: 1.4133 - val_acc: 0.7333\n",
      "Epoch 71/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.5928 - acc: 1.0000 - val_loss: 1.4031 - val_acc: 0.6667\n",
      "Epoch 72/200\n",
      "15/15 [==============================] - 0s 411us/step - loss: 0.5805 - acc: 1.0000 - val_loss: 1.3934 - val_acc: 0.6667\n",
      "Epoch 73/200\n",
      "15/15 [==============================] - 0s 467us/step - loss: 0.5684 - acc: 1.0000 - val_loss: 1.3841 - val_acc: 0.6667\n",
      "Epoch 74/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.5567 - acc: 1.0000 - val_loss: 1.3751 - val_acc: 0.6667\n",
      "Epoch 75/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.5453 - acc: 1.0000 - val_loss: 1.3664 - val_acc: 0.6667\n",
      "Epoch 76/200\n",
      "15/15 [==============================] - 0s 467us/step - loss: 0.5341 - acc: 1.0000 - val_loss: 1.3579 - val_acc: 0.6667\n",
      "Epoch 77/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.5232 - acc: 1.0000 - val_loss: 1.3496 - val_acc: 0.6667\n",
      "Epoch 78/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.5125 - acc: 1.0000 - val_loss: 1.3413 - val_acc: 0.6667\n",
      "Epoch 79/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.5020 - acc: 1.0000 - val_loss: 1.3333 - val_acc: 0.6667\n",
      "Epoch 80/200\n",
      "15/15 [==============================] - 0s 467us/step - loss: 0.4918 - acc: 1.0000 - val_loss: 1.3256 - val_acc: 0.6667\n",
      "Epoch 81/200\n",
      "15/15 [==============================] - 0s 399us/step - loss: 0.4820 - acc: 1.0000 - val_loss: 1.3181 - val_acc: 0.6667\n",
      "Epoch 82/200\n",
      "15/15 [==============================] - 0s 467us/step - loss: 0.4723 - acc: 1.0000 - val_loss: 1.3110 - val_acc: 0.6667\n",
      "Epoch 83/200\n",
      "15/15 [==============================] - 0s 333us/step - loss: 0.4629 - acc: 1.0000 - val_loss: 1.3043 - val_acc: 0.6667\n",
      "Epoch 84/200\n",
      "15/15 [==============================] - 0s 464us/step - loss: 0.4538 - acc: 1.0000 - val_loss: 1.2980 - val_acc: 0.6667\n",
      "Epoch 85/200\n",
      "15/15 [==============================] - 0s 466us/step - loss: 0.4450 - acc: 1.0000 - val_loss: 1.2922 - val_acc: 0.6667\n",
      "Epoch 86/200\n",
      "15/15 [==============================] - 0s 467us/step - loss: 0.4364 - acc: 1.0000 - val_loss: 1.2866 - val_acc: 0.6000\n",
      "Epoch 87/200\n",
      "15/15 [==============================] - 0s 334us/step - loss: 0.4281 - acc: 1.0000 - val_loss: 1.2813 - val_acc: 0.6000\n",
      "Epoch 88/200\n",
      "15/15 [==============================] - 0s 333us/step - loss: 0.4201 - acc: 1.0000 - val_loss: 1.2762 - val_acc: 0.6000\n",
      "Epoch 89/200\n",
      "15/15 [==============================] - 0s 405us/step - loss: 0.4124 - acc: 1.0000 - val_loss: 1.2711 - val_acc: 0.6000\n",
      "Epoch 90/200\n",
      "15/15 [==============================] - 0s 466us/step - loss: 0.4048 - acc: 1.0000 - val_loss: 1.2660 - val_acc: 0.6000\n",
      "Epoch 91/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.3975 - acc: 1.0000 - val_loss: 1.2611 - val_acc: 0.6000\n",
      "Epoch 92/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.3903 - acc: 1.0000 - val_loss: 1.2564 - val_acc: 0.6000\n",
      "Epoch 93/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.3833 - acc: 1.0000 - val_loss: 1.2521 - val_acc: 0.6000\n",
      "Epoch 94/200\n",
      "15/15 [==============================] - 0s 445us/step - loss: 0.3765 - acc: 1.0000 - val_loss: 1.2481 - val_acc: 0.6000\n",
      "Epoch 95/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.3700 - acc: 1.0000 - val_loss: 1.2443 - val_acc: 0.6000\n",
      "Epoch 96/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.3637 - acc: 1.0000 - val_loss: 1.2407 - val_acc: 0.6000\n",
      "Epoch 97/200\n",
      "15/15 [==============================] - 0s 332us/step - loss: 0.3576 - acc: 1.0000 - val_loss: 1.2373 - val_acc: 0.6000\n",
      "Epoch 98/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.3517 - acc: 1.0000 - val_loss: 1.2339 - val_acc: 0.6000\n",
      "Epoch 99/200\n",
      "15/15 [==============================] - 0s 467us/step - loss: 0.3460 - acc: 1.0000 - val_loss: 1.2308 - val_acc: 0.6000\n",
      "Epoch 100/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.3406 - acc: 1.0000 - val_loss: 1.2278 - val_acc: 0.6000\n",
      "Epoch 101/200\n",
      "15/15 [==============================] - 0s 398us/step - loss: 0.3354 - acc: 1.0000 - val_loss: 1.2249 - val_acc: 0.6000\n",
      "Epoch 102/200\n",
      "15/15 [==============================] - 0s 467us/step - loss: 0.3303 - acc: 1.0000 - val_loss: 1.2220 - val_acc: 0.6000\n",
      "Epoch 103/200\n",
      "15/15 [==============================] - 0s 399us/step - loss: 0.3254 - acc: 1.0000 - val_loss: 1.2192 - val_acc: 0.6000\n",
      "Epoch 104/200\n",
      "15/15 [==============================] - 0s 468us/step - loss: 0.3207 - acc: 1.0000 - val_loss: 1.2166 - val_acc: 0.6000\n",
      "Epoch 105/200\n",
      "15/15 [==============================] - 0s 399us/step - loss: 0.3161 - acc: 1.0000 - val_loss: 1.2141 - val_acc: 0.6000\n",
      "Epoch 106/200\n",
      "15/15 [==============================] - 0s 466us/step - loss: 0.3116 - acc: 1.0000 - val_loss: 1.2118 - val_acc: 0.6000\n",
      "Epoch 107/200\n",
      "15/15 [==============================] - 0s 404us/step - loss: 0.3073 - acc: 1.0000 - val_loss: 1.2096 - val_acc: 0.6000\n",
      "Epoch 108/200\n",
      "15/15 [==============================] - 0s 463us/step - loss: 0.3032 - acc: 1.0000 - val_loss: 1.2075 - val_acc: 0.6000\n",
      "Epoch 109/200\n",
      "15/15 [==============================] - 0s 403us/step - loss: 0.2992 - acc: 1.0000 - val_loss: 1.2056 - val_acc: 0.6000\n",
      "Epoch 110/200\n",
      "15/15 [==============================] - 0s 397us/step - loss: 0.2954 - acc: 1.0000 - val_loss: 1.2038 - val_acc: 0.6000\n",
      "Epoch 111/200\n",
      "15/15 [==============================] - 0s 467us/step - loss: 0.2917 - acc: 1.0000 - val_loss: 1.2023 - val_acc: 0.6000\n",
      "Epoch 112/200\n",
      "15/15 [==============================] - 0s 467us/step - loss: 0.2880 - acc: 1.0000 - val_loss: 1.2012 - val_acc: 0.6000\n",
      "Epoch 113/200\n",
      "15/15 [==============================] - 0s 399us/step - loss: 0.2845 - acc: 1.0000 - val_loss: 1.2003 - val_acc: 0.6000\n",
      "Epoch 114/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.2811 - acc: 1.0000 - val_loss: 1.1999 - val_acc: 0.6000\n",
      "Epoch 115/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.2778 - acc: 1.0000 - val_loss: 1.1998 - val_acc: 0.6000\n",
      "Epoch 116/200\n",
      "15/15 [==============================] - 0s 467us/step - loss: 0.2746 - acc: 1.0000 - val_loss: 1.1996 - val_acc: 0.6000\n",
      "Epoch 117/200\n",
      "15/15 [==============================] - 0s 602us/step - loss: 0.2715 - acc: 1.0000 - val_loss: 1.1993 - val_acc: 0.6000\n",
      "Epoch 118/200\n",
      "15/15 [==============================] - 0s 466us/step - loss: 0.2685 - acc: 1.0000 - val_loss: 1.1990 - val_acc: 0.6000\n",
      "Epoch 119/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.2656 - acc: 1.0000 - val_loss: 1.1989 - val_acc: 0.6000\n",
      "Epoch 120/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.2627 - acc: 1.0000 - val_loss: 1.1991 - val_acc: 0.6000\n",
      "Epoch 121/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.2599 - acc: 1.0000 - val_loss: 1.1993 - val_acc: 0.6000\n",
      "Epoch 122/200\n",
      "15/15 [==============================] - 0s 470us/step - loss: 0.2572 - acc: 1.0000 - val_loss: 1.1996 - val_acc: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/200\n",
      "15/15 [==============================] - 0s 466us/step - loss: 0.2545 - acc: 1.0000 - val_loss: 1.2000 - val_acc: 0.6000\n",
      "Epoch 124/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.2520 - acc: 1.0000 - val_loss: 1.2006 - val_acc: 0.6000\n",
      "Epoch 125/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.2495 - acc: 1.0000 - val_loss: 1.2011 - val_acc: 0.6000\n",
      "Epoch 126/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.2471 - acc: 1.0000 - val_loss: 1.2013 - val_acc: 0.6000\n",
      "Epoch 127/200\n",
      "15/15 [==============================] - 0s 399us/step - loss: 0.2448 - acc: 1.0000 - val_loss: 1.2015 - val_acc: 0.6000\n",
      "Epoch 128/200\n",
      "15/15 [==============================] - 0s 467us/step - loss: 0.2425 - acc: 1.0000 - val_loss: 1.2019 - val_acc: 0.6000\n",
      "Epoch 129/200\n",
      "15/15 [==============================] - 0s 467us/step - loss: 0.2402 - acc: 1.0000 - val_loss: 1.2025 - val_acc: 0.6000\n",
      "Epoch 130/200\n",
      "15/15 [==============================] - 0s 467us/step - loss: 0.2381 - acc: 1.0000 - val_loss: 1.2032 - val_acc: 0.6000\n",
      "Epoch 131/200\n",
      "15/15 [==============================] - 0s 467us/step - loss: 0.2359 - acc: 1.0000 - val_loss: 1.2037 - val_acc: 0.6000\n",
      "Epoch 132/200\n",
      "15/15 [==============================] - 0s 467us/step - loss: 0.2339 - acc: 1.0000 - val_loss: 1.2042 - val_acc: 0.6000\n",
      "Epoch 133/200\n",
      "15/15 [==============================] - 0s 533us/step - loss: 0.2318 - acc: 1.0000 - val_loss: 1.2047 - val_acc: 0.6000\n",
      "Epoch 134/200\n",
      "15/15 [==============================] - 0s 402us/step - loss: 0.2298 - acc: 1.0000 - val_loss: 1.2051 - val_acc: 0.6000\n",
      "Epoch 135/200\n",
      "15/15 [==============================] - 0s 421us/step - loss: 0.2279 - acc: 1.0000 - val_loss: 1.2060 - val_acc: 0.6000\n",
      "Epoch 136/200\n",
      "15/15 [==============================] - 0s 427us/step - loss: 0.2260 - acc: 1.0000 - val_loss: 1.2070 - val_acc: 0.6000\n",
      "Epoch 137/200\n",
      "15/15 [==============================] - 0s 533us/step - loss: 0.2241 - acc: 1.0000 - val_loss: 1.2082 - val_acc: 0.6000\n",
      "Epoch 138/200\n",
      "15/15 [==============================] - 0s 399us/step - loss: 0.2222 - acc: 1.0000 - val_loss: 1.2092 - val_acc: 0.6000\n",
      "Epoch 139/200\n",
      "15/15 [==============================] - 0s 533us/step - loss: 0.2204 - acc: 1.0000 - val_loss: 1.2103 - val_acc: 0.6000\n",
      "Epoch 140/200\n",
      "15/15 [==============================] - 0s 466us/step - loss: 0.2186 - acc: 1.0000 - val_loss: 1.2115 - val_acc: 0.6000\n",
      "Epoch 141/200\n",
      "15/15 [==============================] - 0s 401us/step - loss: 0.2169 - acc: 1.0000 - val_loss: 1.2128 - val_acc: 0.6000\n",
      "Epoch 142/200\n",
      "15/15 [==============================] - 0s 399us/step - loss: 0.2153 - acc: 1.0000 - val_loss: 1.2141 - val_acc: 0.6000\n",
      "Epoch 143/200\n",
      "15/15 [==============================] - 0s 466us/step - loss: 0.2136 - acc: 1.0000 - val_loss: 1.2154 - val_acc: 0.6000\n",
      "Epoch 144/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.2120 - acc: 1.0000 - val_loss: 1.2172 - val_acc: 0.6000\n",
      "Epoch 145/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.2104 - acc: 1.0000 - val_loss: 1.2190 - val_acc: 0.6000\n",
      "Epoch 146/200\n",
      "15/15 [==============================] - 0s 332us/step - loss: 0.2088 - acc: 1.0000 - val_loss: 1.2207 - val_acc: 0.6000\n",
      "Epoch 147/200\n",
      "15/15 [==============================] - 0s 467us/step - loss: 0.2072 - acc: 1.0000 - val_loss: 1.2223 - val_acc: 0.6000\n",
      "Epoch 148/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.2057 - acc: 1.0000 - val_loss: 1.2239 - val_acc: 0.6000\n",
      "Epoch 149/200\n",
      "15/15 [==============================] - 0s 408us/step - loss: 0.2042 - acc: 1.0000 - val_loss: 1.2254 - val_acc: 0.6000\n",
      "Epoch 150/200\n",
      "15/15 [==============================] - 0s 394us/step - loss: 0.2027 - acc: 1.0000 - val_loss: 1.2273 - val_acc: 0.6000\n",
      "Epoch 151/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.2013 - acc: 1.0000 - val_loss: 1.2293 - val_acc: 0.6000\n",
      "Epoch 152/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.1998 - acc: 1.0000 - val_loss: 1.2313 - val_acc: 0.6000\n",
      "Epoch 153/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.1984 - acc: 1.0000 - val_loss: 1.2333 - val_acc: 0.6000\n",
      "Epoch 154/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.1971 - acc: 1.0000 - val_loss: 1.2350 - val_acc: 0.6000\n",
      "Epoch 155/200\n",
      "15/15 [==============================] - 0s 332us/step - loss: 0.1958 - acc: 1.0000 - val_loss: 1.2367 - val_acc: 0.6000\n",
      "Epoch 156/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.1944 - acc: 1.0000 - val_loss: 1.2385 - val_acc: 0.6000\n",
      "Epoch 157/200\n",
      "15/15 [==============================] - 0s 428us/step - loss: 0.1931 - acc: 1.0000 - val_loss: 1.2405 - val_acc: 0.6000\n",
      "Epoch 158/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.1918 - acc: 1.0000 - val_loss: 1.2426 - val_acc: 0.6000\n",
      "Epoch 159/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.1905 - acc: 1.0000 - val_loss: 1.2447 - val_acc: 0.6000\n",
      "Epoch 160/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.1893 - acc: 1.0000 - val_loss: 1.2468 - val_acc: 0.6000\n",
      "Epoch 161/200\n",
      "15/15 [==============================] - 0s 466us/step - loss: 0.1880 - acc: 1.0000 - val_loss: 1.2489 - val_acc: 0.6000\n",
      "Epoch 162/200\n",
      "15/15 [==============================] - 0s 399us/step - loss: 0.1868 - acc: 1.0000 - val_loss: 1.2510 - val_acc: 0.6000\n",
      "Epoch 163/200\n",
      "15/15 [==============================] - 0s 333us/step - loss: 0.1856 - acc: 1.0000 - val_loss: 1.2532 - val_acc: 0.6000\n",
      "Epoch 164/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.1844 - acc: 1.0000 - val_loss: 1.2557 - val_acc: 0.6000\n",
      "Epoch 165/200\n",
      "15/15 [==============================] - 0s 460us/step - loss: 0.1832 - acc: 1.0000 - val_loss: 1.2583 - val_acc: 0.6000\n",
      "Epoch 166/200\n",
      "15/15 [==============================] - 0s 533us/step - loss: 0.1820 - acc: 1.0000 - val_loss: 1.2608 - val_acc: 0.6000\n",
      "Epoch 167/200\n",
      "15/15 [==============================] - 0s 333us/step - loss: 0.1809 - acc: 1.0000 - val_loss: 1.2634 - val_acc: 0.6000\n",
      "Epoch 168/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.1797 - acc: 1.0000 - val_loss: 1.2661 - val_acc: 0.6000\n",
      "Epoch 169/200\n",
      "15/15 [==============================] - 0s 466us/step - loss: 0.1785 - acc: 1.0000 - val_loss: 1.2687 - val_acc: 0.6000\n",
      "Epoch 170/200\n",
      "15/15 [==============================] - 0s 467us/step - loss: 0.1774 - acc: 1.0000 - val_loss: 1.2710 - val_acc: 0.6000\n",
      "Epoch 171/200\n",
      "15/15 [==============================] - 0s 393us/step - loss: 0.1762 - acc: 1.0000 - val_loss: 1.2730 - val_acc: 0.6000\n",
      "Epoch 172/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.1751 - acc: 1.0000 - val_loss: 1.2751 - val_acc: 0.6000\n",
      "Epoch 173/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.1740 - acc: 1.0000 - val_loss: 1.2772 - val_acc: 0.6000\n",
      "Epoch 174/200\n",
      "15/15 [==============================] - 0s 399us/step - loss: 0.1730 - acc: 1.0000 - val_loss: 1.2796 - val_acc: 0.6000\n",
      "Epoch 175/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.1719 - acc: 1.0000 - val_loss: 1.2817 - val_acc: 0.6000\n",
      "Epoch 176/200\n",
      "15/15 [==============================] - 0s 406us/step - loss: 0.1709 - acc: 1.0000 - val_loss: 1.2837 - val_acc: 0.6000\n",
      "Epoch 177/200\n",
      "15/15 [==============================] - 0s 593us/step - loss: 0.1698 - acc: 1.0000 - val_loss: 1.2856 - val_acc: 0.6000\n",
      "Epoch 178/200\n",
      "15/15 [==============================] - 0s 467us/step - loss: 0.1688 - acc: 1.0000 - val_loss: 1.2876 - val_acc: 0.6000\n",
      "Epoch 179/200\n",
      "15/15 [==============================] - 0s 465us/step - loss: 0.1678 - acc: 1.0000 - val_loss: 1.2896 - val_acc: 0.6000\n",
      "Epoch 180/200\n",
      "15/15 [==============================] - 0s 398us/step - loss: 0.1668 - acc: 1.0000 - val_loss: 1.2918 - val_acc: 0.6000\n",
      "Epoch 181/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.1658 - acc: 1.0000 - val_loss: 1.2938 - val_acc: 0.6000\n",
      "Epoch 182/200\n",
      "15/15 [==============================] - 0s 390us/step - loss: 0.1648 - acc: 1.0000 - val_loss: 1.2957 - val_acc: 0.6000\n",
      "Epoch 183/200\n",
      "15/15 [==============================] - 0s 536us/step - loss: 0.1638 - acc: 1.0000 - val_loss: 1.2977 - val_acc: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/200\n",
      "15/15 [==============================] - 0s 466us/step - loss: 0.1628 - acc: 1.0000 - val_loss: 1.2998 - val_acc: 0.6000\n",
      "Epoch 185/200\n",
      "15/15 [==============================] - 0s 333us/step - loss: 0.1618 - acc: 1.0000 - val_loss: 1.3020 - val_acc: 0.6000\n",
      "Epoch 186/200\n",
      "15/15 [==============================] - 0s 467us/step - loss: 0.1609 - acc: 1.0000 - val_loss: 1.3042 - val_acc: 0.6000\n",
      "Epoch 187/200\n",
      "15/15 [==============================] - 0s 401us/step - loss: 0.1599 - acc: 1.0000 - val_loss: 1.3068 - val_acc: 0.6000\n",
      "Epoch 188/200\n",
      "15/15 [==============================] - 0s 401us/step - loss: 0.1590 - acc: 1.0000 - val_loss: 1.3092 - val_acc: 0.6000\n",
      "Epoch 189/200\n",
      "15/15 [==============================] - 0s 399us/step - loss: 0.1580 - acc: 1.0000 - val_loss: 1.3116 - val_acc: 0.6000\n",
      "Epoch 190/200\n",
      "15/15 [==============================] - 0s 533us/step - loss: 0.1571 - acc: 1.0000 - val_loss: 1.3137 - val_acc: 0.6000\n",
      "Epoch 191/200\n",
      "15/15 [==============================] - 0s 467us/step - loss: 0.1562 - acc: 1.0000 - val_loss: 1.3155 - val_acc: 0.6000\n",
      "Epoch 192/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.1553 - acc: 1.0000 - val_loss: 1.3173 - val_acc: 0.6000\n",
      "Epoch 193/200\n",
      "15/15 [==============================] - 0s 467us/step - loss: 0.1543 - acc: 1.0000 - val_loss: 1.3193 - val_acc: 0.6000\n",
      "Epoch 194/200\n",
      "15/15 [==============================] - 0s 467us/step - loss: 0.1535 - acc: 1.0000 - val_loss: 1.3216 - val_acc: 0.6000\n",
      "Epoch 195/200\n",
      "15/15 [==============================] - 0s 403us/step - loss: 0.1526 - acc: 1.0000 - val_loss: 1.3241 - val_acc: 0.6000\n",
      "Epoch 196/200\n",
      "15/15 [==============================] - 0s 466us/step - loss: 0.1517 - acc: 1.0000 - val_loss: 1.3264 - val_acc: 0.6000\n",
      "Epoch 197/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.1508 - acc: 1.0000 - val_loss: 1.3285 - val_acc: 0.6000\n",
      "Epoch 198/200\n",
      "15/15 [==============================] - 0s 400us/step - loss: 0.1500 - acc: 1.0000 - val_loss: 1.3307 - val_acc: 0.6000\n",
      "Epoch 199/200\n",
      "15/15 [==============================] - 0s 487us/step - loss: 0.1491 - acc: 1.0000 - val_loss: 1.3328 - val_acc: 0.6000\n",
      "Epoch 200/200\n",
      "15/15 [==============================] - 0s 403us/step - loss: 0.1483 - acc: 1.0000 - val_loss: 1.3346 - val_acc: 0.6000\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 200\n",
    "BATCH_SIZE = 20\n",
    "callbacks = [ EarlyStopping(monitor=\"loss\", patience=10, min_delta=0.0) ]\n",
    "\n",
    "evaluation = model.fit(x_t_c, y_t, shuffle=True,\n",
    "                        epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1,\n",
    "                        validation_data = (x_v_c, y_v),\n",
    "                        callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.75      0.75      0.75        12\n",
      "        1.0       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.60      0.60      0.60        15\n",
      "\n",
      "[[9 3]\n",
      " [3 0]]\n",
      "[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "v_p_kc = model.predict(x_v_c)\n",
    "v_p_kc = [1.0 if v  >= 0.5 else 0.0 for v in v_p_kc]\n",
    "print(classification_report(y_v.flatten(), v_p_kc))\n",
    "print(confusion_matrix(y_v.flatten(), v_p_kc))\n",
    "print(v_p_kc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_p_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
